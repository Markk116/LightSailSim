{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LightSailSim: Lightsail Design and Simulation Tool This repository features a set of tools for analysing the deformation of membranes using a particle system model. Installation Clone the repository: git clone https://github.com/markk116/LightSailSim.git cd LightSailSim pip install -e . Navigate to the project directory: cd LightSailSim To verify everything works you can run python Simulations \\G ao_et_al.py from the root directory. Usage Running simulations Navigate to the Simulations directory and run the desired script: cd Simulations python Simple_config_round.py Acknowledgement Based on Alexander Batchelor: Modeling kite deformation with particle system model. If you need any more help or further assistance with your project, feel free to ask. Happy coding!","title":"Home"},{"location":"#lightsailsim-lightsail-design-and-simulation-tool","text":"This repository features a set of tools for analysing the deformation of membranes using a particle system model.","title":"LightSailSim: Lightsail Design and Simulation Tool"},{"location":"#installation","text":"Clone the repository: git clone https://github.com/markk116/LightSailSim.git cd LightSailSim pip install -e . Navigate to the project directory: cd LightSailSim To verify everything works you can run python Simulations \\G ao_et_al.py from the root directory.","title":"Installation"},{"location":"#usage","text":"","title":"Usage"},{"location":"#running-simulations","text":"Navigate to the Simulations directory and run the desired script: cd Simulations python Simple_config_round.py","title":"Running simulations"},{"location":"#acknowledgement","text":"Based on Alexander Batchelor: Modeling kite deformation with particle system model. If you need any more help or further assistance with your project, feel free to ask. Happy coding!","title":"Acknowledgement"},{"location":"docs/Tutourials/Tutorial%201/","text":"Tutourial 1 In this tutourial we will set up, mesh and simulate a basic membrane using the particle model. First we will import the right modules and set up some basic paramets for the simulation. import numpy as np import matplotlib.pyplot as plt import pandas as pd import sys , os sys . path . append ( os . path . abspath ( '..' )) from src.particleSystem.ParticleSystem import ParticleSystem # dictionary of required parameters params = { # model parameters \"k\" : 2 , # [N/m] spring stiffness \"c\" : 1 , # [N s/m] damping coefficient \"m_segment\" : 1 , # [kg] mass of each node # simulation settings \"dt\" : 0.1 , # [s] simulation timestep \"t_steps\" : 1000 , # [-] number of simulated time steps \"abs_tol\" : 1e-50 , # [m/s] absolute error tolerance iterative solver \"rel_tol\" : 1e-5 , # [-] relative error tolerance iterative solver \"max_iter\" : 1e5 , # [-] maximum number of iterations # physical parameters \"g\" : 9.807 # [m/s^2] gravitational acceleration } Meshing Meshing is fully manual at the moment. This means it is up to us to define a clever discretization for the object we want to simulate. For this tutourial we will simulate a ribbon experiencing an out of plane force. It is important to format the data such that we can feed it to the simulation library the way it expects it. We will have to supply three sturctures: The initial conditions : This represents the starting locations, velocities, masses and the boundary conditions of the nodes. Becuase they're point masses the only supported boundary conditions are fixed and free. The structure is a list with an entry for each node. It has the following form: initial_conditions = [[[ x_1 , y_1 , z_1 ], [ u_1 , v_1 , w_1 ], m_1 , Fixed_1 ], ... , [[ x_n , y_n , z_n ], [ u_n , v_n , w_n ], m_n , Fixed_n ]] The connectivity matrix : This is an n by n array where n is the total number of nodes. It represents the connections between nodes, where the indices of a cell in the array represents which cells are connected. A connection is marked by a non-zero entry. Four nodes connected in a line will have the following connectivity matrix: array ([[ 0. , 1. , 0. , 0. ], [ 1. , 0. , 1. , 0. ], [ 0. , 1. , 0. , 1. ], [ 0. , 0. , 1. , 0. ]]) The external forces : The external forces are passed to the simulation at every timestep. They are represented by F_x, F_y, F_z components for each node, but flattened into a 1D list. This allows the forces to be recalculated each timestep to take into account geometric non-linearities. The list has the form of: F_ext = [ F_x1 , F_y1 , F_z1 , ... , F_xn , F_yn , F_zn ] # grid discretization # We will use a rectanular grid of 6 x 3, which is 6 x 4 nodes spaced 1 unit apart grid_width = 3 grid_length = 6 params [ \"l0\" ] = 1 params [ \"n\" ] = ( grid_width + 1 ) * ( grid_length + 1 ) # Setting up the coordinates for the nodes mesh = np . meshgrid ( np . linspace ( 0 , grid_length , grid_length + 1 ), np . linspace ( 0 , grid_width , grid_width + 1 )) # Fitting it into the required format and setting boundary conditions # A the core of it this section converts the coordinate grids into a list of nodes initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))) . T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )) . T )) for xyz in xyz_coordinates : fixed = False if xyz [ 0 ] == 0 or xyz [ 0 ] == grid_length : #For fixing the other boundary use \"xyz[1] == 0 or xyz[1] == grid_width\" fixed = True initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ \"m_segment\" ], fixed ]) # Setting up the connectivity matrix connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i , node in enumerate ( initial_conditions [: - grid_length - 1 ]): # adding connextions in y-axis connections . append ([ i , i + grid_length + 1 , params [ 'k' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ): # adding connections in x-axis if ( i + 1 ) % ( grid_length + 1 ): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) # For convenience #connections = np.nonzero(np.triu(connectivity_matrix)) # Getting indices of cells with a connection #connections = np.column_stack((connections[0], connections[1])) Checking the mesh Now that we have set up the mesh, we can check if all the nodes and connection are in the right place by plotting it. # Applying external forces # Just using a simple load in z for this example f_ext = np . array ([[ 0 , 0 , 1 ] for i in range ( params [ 'n' ])]) . flatten () # Plotting mesh with external forces fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) for i , node in enumerate ( initial_conditions ): if node [ 3 ]: ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'red' , marker = 'o' ) else : ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'blue' , marker = 'o' ) ax . quiver ( * node [ 0 ] . tolist (), f_ext [ 3 * i ], f_ext [ 3 * i + 1 ], f_ext [ 3 * i + 2 ], length = 1 ) for connection in connections : line = np . column_stack ([ initial_conditions [ connection [ 0 ]][ 0 ], initial_conditions [ connection [ 1 ]][ 0 ]]) ax . plot ( line [ 0 ], line [ 1 ], line [ 2 ], color = 'black' ) ax . set_box_aspect (( grid_length , grid_width , 1 )) ax . set_zlim ( - 1 , 1 ) plt . title ( \"Initial state\" ) Text(0.5, 0.92, 'Initial state') Running the simulation Now we will set up the simulation itself. We need to determine for ourselves at what point we consider the simulation complete. In this case I have chosen a cutoff value for the kinetic energy. However, the simulation uses kinetic dampening so we cannot simply stop the simulation once the cutoff has been reached for the first time. This is because the velocities are all periodically set to zero. Hence we look at the highest value in a window of ten timesteps and stop the simulation when the highest one of the window is below our cutoff. # Now we can setup the particle system and simulation PS = ParticleSystem ( connections , initial_conditions , params ) t_vector = np . linspace ( params [ \"dt\" ], params [ \"t_steps\" ] * params [ \"dt\" ], params [ \"t_steps\" ]) final_step = 0 E_kin = [] f_int = [] # And run the simulation for step in t_vector : PS . kin_damp_sim ( f_ext ) final_step = step x , v , = PS . x_v_current E_kin . append ( np . linalg . norm ( v * v )) f_int . append ( np . linalg . norm ( PS . f_int )) converged = False if step > 10 : if np . max ( E_kin [ - 10 : - 1 ]) <= 1e-29 : converged = True if converged and step > 1 : print ( \"Kinetic damping PS converged\" , step ) break Kinetic damping PS converged 77.0 Let's take a look at the convergence behaviour of the simulation and see what we can learn. Let's also plot another common convergence criterium for comparison, the internal forces. We see that towards the end of the simulation the curve starts to flatten out for the Kinetic energy. This indicates that further simulation has decreasing marginal returns. The internal forces stabilise onto a set value and osclilate around this value. These dampened oscilations are very hard to visualise in one plot because of the diminishing size of the oscilations. # Let's check the convergence plot # Change these to zoom in on a specific region. plotstop = len ( E_kin ) plotstart = 0 plt . plot ( t_vector [: plotstop ], E_kin [: plotstop ], label = 'Kinetic Energy [J]' ) plt . plot ( t_vector [ plotstart : plotstop ], f_int [ plotstart : plotstop ], label = 'Internal Forces [N]' ) # Filtering out the peaks to mark where the kinetic damping algorithm kicked in. df = pd . DataFrame ( E_kin , index = t_vector [ 0 : plotstop ]) peaksonly = df [( df [ 0 ] . shift ( 1 ) < df [ 0 ]) & ( df [ 0 ] . shift ( - 1 ) < df [ 0 ])] plt . scatter ( peaksonly . index , peaksonly [ 0 ], c = 'r' , linewidths = 1 , marker = '+' , label = 'Kinetic Damping Enacted' ) plt . legend () plt . yscale ( 'log' ) plt . title ( \"Convergence Plot\" ) plt . xlabel ( 'Time [s]' ) plt . ylabel ( 'Quantity of interest' ) plt . xlim ( t_vector [ 0 ], t_vector [ plotstop ]) (0.1, 77.1) Reviewing results To view the results we will once again plot the system in 3D. To do this we first have to extract the current positions from the system. After that we can re-use the code from the beginning to visualise our result. final_positions = [[ particle . x , particle . v , particle . m , particle . fixed ] for particle in PS . particles ] # Plotting final results fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) for i , node in enumerate ( final_positions ): if node [ 3 ]: ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'red' , marker = 'o' ) else : ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'blue' , marker = 'o' ) ax . quiver ( * node [ 0 ] . tolist (), f_ext [ 3 * i ], f_ext [ 3 * i + 1 ], f_ext [ 3 * i + 2 ]) #, length = 0.3) for connection in connections : line = np . column_stack ([ final_positions [ connection [ 0 ]][ 0 ], final_positions [ connection [ 1 ]][ 0 ]]) ax . plot ( line [ 0 ], line [ 1 ], line [ 2 ], color = 'black' ) ax . legend ([ 'Fixed nodes' , 'Forces' , 'Free nodes' ]) # Finding bounding box and setting aspect ratio xyz = np . array ([ particle . x for particle in PS . particles ]) bb = [ np . ptp ( i ) for i in xyz . T ] ax . set_box_aspect ( bb ) plt . title ( \"Final state\" ) Text(0.5, 0.92, 'Final state')","title":"Tutorial 1"},{"location":"docs/Tutourials/Tutorial%201/#tutourial-1","text":"In this tutourial we will set up, mesh and simulate a basic membrane using the particle model. First we will import the right modules and set up some basic paramets for the simulation. import numpy as np import matplotlib.pyplot as plt import pandas as pd import sys , os sys . path . append ( os . path . abspath ( '..' )) from src.particleSystem.ParticleSystem import ParticleSystem # dictionary of required parameters params = { # model parameters \"k\" : 2 , # [N/m] spring stiffness \"c\" : 1 , # [N s/m] damping coefficient \"m_segment\" : 1 , # [kg] mass of each node # simulation settings \"dt\" : 0.1 , # [s] simulation timestep \"t_steps\" : 1000 , # [-] number of simulated time steps \"abs_tol\" : 1e-50 , # [m/s] absolute error tolerance iterative solver \"rel_tol\" : 1e-5 , # [-] relative error tolerance iterative solver \"max_iter\" : 1e5 , # [-] maximum number of iterations # physical parameters \"g\" : 9.807 # [m/s^2] gravitational acceleration }","title":"Tutourial 1"},{"location":"docs/Tutourials/Tutorial%201/#meshing","text":"Meshing is fully manual at the moment. This means it is up to us to define a clever discretization for the object we want to simulate. For this tutourial we will simulate a ribbon experiencing an out of plane force. It is important to format the data such that we can feed it to the simulation library the way it expects it. We will have to supply three sturctures: The initial conditions : This represents the starting locations, velocities, masses and the boundary conditions of the nodes. Becuase they're point masses the only supported boundary conditions are fixed and free. The structure is a list with an entry for each node. It has the following form: initial_conditions = [[[ x_1 , y_1 , z_1 ], [ u_1 , v_1 , w_1 ], m_1 , Fixed_1 ], ... , [[ x_n , y_n , z_n ], [ u_n , v_n , w_n ], m_n , Fixed_n ]] The connectivity matrix : This is an n by n array where n is the total number of nodes. It represents the connections between nodes, where the indices of a cell in the array represents which cells are connected. A connection is marked by a non-zero entry. Four nodes connected in a line will have the following connectivity matrix: array ([[ 0. , 1. , 0. , 0. ], [ 1. , 0. , 1. , 0. ], [ 0. , 1. , 0. , 1. ], [ 0. , 0. , 1. , 0. ]]) The external forces : The external forces are passed to the simulation at every timestep. They are represented by F_x, F_y, F_z components for each node, but flattened into a 1D list. This allows the forces to be recalculated each timestep to take into account geometric non-linearities. The list has the form of: F_ext = [ F_x1 , F_y1 , F_z1 , ... , F_xn , F_yn , F_zn ] # grid discretization # We will use a rectanular grid of 6 x 3, which is 6 x 4 nodes spaced 1 unit apart grid_width = 3 grid_length = 6 params [ \"l0\" ] = 1 params [ \"n\" ] = ( grid_width + 1 ) * ( grid_length + 1 ) # Setting up the coordinates for the nodes mesh = np . meshgrid ( np . linspace ( 0 , grid_length , grid_length + 1 ), np . linspace ( 0 , grid_width , grid_width + 1 )) # Fitting it into the required format and setting boundary conditions # A the core of it this section converts the coordinate grids into a list of nodes initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))) . T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )) . T )) for xyz in xyz_coordinates : fixed = False if xyz [ 0 ] == 0 or xyz [ 0 ] == grid_length : #For fixing the other boundary use \"xyz[1] == 0 or xyz[1] == grid_width\" fixed = True initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ \"m_segment\" ], fixed ]) # Setting up the connectivity matrix connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i , node in enumerate ( initial_conditions [: - grid_length - 1 ]): # adding connextions in y-axis connections . append ([ i , i + grid_length + 1 , params [ 'k' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ): # adding connections in x-axis if ( i + 1 ) % ( grid_length + 1 ): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) # For convenience #connections = np.nonzero(np.triu(connectivity_matrix)) # Getting indices of cells with a connection #connections = np.column_stack((connections[0], connections[1]))","title":"Meshing"},{"location":"docs/Tutourials/Tutorial%201/#checking-the-mesh","text":"Now that we have set up the mesh, we can check if all the nodes and connection are in the right place by plotting it. # Applying external forces # Just using a simple load in z for this example f_ext = np . array ([[ 0 , 0 , 1 ] for i in range ( params [ 'n' ])]) . flatten () # Plotting mesh with external forces fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) for i , node in enumerate ( initial_conditions ): if node [ 3 ]: ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'red' , marker = 'o' ) else : ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'blue' , marker = 'o' ) ax . quiver ( * node [ 0 ] . tolist (), f_ext [ 3 * i ], f_ext [ 3 * i + 1 ], f_ext [ 3 * i + 2 ], length = 1 ) for connection in connections : line = np . column_stack ([ initial_conditions [ connection [ 0 ]][ 0 ], initial_conditions [ connection [ 1 ]][ 0 ]]) ax . plot ( line [ 0 ], line [ 1 ], line [ 2 ], color = 'black' ) ax . set_box_aspect (( grid_length , grid_width , 1 )) ax . set_zlim ( - 1 , 1 ) plt . title ( \"Initial state\" ) Text(0.5, 0.92, 'Initial state')","title":"Checking the mesh"},{"location":"docs/Tutourials/Tutorial%201/#running-the-simulation","text":"Now we will set up the simulation itself. We need to determine for ourselves at what point we consider the simulation complete. In this case I have chosen a cutoff value for the kinetic energy. However, the simulation uses kinetic dampening so we cannot simply stop the simulation once the cutoff has been reached for the first time. This is because the velocities are all periodically set to zero. Hence we look at the highest value in a window of ten timesteps and stop the simulation when the highest one of the window is below our cutoff. # Now we can setup the particle system and simulation PS = ParticleSystem ( connections , initial_conditions , params ) t_vector = np . linspace ( params [ \"dt\" ], params [ \"t_steps\" ] * params [ \"dt\" ], params [ \"t_steps\" ]) final_step = 0 E_kin = [] f_int = [] # And run the simulation for step in t_vector : PS . kin_damp_sim ( f_ext ) final_step = step x , v , = PS . x_v_current E_kin . append ( np . linalg . norm ( v * v )) f_int . append ( np . linalg . norm ( PS . f_int )) converged = False if step > 10 : if np . max ( E_kin [ - 10 : - 1 ]) <= 1e-29 : converged = True if converged and step > 1 : print ( \"Kinetic damping PS converged\" , step ) break Kinetic damping PS converged 77.0 Let's take a look at the convergence behaviour of the simulation and see what we can learn. Let's also plot another common convergence criterium for comparison, the internal forces. We see that towards the end of the simulation the curve starts to flatten out for the Kinetic energy. This indicates that further simulation has decreasing marginal returns. The internal forces stabilise onto a set value and osclilate around this value. These dampened oscilations are very hard to visualise in one plot because of the diminishing size of the oscilations. # Let's check the convergence plot # Change these to zoom in on a specific region. plotstop = len ( E_kin ) plotstart = 0 plt . plot ( t_vector [: plotstop ], E_kin [: plotstop ], label = 'Kinetic Energy [J]' ) plt . plot ( t_vector [ plotstart : plotstop ], f_int [ plotstart : plotstop ], label = 'Internal Forces [N]' ) # Filtering out the peaks to mark where the kinetic damping algorithm kicked in. df = pd . DataFrame ( E_kin , index = t_vector [ 0 : plotstop ]) peaksonly = df [( df [ 0 ] . shift ( 1 ) < df [ 0 ]) & ( df [ 0 ] . shift ( - 1 ) < df [ 0 ])] plt . scatter ( peaksonly . index , peaksonly [ 0 ], c = 'r' , linewidths = 1 , marker = '+' , label = 'Kinetic Damping Enacted' ) plt . legend () plt . yscale ( 'log' ) plt . title ( \"Convergence Plot\" ) plt . xlabel ( 'Time [s]' ) plt . ylabel ( 'Quantity of interest' ) plt . xlim ( t_vector [ 0 ], t_vector [ plotstop ]) (0.1, 77.1)","title":"Running the simulation"},{"location":"docs/Tutourials/Tutorial%201/#reviewing-results","text":"To view the results we will once again plot the system in 3D. To do this we first have to extract the current positions from the system. After that we can re-use the code from the beginning to visualise our result. final_positions = [[ particle . x , particle . v , particle . m , particle . fixed ] for particle in PS . particles ] # Plotting final results fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) for i , node in enumerate ( final_positions ): if node [ 3 ]: ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'red' , marker = 'o' ) else : ax . scatter ( node [ 0 ][ 0 ], node [ 0 ][ 1 ], node [ 0 ][ 2 ], color = 'blue' , marker = 'o' ) ax . quiver ( * node [ 0 ] . tolist (), f_ext [ 3 * i ], f_ext [ 3 * i + 1 ], f_ext [ 3 * i + 2 ]) #, length = 0.3) for connection in connections : line = np . column_stack ([ final_positions [ connection [ 0 ]][ 0 ], final_positions [ connection [ 1 ]][ 0 ]]) ax . plot ( line [ 0 ], line [ 1 ], line [ 2 ], color = 'black' ) ax . legend ([ 'Fixed nodes' , 'Forces' , 'Free nodes' ]) # Finding bounding box and setting aspect ratio xyz = np . array ([ particle . x for particle in PS . particles ]) bb = [ np . ptp ( i ) for i in xyz . T ] ax . set_box_aspect ( bb ) plt . title ( \"Final state\" ) Text(0.5, 0.92, 'Final state')","title":"Reviewing results"},{"location":"reference/src/ExternalForces/LaserBeam/","text":"Module src.ExternalForces.LaserBeam Child Class 'LaserBeam', for holding laser atributes View Source # -*- coding: utf-8 -*- \"\"\" Child Class 'LaserBeam', for holding laser atributes \"\"\" from typing import Callable import numpy as np import matplotlib.pyplot as plt from src.particleSystem.SystemObject import SystemObject class LaserBeam ( SystemObject ): \"\"\" Holds information about the laserbeam Attributes --------- intensity_profile : Callable[[float, float], float] Maps (x, y) to the scalar intensity profile of the beam. polarization_map : Callable[[float, float], np.ndarray] Maps (x, y) to the polarization profile of the beam represented as a Jones vector. \"\"\" def __init__ ( self , intensity_profile : Callable [[ float , float ], float ], polarization_map : Callable [[ float , float ], list [ np . complex_ , np . complex_ ]] ): \"\"\" Initializes a laserbeam based on input parameters The polarization profile represents the Jones vector. Its datatype is allowed to be complex in order to capture both linear and circular polarization states. Parameters ---------- intensity_profile : Callable[[float, float], float] A numpy compatible function that maps x, y to the scalar intensity profile of the beam. [W/m^2] polarization_map : Callable[[float, float], np.ndarray] A numpy compatible function that maps x, y to the polarization profile of the beam. [-] The polarisation vector should be a unit vector! Returns ------- None. \"\"\" self . intensity_profile = intensity_profile self . polarization_map = polarization_map def __str__ ( self ): print ( \"LaserBeam instantiated with attributes:\" ) print ( f \"polarisation_map: { self . polarization_map } \" ) print ( f \"intensity_profile: { self . intensity_profile } \" ) return \"\" def plot ( self , ax = None , x_range = ( - 1 , 1 ), y_range = ( - 1 , 1 ), z_scale = 1 , number_of_points = 121 , arrow_length = 0.1 ): \"\"\" plotting function to display shape and polarisation of LaserBeam object. Parameters ---------- ax : matplotlib.Axes, optional Allows feeding in axes to plot over existing axes. The default is None. x_range : list[float,float], optional range in x over which to pol function. The default is [-1,1]. y_range : list[float,float], optional range in y over which to pol function. The default is [-1,1]. z_scale : float, optional amount by which to scale the z axis up or down. number_of_points : int, optional number of points to plot over. The default is 100. arrow_length : float, optional sets the length of the polarisation arrows Returns ------- ax : matplitlib.Axes Returns axes for further work. \"\"\" n_sqrt = int ( np . sqrt ( number_of_points )) x_range = np . linspace ( x_range [ 0 ], x_range [ 1 ], n_sqrt ) y_range = np . linspace ( y_range [ 0 ], y_range [ 1 ], n_sqrt ) x_range , y_range = np . meshgrid ( x_range , y_range ) intensity_profile = self . intensity_profile ( x_range , y_range ) polarization_map = self . polarization_map ( x_range , y_range ) if ax is None : fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax . plot_surface ( x_range , y_range , intensity_profile / z_scale , label = \"Intensity\" , alpha = 0.5 , color = 'lightblue' ) ax . quiver ( x_range . ravel (), y_range . ravel (), ( intensity_profile / z_scale ) . ravel (), polarization_map . T [ 0 ], polarization_map . T [ 1 ], np . zeros ( polarization_map . T [ 0 ] . shape ), length = arrow_length , color = 'r' , label = \"Polarization\" ) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) plt . legend () return ax if __name__ == \"__main__\" : mu = 0 sigma = 0.5 LB = LaserBeam ( lambda x , y : np . exp ( - 1 / 2 * (( x - mu ) / sigma ) ** 2 - 1 / 2 * (( y - mu ) / sigma ) ** 2 ), lambda x , y : np . array ([ 1 + 0 j , 0 + 0 j ]) ) LB . plot () Classes LaserBeam class LaserBeam ( intensity_profile : Callable [[ float , float ], float ], polarization_map : Callable [[ float , float ], list [ numpy . complex128 , numpy . complex128 ]] ) Holds information about the laserbeam Attributes intensity_profile : Callable[[float, float], float] Maps (x, y) to the scalar intensity profile of the beam. polarization_map : Callable[[float, float], np.ndarray] Maps (x, y) to the polarization profile of the beam represented as a Jones vector. View Source class LaserBeam(SystemObject): \"\"\" Holds information about the laserbeam Attributes --------- intensity_profile : Callable [[ float , float ] , float ] Maps (x , y) to the scalar intensity profile of the beam . polarization_map : Callable [[ float , float ] , np . ndarray ] Maps (x , y) to the polarization profile of the beam represented as a Jones vector . \"\"\" def __init__(self , intensity_profile: Callable [[ float , float ] , float ] , polarization_map: Callable [[ float , float ] , list [ np . complex_ , np . complex_ ]] ): \"\"\" Initializes a laserbeam based on input parameters The polarization profile represents the Jones vector . Its datatype is allowed to be complex in order to capture both linear and circular polarization states . Parameters ---------- intensity_profile : Callable [[ float , float ] , float ] A numpy compatible function that maps x , y to the scalar intensity profile of the beam . [ W/m^2 ] polarization_map : Callable [[ float , float ] , np . ndarray ] A numpy compatible function that maps x , y to the polarization profile of the beam . [ - ] The polarisation vector should be a unit vector! Returns ------- None . \"\"\" self . intensity_profile = intensity_profile self . polarization_map = polarization_map def __str__(self): print(\"LaserBeam instantiated with attributes:\") print(f\"polarisation_map: {self . polarization_map}\") print(f\"intensity_profile: {self . intensity_profile}\") return \"\" def plot(self , ax = None , x_range = ( - 1 , 1) , y_range = ( - 1 , 1) , z_scale = 1 , number_of_points = 121 , arrow_length = 0 . 1): \"\"\" plotting function to display shape and polarisation of LaserBeam object . Parameters ---------- ax : matplotlib . Axes , optional Allows feeding in axes to plot over existing axes . The default is None . x_range : list [ float , float ] , optional range in x over which to pol function . The default is [ - 1 , 1 ] . y_range : list [ float , float ] , optional range in y over which to pol function . The default is [ - 1 , 1 ] . z_scale : float , optional amount by which to scale the z axis up or down . number_of_points : int , optional number of points to plot over . The default is 100 . arrow_length : float , optional sets the length of the polarisation arrows Returns ------- ax : matplitlib . Axes Returns axes for further work . \"\"\" n_sqrt = int(np . sqrt(number_of_points)) x_range = np . linspace(x_range [ 0 ] , x_range [ 1 ] , n_sqrt) y_range = np . linspace(y_range [ 0 ] , y_range [ 1 ] , n_sqrt) x_range , y_range = np . meshgrid(x_range , y_range) intensity_profile = self . intensity_profile(x_range , y_range) polarization_map = self . polarization_map(x_range , y_range) if ax is None: fig = plt . figure() ax = fig . add_subplot(projection = '3d') ax . plot_surface(x_range , y_range , intensity_profile/z_scale , label = \"Intensity\" , alpha = 0 . 5 , color = 'lightblue') ax . quiver(x_range . ravel() , y_range . ravel() , (intensity_profile/z_scale) . ravel() , polarization_map . T [ 0 ] , polarization_map . T [ 1 ] , np . zeros(polarization_map . T [ 0 ] . shape) , length = arrow_length , color='r' , label = \"Polarization\") ax . set_xlabel('x') ax . set_ylabel('y') plt . legend() return ax Ancestors (in MRO) src.particleSystem.SystemObject.SystemObject abc.ABC Methods plot def plot ( self , ax = None , x_range = ( - 1 , 1 ), y_range = ( - 1 , 1 ), z_scale = 1 , number_of_points = 121 , arrow_length = 0.1 ) plotting function to display shape and polarisation of LaserBeam object. Parameters: Name Type Description Default ax matplotlib.Axes Allows feeding in axes to plot over existing axes. The default is None. None x_range list[float,float] range in x over which to pol function. The default is [-1,1]. is y_range list[float,float] range in y over which to pol function. The default is [-1,1]. is z_scale float amount by which to scale the z axis up or down. None number_of_points int number of points to plot over. The default is 100. 100 arrow_length float sets the length of the polarisation arrows None Returns: Type Description matplitlib.Axes Returns axes for further work. View Source def plot ( self , ax = None , x_range = ( - 1 , 1 ) , y_range = ( - 1 , 1 ) , z_scale = 1 , number_of_points = 121 , arrow_length = 0 . 1 ) : \"\" \" plotting function to display shape and polarisation of LaserBeam object. Parameters ---------- ax : matplotlib.Axes, optional Allows feeding in axes to plot over existing axes. The default is None. x_range : list[float,float], optional range in x over which to pol function. The default is [-1,1]. y_range : list[float,float], optional range in y over which to pol function. The default is [-1,1]. z_scale : float, optional amount by which to scale the z axis up or down. number_of_points : int, optional number of points to plot over. The default is 100. arrow_length : float, optional sets the length of the polarisation arrows Returns ------- ax : matplitlib.Axes Returns axes for further work. \"\" \" n_sqrt = int(np.sqrt(number_of_points)) x_range = np.linspace(x_range[0],x_range[1],n_sqrt) y_range = np.linspace(y_range[0],y_range[1],n_sqrt) x_range, y_range = np.meshgrid(x_range,y_range) intensity_profile = self.intensity_profile(x_range,y_range) polarization_map = self.polarization_map(x_range,y_range) if ax is None: fig = plt.figure() ax = fig.add_subplot(projection = '3d') ax . plot_surface ( x_range , y_range , intensity_profile / z_scale , label = \"Intensity\" , alpha = 0 . 5 , color = 'lightblue' ) ax . quiver ( x_range . ravel () , y_range . ravel () , ( intensity_profile / z_scale ) . ravel () , polarization_map . T [ 0 ], polarization_map . T [ 1 ], np . zeros ( polarization_map . T [ 0 ]. shape ) , length = arrow_length , color = 'r' , label = \"Polarization\" ) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) plt . legend () return ax","title":"Laserbeam"},{"location":"reference/src/ExternalForces/LaserBeam/#module-srcexternalforceslaserbeam","text":"Child Class 'LaserBeam', for holding laser atributes View Source # -*- coding: utf-8 -*- \"\"\" Child Class 'LaserBeam', for holding laser atributes \"\"\" from typing import Callable import numpy as np import matplotlib.pyplot as plt from src.particleSystem.SystemObject import SystemObject class LaserBeam ( SystemObject ): \"\"\" Holds information about the laserbeam Attributes --------- intensity_profile : Callable[[float, float], float] Maps (x, y) to the scalar intensity profile of the beam. polarization_map : Callable[[float, float], np.ndarray] Maps (x, y) to the polarization profile of the beam represented as a Jones vector. \"\"\" def __init__ ( self , intensity_profile : Callable [[ float , float ], float ], polarization_map : Callable [[ float , float ], list [ np . complex_ , np . complex_ ]] ): \"\"\" Initializes a laserbeam based on input parameters The polarization profile represents the Jones vector. Its datatype is allowed to be complex in order to capture both linear and circular polarization states. Parameters ---------- intensity_profile : Callable[[float, float], float] A numpy compatible function that maps x, y to the scalar intensity profile of the beam. [W/m^2] polarization_map : Callable[[float, float], np.ndarray] A numpy compatible function that maps x, y to the polarization profile of the beam. [-] The polarisation vector should be a unit vector! Returns ------- None. \"\"\" self . intensity_profile = intensity_profile self . polarization_map = polarization_map def __str__ ( self ): print ( \"LaserBeam instantiated with attributes:\" ) print ( f \"polarisation_map: { self . polarization_map } \" ) print ( f \"intensity_profile: { self . intensity_profile } \" ) return \"\" def plot ( self , ax = None , x_range = ( - 1 , 1 ), y_range = ( - 1 , 1 ), z_scale = 1 , number_of_points = 121 , arrow_length = 0.1 ): \"\"\" plotting function to display shape and polarisation of LaserBeam object. Parameters ---------- ax : matplotlib.Axes, optional Allows feeding in axes to plot over existing axes. The default is None. x_range : list[float,float], optional range in x over which to pol function. The default is [-1,1]. y_range : list[float,float], optional range in y over which to pol function. The default is [-1,1]. z_scale : float, optional amount by which to scale the z axis up or down. number_of_points : int, optional number of points to plot over. The default is 100. arrow_length : float, optional sets the length of the polarisation arrows Returns ------- ax : matplitlib.Axes Returns axes for further work. \"\"\" n_sqrt = int ( np . sqrt ( number_of_points )) x_range = np . linspace ( x_range [ 0 ], x_range [ 1 ], n_sqrt ) y_range = np . linspace ( y_range [ 0 ], y_range [ 1 ], n_sqrt ) x_range , y_range = np . meshgrid ( x_range , y_range ) intensity_profile = self . intensity_profile ( x_range , y_range ) polarization_map = self . polarization_map ( x_range , y_range ) if ax is None : fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax . plot_surface ( x_range , y_range , intensity_profile / z_scale , label = \"Intensity\" , alpha = 0.5 , color = 'lightblue' ) ax . quiver ( x_range . ravel (), y_range . ravel (), ( intensity_profile / z_scale ) . ravel (), polarization_map . T [ 0 ], polarization_map . T [ 1 ], np . zeros ( polarization_map . T [ 0 ] . shape ), length = arrow_length , color = 'r' , label = \"Polarization\" ) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) plt . legend () return ax if __name__ == \"__main__\" : mu = 0 sigma = 0.5 LB = LaserBeam ( lambda x , y : np . exp ( - 1 / 2 * (( x - mu ) / sigma ) ** 2 - 1 / 2 * (( y - mu ) / sigma ) ** 2 ), lambda x , y : np . array ([ 1 + 0 j , 0 + 0 j ]) ) LB . plot ()","title":"Module src.ExternalForces.LaserBeam"},{"location":"reference/src/ExternalForces/LaserBeam/#classes","text":"","title":"Classes"},{"location":"reference/src/ExternalForces/LaserBeam/#laserbeam","text":"class LaserBeam ( intensity_profile : Callable [[ float , float ], float ], polarization_map : Callable [[ float , float ], list [ numpy . complex128 , numpy . complex128 ]] ) Holds information about the laserbeam","title":"LaserBeam"},{"location":"reference/src/ExternalForces/LaserBeam/#attributes","text":"intensity_profile : Callable[[float, float], float] Maps (x, y) to the scalar intensity profile of the beam. polarization_map : Callable[[float, float], np.ndarray] Maps (x, y) to the polarization profile of the beam represented as a Jones vector. View Source class LaserBeam(SystemObject): \"\"\" Holds information about the laserbeam Attributes --------- intensity_profile : Callable [[ float , float ] , float ] Maps (x , y) to the scalar intensity profile of the beam . polarization_map : Callable [[ float , float ] , np . ndarray ] Maps (x , y) to the polarization profile of the beam represented as a Jones vector . \"\"\" def __init__(self , intensity_profile: Callable [[ float , float ] , float ] , polarization_map: Callable [[ float , float ] , list [ np . complex_ , np . complex_ ]] ): \"\"\" Initializes a laserbeam based on input parameters The polarization profile represents the Jones vector . Its datatype is allowed to be complex in order to capture both linear and circular polarization states . Parameters ---------- intensity_profile : Callable [[ float , float ] , float ] A numpy compatible function that maps x , y to the scalar intensity profile of the beam . [ W/m^2 ] polarization_map : Callable [[ float , float ] , np . ndarray ] A numpy compatible function that maps x , y to the polarization profile of the beam . [ - ] The polarisation vector should be a unit vector! Returns ------- None . \"\"\" self . intensity_profile = intensity_profile self . polarization_map = polarization_map def __str__(self): print(\"LaserBeam instantiated with attributes:\") print(f\"polarisation_map: {self . polarization_map}\") print(f\"intensity_profile: {self . intensity_profile}\") return \"\" def plot(self , ax = None , x_range = ( - 1 , 1) , y_range = ( - 1 , 1) , z_scale = 1 , number_of_points = 121 , arrow_length = 0 . 1): \"\"\" plotting function to display shape and polarisation of LaserBeam object . Parameters ---------- ax : matplotlib . Axes , optional Allows feeding in axes to plot over existing axes . The default is None . x_range : list [ float , float ] , optional range in x over which to pol function . The default is [ - 1 , 1 ] . y_range : list [ float , float ] , optional range in y over which to pol function . The default is [ - 1 , 1 ] . z_scale : float , optional amount by which to scale the z axis up or down . number_of_points : int , optional number of points to plot over . The default is 100 . arrow_length : float , optional sets the length of the polarisation arrows Returns ------- ax : matplitlib . Axes Returns axes for further work . \"\"\" n_sqrt = int(np . sqrt(number_of_points)) x_range = np . linspace(x_range [ 0 ] , x_range [ 1 ] , n_sqrt) y_range = np . linspace(y_range [ 0 ] , y_range [ 1 ] , n_sqrt) x_range , y_range = np . meshgrid(x_range , y_range) intensity_profile = self . intensity_profile(x_range , y_range) polarization_map = self . polarization_map(x_range , y_range) if ax is None: fig = plt . figure() ax = fig . add_subplot(projection = '3d') ax . plot_surface(x_range , y_range , intensity_profile/z_scale , label = \"Intensity\" , alpha = 0 . 5 , color = 'lightblue') ax . quiver(x_range . ravel() , y_range . ravel() , (intensity_profile/z_scale) . ravel() , polarization_map . T [ 0 ] , polarization_map . T [ 1 ] , np . zeros(polarization_map . T [ 0 ] . shape) , length = arrow_length , color='r' , label = \"Polarization\") ax . set_xlabel('x') ax . set_ylabel('y') plt . legend() return ax","title":"Attributes"},{"location":"reference/src/ExternalForces/LaserBeam/#ancestors-in-mro","text":"src.particleSystem.SystemObject.SystemObject abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/src/ExternalForces/LaserBeam/#methods","text":"","title":"Methods"},{"location":"reference/src/ExternalForces/LaserBeam/#plot","text":"def plot ( self , ax = None , x_range = ( - 1 , 1 ), y_range = ( - 1 , 1 ), z_scale = 1 , number_of_points = 121 , arrow_length = 0.1 ) plotting function to display shape and polarisation of LaserBeam object. Parameters: Name Type Description Default ax matplotlib.Axes Allows feeding in axes to plot over existing axes. The default is None. None x_range list[float,float] range in x over which to pol function. The default is [-1,1]. is y_range list[float,float] range in y over which to pol function. The default is [-1,1]. is z_scale float amount by which to scale the z axis up or down. None number_of_points int number of points to plot over. The default is 100. 100 arrow_length float sets the length of the polarisation arrows None Returns: Type Description matplitlib.Axes Returns axes for further work. View Source def plot ( self , ax = None , x_range = ( - 1 , 1 ) , y_range = ( - 1 , 1 ) , z_scale = 1 , number_of_points = 121 , arrow_length = 0 . 1 ) : \"\" \" plotting function to display shape and polarisation of LaserBeam object. Parameters ---------- ax : matplotlib.Axes, optional Allows feeding in axes to plot over existing axes. The default is None. x_range : list[float,float], optional range in x over which to pol function. The default is [-1,1]. y_range : list[float,float], optional range in y over which to pol function. The default is [-1,1]. z_scale : float, optional amount by which to scale the z axis up or down. number_of_points : int, optional number of points to plot over. The default is 100. arrow_length : float, optional sets the length of the polarisation arrows Returns ------- ax : matplitlib.Axes Returns axes for further work. \"\" \" n_sqrt = int(np.sqrt(number_of_points)) x_range = np.linspace(x_range[0],x_range[1],n_sqrt) y_range = np.linspace(y_range[0],y_range[1],n_sqrt) x_range, y_range = np.meshgrid(x_range,y_range) intensity_profile = self.intensity_profile(x_range,y_range) polarization_map = self.polarization_map(x_range,y_range) if ax is None: fig = plt.figure() ax = fig.add_subplot(projection = '3d') ax . plot_surface ( x_range , y_range , intensity_profile / z_scale , label = \"Intensity\" , alpha = 0 . 5 , color = 'lightblue' ) ax . quiver ( x_range . ravel () , y_range . ravel () , ( intensity_profile / z_scale ) . ravel () , polarization_map . T [ 0 ], polarization_map . T [ 1 ], np . zeros ( polarization_map . T [ 0 ]. shape ) , length = arrow_length , color = 'r' , label = \"Polarization\" ) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) plt . legend () return ax","title":"plot"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/","text":"Module src.ExternalForces.OpticalForceCalculator Optical force calculation framework Created on Tue Nov 7 14:19:21 2023 View Source # -*- coding: utf-8 -*- \"\"\" Optical force calculation framework Created on Tue Nov 7 14:19:21 2023 @author: Mark Kalsbeek \"\"\" from enum import Enum from itertools import compress from collections import defaultdict import numpy as np import numpy.typing as npt import scipy as sp from scipy.constants import c from scipy.spatial.transform import Rotation from src.particleSystem.Force import Force import logging class OpticalForceCalculator ( Force ): \"\"\" Handles the calculation of forces arising from optical pressure \"\"\" def __init__ ( self , ParticleSystem , LaserBeam ): self . ParticleSystem = ParticleSystem self . PS = self . ParticleSystem #alias for convenience self . LaserBeam = LaserBeam if not hasattr ( self . ParticleSystem . particles [ 0 ], 'optical_type' ): raise AttributeError ( \"ParticleSystem does not have any optical properties set!\" ) super () . __init__ () return def __str__ ( self ): print ( \"OpticalForceCalculator object instantiated with attributes:\" ) print ( f \"ParticleSystem: \\n { self . ParticleSystem } \" ) print ( f \"LaserBeam: \\n { self . LaserBeam } \" ) return \"\" def force_value ( self ): \"\"\" Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" PS = self . ParticleSystem LB = self . LaserBeam area_vectors = PS . find_surface () area_vectors = np . nan_to_num ( area_vectors ) locations , _ = PS . x_v_current_3D forces = np . zeros ( locations . shape ) if not hasattr ( self , 'optical_type_mask' ): self . create_optical_type_mask () # ! Note ! This bakes in implicitly that the orientation of the light # vector is in z+ direction intensity_vectors = np . array ([[ 0 , 0 , LB . intensity_profile ( x , y )] for x , y , z in locations ]) polarisation_vectors = LB . polarization_map ( locations [:, 0 ], locations [:, 1 ]) for optical_type in self . optical_type_mask . keys (): if optical_type == ParticleOpticalPropertyType . SPECULAR : mask = self . optical_type_mask [ optical_type ] forces [ mask ] = self . calculate_specular_force ( area_vectors [ mask ], intensity_vectors [ mask ]) elif optical_type == ParticleOpticalPropertyType . AXICONGRATING : mask = self . optical_type_mask [ optical_type ] filtered_particles = compress ( PS . particles , mask ) axicon_angle = [ p . axicon_angle for p in filtered_particles ] forces [ mask ] = self . calculate_axicongrating_force ( area_vectors [ mask ], intensity_vectors [ mask ], axicon_angle ) elif optical_type == ParticleOpticalPropertyType . ARBITRARY_PHC : mask = self . optical_type_mask [ optical_type ] if not hasattr ( self , 'optical_interpolators' ): self . create_phc_map ( mask ) forces [ mask ] = self . calculate_arbitrary_phc_force ( area_vectors [ mask ], intensity_vectors [ mask ], polarisation_vectors [ mask ], self . optical_interpolators ) return forces def create_phc_map ( self , mask ): filtered_particles = compress ( self . PS . particles , mask ) original_indices = [ i for i , m in enumerate ( mask ) if m ] self . optical_interpolators = [] # let's check if it's one or multiple PHC's self . phc_dict = defaultdict ( list ) for i , p in enumerate ( filtered_particles ): self . optical_interpolators . append ( p . optical_interpolator ) #build dict of mask entries and which PhC they belong to. self . phc_dict [ p . optical_interpolator ] . append ( original_indices [ i ]) for key in self . phc_dict . keys (): self . phc_dict [ key ] = self . create_submask ( self . phc_dict [ key ]) def create_submask ( self , indice_list ): length = len ( self . PS . particles ) submask = np . zeros ( length , dtype = bool ) for i in indice_list : submask [ i ] = True return submask def calculate_specular_force ( self , area_vectors , intensity_vectors ): \"\"\" Calculates forces for particles of optical type 'specular' !!! TODO implement reflectivity coefficient Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # First we compute the incident power on the particle areas abs_area_vectors = area_vectors [:, 2 ] # assumes z+ poynting vector abs_intensity_vectors = intensity_vectors [:, 2 ] # assumes z+ poynting vector incident_power = abs_area_vectors * abs_intensity_vectors # To get the direction of the forces we need to normalise the area # vectors. For convenience we roll that into the force calculation of # dF = dP/c. We double it because the PhC is acting in reflection norms = np . linalg . norm ( area_vectors , axis = 1 ) forces = area_vectors . copy () for i in range ( 3 ): forces [:, i ] *= 2 * incident_power / ( c * norms ) return forces def calculate_axicongrating_force ( self , area_vectors , intensity_vectors , axicon_angle ): \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors axicon_angle : npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" rotation_super_matrix = sp . linalg . block_diag ( * axicon_angle ) forces = self . calculate_specular_force ( area_vectors , intensity_vectors ) forces = rotation_super_matrix . dot ( np . hstack ( forces ) . T ) forces = np . reshape ( forces , [ int ( forces . shape [ 0 ] / 3 ), 3 ]) # The forces need to be scaled to account for the fact that # |[1,1]| != |[1]|+|[1]| # We don't have acces to the angle, but we can make use of the cosine # rule: cos(alpha) = A.dot(B) / (|A| |B|) to get the angle between # z+ and the line of action of the force. unit_z = np . array ([ 0 , 0 , 1 ]) scaling_factor = np . matmul ( axicon_angle , unit_z ) . dot ( unit_z ) for i in range ( 3 ): forces [:, i ] *= scaling_factor return forces def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ): \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. intensity_vectors : npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # Convert area vector to spherical coordinates result = compute_spherical_coordinates ( area_vectors , polarisation_vectors ) polar_angles , azimuth_angles , polarisation_angles = result # Switch reference frame; made easier becasue we a coming from [0,0,1] # azimuth_angles += np.pi # azimuth_angles %= 2*np.pi # Condition them for the interpolator: wrapped_coordinates = wrap_spherical_coordinates ( polar_angles , azimuth_angles , polarisation_angles ) polar_angles , azimuth_angles , polarisation_angles = wrapped_coordinates incoming_ray = np . vstack (( polar_angles , azimuth_angles , polarisation_angles )) . T # Find directions of outgoing rays # Interpolator([polar_in, azimuth_in, polarization_in])->[polar_out, azimuth_out, magnitude] reflected_ray = np . zeros ( incoming_ray . shape ) for phc in self . phc_dict : submask = self . phc_dict [ phc ] reflected_ray [ submask ] = phc ( incoming_ray [ submask ]) # reflected_ray = [interp(incoming_ray[i]) # reflected_ray = [interp(tuple(incoming_ray[i])) # for i, interp # in enumerate(optical_interpolators)] # [polar_out, azimuth_out, magnitude] polar_angles_out , azimuth_angles_out , magnitudes = np . array ( reflected_ray ) . T # Switch reference frame again; made easier becasue we are going to [0,0,1] polar_angles_out += polar_angles reflected_vectors = spherical_to_cartesian ( polar_angles_out , azimuth_angles_out , magnitudes ) # Compute the incident power on the particle areas abs_area_vectors = area_vectors [:, 2 ] # assumes z+ poynting vector abs_intensity_vectors = intensity_vectors [:, 2 ] # assumes z+ poynting vector incident_power = abs_area_vectors * abs_intensity_vectors scattered_power = reflected_vectors * incident_power [:, np . newaxis ] net_power = np . hstack (( np . zeros (( incident_power . shape [ 0 ], 2 )), incident_power [:, np . newaxis ])) + scattered_power forces = net_power / c return forces def create_optical_type_mask ( self ): \"\"\" loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises ------ AttributeError Raises error when particles have no optical type set. \"\"\" optical_type_list = [] error_index_list = [] for i , particle in enumerate ( self . ParticleSystem . particles ): if hasattr ( particle , 'optical_type' ): optical_type_list . append ( particle . optical_type ) else : error_index_list . append ( i ) if len ( error_index_list ) > 0 : raise AttributeError ( \"All particles should have an optical type\" \" set prior to calculation of optical forces.\" \" Currently the particles with indices\" f \" { error_index_list } have no property set\" ) optical_type_list = np . array ( optical_type_list ) self . optical_type_mask = {} for optical_type in ParticleOpticalPropertyType : mask = optical_type_list == optical_type if sum ( mask ) > 0 : self . optical_type_mask [ optical_type ] = mask def calculate_stability_coefficients ( self , displacement_range = [ 0.1 , 5 ]): \"\"\" Calculates the stability coefficients for the particle system Parameters ---------- displacement_range : list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. Returns ------- stability_matrix : npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg \"\"\" q , alpha = displacement_range displacement_vectors = np . array ([[ q , 0 , 0 , 0 , 0 , 0 ], [ 0 , q , 0 , 0 , 0 , 0 ], [ 0 , 0 , q , 0 , 0 , 0 ], [ 0 , 0 , 0 , alpha , 0 , 0 ], [ 0 , 0 , 0 , 0 , alpha , 0 ], [ 0 , 0 , 0 , 0 , 0 , alpha ]]) jacobian = np . zeros (( 6 , 6 )) for i , vector in enumerate ( displacement_vectors ): jacobian [:, i ] = np . hstack ( self . calculate_force_gradient ( vector )) return jacobian def calculate_force_gradient ( self , displacement_vector : npt . ArrayLike ): \"\"\" Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters ---------- displacement_vector : npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero Raises ------ AttributeError Raises error if multiple displacements are supplied. Returns ------- k_trans : list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] k_rot : TYPE lenght 3 list of translational reaction coefficients [dM_x/dx__i, dM_y/dx__i, dM_z/dx__i] \"\"\" displacement = displacement_vector [ displacement_vector != 0 ] if len ( displacement ) > 1 : raise AttributeError ( \"Expected vector with only one nonzero value,\" f \"instead got { displacement_vector } \" ) original = self . calculate_restoring_forces () self . PS . displace ( displacement_vector ) reaction = self . calculate_restoring_forces () self . PS . un_displace () k_trans = ( reaction [ 0 ] - original [ 0 ]) / displacement k_rot = ( reaction [ 1 ] - original [ 1 ]) / displacement return k_trans , k_rot def calculate_restoring_forces ( self , forces : npt . ArrayLike = None ): \"\"\" calculates net forces and moments around the center of mass Parameters ---------- forces : npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. Returns ------- net_force : npt.ArrayLike Net force on center of mass. net_moments : npt.ArrayLike Net moments around center of mass. \"\"\" PS = self . ParticleSystem if type ( forces ) == type ( None ): forces = self . force_value () net_force = np . sum ( forces , axis = 0 ) COM = PS . calculate_center_of_mass () locations , _ = PS . x_v_current_3D moment_arms = PS . translate_mesh ( locations , - COM ) # note: this doesn't displace the PS, just applies a transformation on the 'locations' variable moments = np . cross ( moment_arms , forces ) net_moments = np . sum ( moments , axis = 0 ) return net_force , net_moments class ParticleOpticalPropertyType ( Enum ): \"\"\" Enumeration representing the various types of optical properties for the Particles Attributes ---------- SPECULAR : str Indicates that the particle reflects light specularly ARBITRARY_PHC : str Indicates that the particle represents an arbitrary photonic crystal NOTE: scipy.interpolate.interpnd.LinearNDInterpolator has to be set on particle.optical_interpolator(elevation, azimuth, polarisation_angle) ->(elevation, azimuth, magnitude) AXICONGRATING : str Indicates that the particle scatter light like a cone NOTE: Directing angle should be set in the format of a rotation matrix for the relevant particles that represents [rx, ry] rotations of area vector on property particle.axicon_angle \"\"\" SPECULAR = \"specular\" AXICONGRATING = \"axicongrating\" ARBITRARY_PHC = \"ARBITRARY_PHC\" vectorized_optical_type_retriever = np . vectorize ( lambda p : p . optical_type ) def compute_spherical_coordinates ( area_vectors : npt . NDArray , polarisation_vectors : npt . NDArray ) -> ( npt . NDArray , npt . NDArray , npt . NDArray ): \"\"\" Computes the polar angles, azimuth angles, and polarisation angles of the incoming ray and its polarisation relative to the orientation of area elements represented by area vectors. Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 2) representing the polarisation vectors of laser beams for n particles. Returns ------- polar_angles : npt.NDArray An array of polar angles of the area vectors relative to the z-axis [rad]. azimuth_angles : npt.NDArray An array of azimuth angles of the area vectors in the xy-plane [rad]. polarisation_angles : npt.NDArray An array of angles between the polarisation vectors and their projection onto the plane orthogonal to the area vectors [rad]. \"\"\" # Normalize the area vectors norm_area_vectors = area_vectors / np . linalg . norm ( area_vectors , axis = 1 )[:, np . newaxis ] # Compute polar angles using the dot product between area vectors and the z-axis polar_angles = np . arccos ( norm_area_vectors [:, 2 ]) # Compute azimuth angles azimuth_angles = np . arctan2 ( norm_area_vectors [:, 1 ], norm_area_vectors [:, 0 ]) # Compute the polarisation angle in cartesian space: polarisation_angles = np . arccos ( polarisation_vectors [:, 0 ]) return polar_angles , azimuth_angles , polarisation_angles def spherical_to_cartesian ( polar_angles : npt . NDArray , azimuth_angles : npt . NDArray , magnitudes : npt . NDArray ) -> npt . NDArray : \"\"\" Converts spherical coordinates back to Cartesian coordinates in the global frame, using the area vectors to define the local reference frames. Scales the resulting vectors by the magnitudes. Parameters ---------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes to scale the intensity of the resulting rays. area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles, used to define the local reference frames. Returns ------- cartesian_vectors : npt.NDArray An array of shape (n_particles, 3) representing the resulting Cartesian vectors in the global frame. \"\"\" # Convert spherical to Cartesian coordinates in the local frame x = magnitudes * np . sin ( polar_angles ) * np . cos ( azimuth_angles ) y = magnitudes * np . sin ( polar_angles ) * np . sin ( azimuth_angles ) z = magnitudes * np . cos ( polar_angles ) cartesian_vectors = np . vstack (( x , y , z )) . T return cartesian_vectors def cartesian_to_sphereical ( vectors : npt . NDArray ) -> npt . NDArray : \"\"\" Converts a set of vectors from cartesian to spherical coordinates Parameters ---------- vectors : npt.NDArray An array of shape (n_particles, 3) representing the vectors to convert. Returns ------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes of the vectors. \"\"\" x , y , z = vectors [:, 0 ], vectors [:, 1 ], vectors [:, 2 ] magnitudes = np . linalg . norm ( vectors , axis = 1 ) polar_angles = np . arccos ( z / magnitudes ) azimuth_angles = np . arctan2 ( y , x ) return polar_angles , azimuth_angles , magnitudes def wrap_spherical_coordinates ( theta : npt . NDArray , phi : npt . NDArray , pol : npt . NDArray = None ): \"\"\" wraps points in spherical coordinates to always stay within the interpolators defined range Parameters ---------- theta : npt.NDArray polar angle [rad] phi : npt.NDArray azimuthal angle [rad] pol : npt.NDArray polarisation angle [rad] Returns ------- theta : npt.NDArray polar angle phi : npt.NDArray azimuthal angle pol : npt.NDArray polarisation angle \"\"\" phi [ theta > np . pi ] += np . pi theta [ theta > np . pi ] = np . pi - theta [ theta > np . pi ] % np . pi phi [ theta < 0 ] += np . pi theta [ theta < 0 ] *=- 1 phi %= 2 * np . pi phi [ abs ( phi - 2 * np . pi ) < 1e-5 ] = 0 # wraps values that are _almost_ 2*np.pi if np . any ( pol != None ): x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) pol = np . arctan ( y / x ) return theta , phi , pol else : return theta , phi # quick test # !!! todo move to testing file theta = np . random . random ( 100 ) * 3 * np . pi - np . pi phi = np . random . random ( 100 ) * 3 * np . pi - np . pi pol = np . random . random ( 100 ) * 3 * np . pi - np . pi def test_wrap_spherical_coordinates ( dat ): mags = np . ones ( dat [ 0 ] . shape ) t1 = spherical_to_cartesian ( * wrap_spherical_coordinates ( * dat )[: 2 ], mags ) t2 = spherical_to_cartesian ( * dat [: 2 ], mags ) return ( t1 == t2 ) . all () test_wrap_spherical_coordinates (( theta , phi , pol )) if __name__ == \"__main__\" : from code_Validation.saddle_form import saddle_form from src.ExternalForces.LaserBeam import LaserBeam import matplotlib.pyplot as plt PS = saddle_form . instantiate_ps () #PS.stress_self() #for i in range(10): PS.simulate() for particle in PS . particles : particle . x [ 2 ] = 0 I_0 = 100e9 / ( 10 * 10 ) mu_x = 5 mu_y = 5 sigma = 5 LB = LaserBeam ( lambda x , y : I_0 * np . exp ( - 1 / 2 * (( x - mu_x ) / sigma ) ** 2 - 1 / 2 * (( y - mu_y ) / sigma ) ** 2 ), lambda x , y : [ 0 , 1 ]) LB = LaserBeam ( lambda x , y : np . ones ( x . shape ) * I_0 , lambda x , y : [ 0 , 1 ]) # One half of example will be 45 deg axicon angle directed towards (5,5) # other half will be specular reflection rots = [] for particle in PS . particles : particle . optical_type = ParticleOpticalPropertyType . SPECULAR if ( particle . x [ 0 ] - 5 ) ** 2 + ( particle . x [ 1 ] - 5 ) ** 2 >= 3 ** 2 : roty = 45 rotz = np . rad2deg ( np . arctan2 (( particle . x [ 1 ] - 5 ), ( particle . x [ 0 ] - 4.999 ))) particle . optical_type = ParticleOpticalPropertyType . AXICONGRATING #particle.axicon_angle = Rotation.from_euler('yz', [roty, rotz], degrees=True).as_matrix() particle . axicon_angle = Rotation . from_euler ( 'yz' , [ roty , rotz ], degrees = True ) . as_matrix () rots . append (( roty , rotz % 360 )) OFC = OpticalForceCalculator ( PS , LB ) forces = OFC . force_value () ax = PS . plot () points , _ = PS . x_v_current_3D x , y , z = points [:, 0 ], points [:, 1 ], points [:, 2 ] a_u = forces [:, 0 ] a_v = forces [:, 1 ] a_w = forces [:, 2 ] ax . scatter ( x , y , z ) ax . quiver ( x , y , z , a_u , a_v , a_w , length = 0.1 ) ax . set_box_aspect ([ 1 , 1 , 1 ]) ax . set_zlim ( - 5 , 5 ) #ax.set_zscale('symlog') #ax2 = fig.add_subplot(projection='3d') #LB.plot(ax2, x_range = [0,10], y_range=[0,10]) Variables c vectorized_optical_type_retriever Functions cartesian_to_sphereical def cartesian_to_sphereical ( vectors : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] ) -> numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] Converts a set of vectors from cartesian to spherical coordinates Parameters: Name Type Description Default vectors npt.NDArray An array of shape (n_particles, 3) representing the vectors to convert. None Returns: Type Description npt.NDArray An array of polar angles in radians. View Source def cartesian_to_sphereical ( vectors : npt . NDArray ) -> npt . NDArray : \"\"\" Converts a set of vectors from cartesian to spherical coordinates Parameters ---------- vectors : npt.NDArray An array of shape (n_particles, 3) representing the vectors to convert. Returns ------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes of the vectors. \"\"\" x , y , z = vectors [ : , 0 ], vectors [ : , 1 ], vectors [ : , 2 ] magnitudes = np . linalg . norm ( vectors , axis = 1 ) polar_angles = np . arccos ( z / magnitudes ) azimuth_angles = np . arctan2 ( y , x ) return polar_angles , azimuth_angles , magnitudes compute_spherical_coordinates def compute_spherical_coordinates ( area_vectors : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], polarisation_vectors : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] ) -> ( numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]]) Computes the polar angles, azimuth angles, and polarisation angles of the incoming ray and its polarisation relative to the orientation of area elements represented by area vectors. Parameters: Name Type Description Default area_vectors npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. None polarisation_vectors npt.NDArray An array of shape (n_particles, 2) representing the polarisation vectors of laser beams for n particles. None Returns: Type Description npt.NDArray An array of polar angles of the area vectors relative to the z-axis [rad]. View Source def compute_spherical_coordinates ( area_vectors : npt . NDArray , polarisation_vectors : npt . NDArray ) -> ( npt . NDArray , npt . NDArray , npt . NDArray ) : \"\"\" Computes the polar angles, azimuth angles, and polarisation angles of the incoming ray and its polarisation relative to the orientation of area elements represented by area vectors. Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 2) representing the polarisation vectors of laser beams for n particles. Returns ------- polar_angles : npt.NDArray An array of polar angles of the area vectors relative to the z-axis [rad]. azimuth_angles : npt.NDArray An array of azimuth angles of the area vectors in the xy-plane [rad]. polarisation_angles : npt.NDArray An array of angles between the polarisation vectors and their projection onto the plane orthogonal to the area vectors [rad]. \"\"\" # Normalize the area vectors norm_area_vectors = area_vectors / np . linalg . norm ( area_vectors , axis = 1 ) [ :, np.newaxis ] # Compute polar angles using the dot product between area vectors and the z - axis polar_angles = np . arccos ( norm_area_vectors [ :, 2 ] ) # Compute azimuth angles azimuth_angles = np . arctan2 ( norm_area_vectors [ :,1 ] , norm_area_vectors [ :,0 ] ) # Compute the polarisation angle in cartesian space : polarisation_angles = np . arccos ( polarisation_vectors [ :,0 ] ) return polar_angles , azimuth_angles , polarisation_angles spherical_to_cartesian def spherical_to_cartesian ( polar_angles : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], azimuth_angles : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], magnitudes : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] ) -> numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] Converts spherical coordinates back to Cartesian coordinates in the global frame, using the area vectors to define the local reference frames. Scales the resulting vectors by the magnitudes. Parameters: Name Type Description Default polar_angles npt.NDArray An array of polar angles in radians. None azimuth_angles npt.NDArray An array of azimuth angles in radians. None magnitudes npt.NDArray An array of magnitudes to scale the intensity of the resulting rays. None area_vectors npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles, used to define the local reference frames. None Returns: Type Description npt.NDArray An array of shape (n_particles, 3) representing the resulting Cartesian vectors in the global frame. View Source def spherical_to_cartesian ( polar_angles : npt . NDArray , azimuth_angles : npt . NDArray , magnitudes : npt . NDArray ) -> npt . NDArray : \"\"\" Converts spherical coordinates back to Cartesian coordinates in the global frame, using the area vectors to define the local reference frames. Scales the resulting vectors by the magnitudes. Parameters ---------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes to scale the intensity of the resulting rays. area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles, used to define the local reference frames. Returns ------- cartesian_vectors : npt.NDArray An array of shape (n_particles, 3) representing the resulting Cartesian vectors in the global frame. \"\"\" # Convert spherical to Cartesian coordinates in the local frame x = magnitudes * np . sin ( polar_angles ) * np . cos ( azimuth_angles ) y = magnitudes * np . sin ( polar_angles ) * np . sin ( azimuth_angles ) z = magnitudes * np . cos ( polar_angles ) cartesian_vectors = np . vstack (( x , y , z )). T return cartesian_vectors wrap_spherical_coordinates def wrap_spherical_coordinates ( theta : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], phi : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], pol : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] = None ) wraps points in spherical coordinates to always stay within the interpolators defined range Parameters: Name Type Description Default theta npt.NDArray polar angle [rad] None phi npt.NDArray azimuthal angle [rad] None pol npt.NDArray polarisation angle [rad] None Returns: Type Description npt.NDArray polar angle View Source def wrap_spherical_coordinates ( theta : npt . NDArray , phi : npt . NDArray , pol : npt . NDArray = None ) : \"\"\" wraps points in spherical coordinates to always stay within the interpolators defined range Parameters ---------- theta : npt.NDArray polar angle [rad] phi : npt.NDArray azimuthal angle [rad] pol : npt.NDArray polarisation angle [rad] Returns ------- theta : npt.NDArray polar angle phi : npt.NDArray azimuthal angle pol : npt.NDArray polarisation angle \"\"\" phi [ theta>np.pi ] += np . pi theta [ theta>np.pi ]= np . pi - theta [ theta>np.pi ]% np . pi phi [ theta<0 ] += np . pi theta [ theta<0 ] *=- 1 phi %= 2 * np . pi phi [ abs(phi-2*np.pi)<1e-5 ]= 0 # wraps values that are _almost_ 2 * np . pi if np . any ( pol != None ) : x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) pol = np . arctan ( y / x ) return theta , phi , pol else : return theta , phi # quick test # !!! todo move to testing file theta = np . random . random ( 100 ) * 3 * np . pi - np . pi phi = np . random . random ( 100 ) * 3 * np . pi - np . pi pol = np . random . random ( 100 ) * 3 * np . pi - np . pi def test_wrap_spherical_coordinates ( dat ) : mags = np . ones ( dat [ 0 ] . shape ) t1 = spherical_to_cartesian ( * wrap_spherical_coordinates ( * dat ) [ :2 ] , mags ) t2 = spherical_to_cartesian ( * dat [ :2 ] , mags ) return ( t1 == t2 ). all () test_wrap_spherical_coordinates (( theta , phi , pol )) Classes OpticalForceCalculator class OpticalForceCalculator ( ParticleSystem , LaserBeam ) Handles the calculation of forces arising from optical pressure View Source class OpticalForceCalculator ( Force ) : \"\"\" Handles the calculation of forces arising from optical pressure \"\"\" def __init__ ( self , ParticleSystem , LaserBeam ) : self . ParticleSystem = ParticleSystem self . PS = self . ParticleSystem #alias for convenience self . LaserBeam = LaserBeam if not hasattr ( self . ParticleSystem . particles [ 0 ] , 'optical_type' ) : raise AttributeError ( \"ParticleSystem does not have any optical properties set!\" ) super (). __init__ () return def __str__ ( self ) : print ( \"OpticalForceCalculator object instantiated with attributes:\" ) print ( f \"ParticleSystem: \\n {self.ParticleSystem}\" ) print ( f \"LaserBeam: \\n {self.LaserBeam}\" ) return \"\" def force_value ( self ) : \"\"\" Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" PS = self . ParticleSystem LB = self . LaserBeam area_vectors = PS . find_surface () area_vectors = np . nan_to_num ( area_vectors ) locations , _ = PS . x_v_current_3D forces = np . zeros ( locations . shape ) if not hasattr ( self , 'optical_type_mask' ) : self . create_optical_type_mask () # ! Note ! This bakes in implicitly that the orientation of the light # vector is in z + direction intensity_vectors = np . array ( [ [0,0,LB.intensity_profile(x,y) ] for x , y , z in locations ] ) polarisation_vectors = LB . polarization_map ( locations [ :,0 ] , locations [ :,1 ] ) for optical_type in self . optical_type_mask . keys () : if optical_type == ParticleOpticalPropertyType . SPECULAR : mask = self . optical_type_mask [ optical_type ] forces [ mask ] = self . calculate_specular_force ( area_vectors [ mask ] , intensity_vectors [ mask ] ) elif optical_type == ParticleOpticalPropertyType . AXICONGRATING : mask = self . optical_type_mask [ optical_type ] filtered_particles = compress ( PS . particles , mask ) axicon_angle = [ p.axicon_angle for p in filtered_particles ] forces [ mask ] = self . calculate_axicongrating_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , axicon_angle ) elif optical_type == ParticleOpticalPropertyType . ARBITRARY_PHC : mask = self . optical_type_mask [ optical_type ] if not hasattr ( self , 'optical_interpolators' ) : self . create_phc_map ( mask ) forces [ mask ] = self . calculate_arbitrary_phc_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , polarisation_vectors [ mask ] , self . optical_interpolators ) return forces def create_phc_map ( self , mask ) : filtered_particles = compress ( self . PS . particles , mask ) original_indices = [ i for i, m in enumerate(mask) if m ] self . optical_interpolators = [] # let 's check if it' s one or multiple PHC 's self.phc_dict = defaultdict(list) for i, p in enumerate(filtered_particles): self.optical_interpolators.append(p.optical_interpolator) #build dict of mask entries and which PhC they belong to. self.phc_dict[p.optical_interpolator].append(original_indices[i]) for key in self.phc_dict.keys(): self.phc_dict[key] = self.create_submask(self.phc_dict[key]) def create_submask(self, indice_list): length = len(self.PS.particles) submask = np.zeros(length, dtype=bool) for i in indice_list: submask[i] = True return submask def calculate_specular_force(self, area_vectors, intensity_vectors): \"\"\" Calculates forces for particles of optical type ' specular ' !!! TODO implement reflectivity coefficient Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # First we compute the incident power on the particle areas abs_area_vectors = area_vectors[:,2] # assumes z+ poynting vector abs_intensity_vectors = intensity_vectors[:,2] # assumes z+ poynting vector incident_power = abs_area_vectors * abs_intensity_vectors # To get the direction of the forces we need to normalise the area # vectors. For convenience we roll that into the force calculation of # dF = dP/c. We double it because the PhC is acting in reflection norms = np.linalg.norm(area_vectors, axis=1) forces = area_vectors.copy() for i in range(3): forces[:,i] *= 2*incident_power / (c*norms) return forces def calculate_axicongrating_force(self, area_vectors, intensity_vectors, axicon_angle): \"\"\" Calculates forces for particles of optical type ' axicon grating ' Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors axicon_angle : npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" rotation_super_matrix = sp.linalg.block_diag(*axicon_angle) forces = self.calculate_specular_force(area_vectors, intensity_vectors) forces = rotation_super_matrix.dot(np.hstack(forces).T) forces = np.reshape(forces, [int(forces.shape[0]/3),3]) # The forces need to be scaled to account for the fact that # |[1,1]| != |[1]|+|[1]| # We don' t have acces to the angle , but we can make use of the cosine # rule : cos ( alpha ) = A . dot ( B ) / ( | A | | B | ) to get the angle between # z + and the line of action of the force . unit_z = np . array ( [ 0,0,1 ] ) scaling_factor = np . matmul ( axicon_angle , unit_z ). dot ( unit_z ) for i in range ( 3 ) : forces [ :,i ]*= scaling_factor return forces def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ) : \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. intensity_vectors : npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # Convert area vector to spherical coordinates result = compute_spherical_coordinates ( area_vectors , polarisation_vectors ) polar_angles , azimuth_angles , polarisation_angles = result # Switch reference frame ; made easier becasue we a coming from [ 0,0,1 ] # azimuth_angles += np . pi # azimuth_angles %= 2 * np . pi # Condition them for the interpolator : wrapped_coordinates = wrap_spherical_coordinates ( polar_angles , azimuth_angles , polarisation_angles ) polar_angles , azimuth_angles , polarisation_angles = wrapped_coordinates incoming_ray = np . vstack (( polar_angles , azimuth_angles , polarisation_angles )). T # Find directions of outgoing rays # Interpolator ( [ polar_in, azimuth_in, polarization_in ] ) ->[ polar_out, azimuth_out, magnitude ] reflected_ray = np . zeros ( incoming_ray . shape ) for phc in self . phc_dict : submask = self . phc_dict [ phc ] reflected_ray [ submask ] = phc ( incoming_ray [ submask ] ) # reflected_ray = [ interp(incoming_ray[i ] ) # reflected_ray = [ interp(tuple(incoming_ray[i ] )) # for i , interp # in enumerate ( optical_interpolators ) ] # [ polar_out, azimuth_out, magnitude ] polar_angles_out , azimuth_angles_out , magnitudes = np . array ( reflected_ray ). T # Switch reference frame again ; made easier becasue we are going to [ 0,0,1 ] polar_angles_out += polar_angles reflected_vectors = spherical_to_cartesian ( polar_angles_out , azimuth_angles_out , magnitudes ) # Compute the incident power on the particle areas abs_area_vectors = area_vectors [ :,2 ] # assumes z + poynting vector abs_intensity_vectors = intensity_vectors [ :,2 ] # assumes z + poynting vector incident_power = abs_area_vectors * abs_intensity_vectors scattered_power = reflected_vectors * incident_power [ :,np.newaxis ] net_power = np . hstack (( np . zeros (( incident_power . shape [ 0 ] , 2 )), incident_power [ :,np.newaxis ] )) + scattered_power forces = net_power / c return forces def create_optical_type_mask ( self ) : \"\"\" loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises ------ AttributeError Raises error when particles have no optical type set. \"\"\" optical_type_list = [] error_index_list = [] for i , particle in enumerate ( self . ParticleSystem . particles ) : if hasattr ( particle , 'optical_type' ) : optical_type_list . append ( particle . optical_type ) else : error_index_list . append ( i ) if len ( error_index_list ) > 0 : raise AttributeError ( \"All particles should have an optical type\" \" set prior to calculation of optical forces.\" \" Currently the particles with indices\" f \" {error_index_list} have no property set\" ) optical_type_list = np . array ( optical_type_list ) self . optical_type_mask = {} for optical_type in ParticleOpticalPropertyType : mask = optical_type_list == optical_type if sum ( mask ) > 0 : self . optical_type_mask [ optical_type ] = mask def calculate_stability_coefficients ( self , displacement_range = [ 0.1, 5 ] ) : \"\"\" Calculates the stability coefficients for the particle system Parameters ---------- displacement_range : list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. Returns ------- stability_matrix : npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg \"\"\" q , alpha = displacement_range displacement_vectors = np . array ( [ [q,0,0,0,0,0 ] , [ 0,q,0,0,0,0 ] , [ 0,0,q,0,0,0 ] , [ 0,0,0,alpha,0,0 ] , [ 0,0,0,0,alpha,0 ] , [ 0,0,0,0,0,alpha ] ] ) jacobian = np . zeros (( 6 , 6 )) for i , vector in enumerate ( displacement_vectors ) : jacobian [ :,i ] = np . hstack ( self . calculate_force_gradient ( vector )) return jacobian def calculate_force_gradient ( self , displacement_vector : npt . ArrayLike ) : \"\"\" Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters ---------- displacement_vector : npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero Raises ------ AttributeError Raises error if multiple displacements are supplied. Returns ------- k_trans : list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] k_rot : TYPE lenght 3 list of translational reaction coefficients [dM_x/dx__i, dM_y/dx__i, dM_z/dx__i] \"\"\" displacement = displacement_vector [ displacement_vector !=0 ] if len ( displacement ) > 1 : raise AttributeError ( \"Expected vector with only one nonzero value,\" f \"instead got {displacement_vector}\" ) original = self . calculate_restoring_forces () self . PS . displace ( displacement_vector ) reaction = self . calculate_restoring_forces () self . PS . un_displace () k_trans = ( reaction [ 0 ] - original [ 0 ] ) / displacement k_rot = ( reaction [ 1 ] - original [ 1 ] ) / displacement return k_trans , k_rot def calculate_restoring_forces ( self , forces : npt . ArrayLike = None ) : \"\"\" calculates net forces and moments around the center of mass Parameters ---------- forces : npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. Returns ------- net_force : npt.ArrayLike Net force on center of mass. net_moments : npt.ArrayLike Net moments around center of mass. \"\"\" PS = self . ParticleSystem if type ( forces ) == type ( None ) : forces = self . force_value () net_force = np . sum ( forces , axis = 0 ) COM = PS . calculate_center_of_mass () locations , _ = PS . x_v_current_3D moment_arms = PS . translate_mesh ( locations , - COM ) # note : this doesn 't displace the PS, just applies a transformation on the ' locations ' variable moments = np . cross ( moment_arms , forces ) net_moments = np . sum ( moments , axis = 0 ) return net_force , net_moments Ancestors (in MRO) src.particleSystem.Force.Force src.particleSystem.SystemObject.SystemObject abc.ABC Methods calculate_arbitrary_phc_force def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ) Calculates forces for particles of optical type 'axicon grating' Parameters: Name Type Description Default area_vectors npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. None intensity_vectors npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. None polarisation_vectors npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. None Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ) : \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. intensity_vectors : npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # Convert area vector to spherical coordinates result = compute_spherical_coordinates ( area_vectors , polarisation_vectors ) polar_angles , azimuth_angles , polarisation_angles = result # Switch reference frame ; made easier becasue we a coming from [ 0,0,1 ] # azimuth_angles += np . pi # azimuth_angles %= 2 * np . pi # Condition them for the interpolator : wrapped_coordinates = wrap_spherical_coordinates ( polar_angles , azimuth_angles , polarisation_angles ) polar_angles , azimuth_angles , polarisation_angles = wrapped_coordinates incoming_ray = np . vstack (( polar_angles , azimuth_angles , polarisation_angles )). T # Find directions of outgoing rays # Interpolator ( [ polar_in, azimuth_in, polarization_in ] ) ->[ polar_out, azimuth_out, magnitude ] reflected_ray = np . zeros ( incoming_ray . shape ) for phc in self . phc_dict : submask = self . phc_dict [ phc ] reflected_ray [ submask ] = phc ( incoming_ray [ submask ] ) # reflected_ray = [ interp(incoming_ray[i ] ) # reflected_ray = [ interp(tuple(incoming_ray[i ] )) # for i , interp # in enumerate ( optical_interpolators ) ] # [ polar_out, azimuth_out, magnitude ] polar_angles_out , azimuth_angles_out , magnitudes = np . array ( reflected_ray ). T # Switch reference frame again ; made easier becasue we are going to [ 0,0,1 ] polar_angles_out += polar_angles reflected_vectors = spherical_to_cartesian ( polar_angles_out , azimuth_angles_out , magnitudes ) # Compute the incident power on the particle areas abs_area_vectors = area_vectors [ :,2 ] # assumes z + poynting vector abs_intensity_vectors = intensity_vectors [ :,2 ] # assumes z + poynting vector incident_power = abs_area_vectors * abs_intensity_vectors scattered_power = reflected_vectors * incident_power [ :,np.newaxis ] net_power = np . hstack (( np . zeros (( incident_power . shape [ 0 ] , 2 )), incident_power [ :,np.newaxis ] )) + scattered_power forces = net_power / c return forces calculate_axicongrating_force def calculate_axicongrating_force ( self , area_vectors , intensity_vectors , axicon_angle ) Calculates forces for particles of optical type 'axicon grating' Parameters: Name Type Description Default area_vectors npt.NDArray n_particles x 3 array of area vectors None intensity_vectors npt.NDArray n_particles x 3 array of laser beam intensity vectors None axicon_angle npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces None Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def calculate_axicongrating_force ( self , area_vectors , intensity_vectors , axicon_angle ): \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors axicon_angle : npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" rotation_super_matrix = sp . linalg . block_diag ( * axicon_angle ) forces = self . calculate_specular_force ( area_vectors , intensity_vectors ) forces = rotation_super_matrix . dot ( np . hstack ( forces ). T ) forces = np . reshape ( forces , [ int ( forces . shape [ 0 ] / 3 ), 3 ]) # The forces need to be scaled to account for the fact that # | [ 1 , 1 ] | != | [ 1 ] |+| [ 1 ] | # We don ' t have acces to the angle , but we can make use of the cosine # rule : cos ( alpha ) = A . dot ( B ) / ( | A | | B | ) to get the angle between # z + and the line of action of the force . unit_z = np . array ([ 0 , 0 , 1 ]) scaling_factor = np . matmul ( axicon_angle , unit_z ). dot ( unit_z ) for i in range ( 3 ): forces [:, i ] *= scaling_factor return forces calculate_force_gradient def calculate_force_gradient ( self , displacement_vector : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters: Name Type Description Default displacement_vector npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero None Returns: Type Description list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] Raises: Type Description AttributeError Raises error if multiple displacements are supplied. View Source def calculate_force_gradient ( self , displacement_vector : npt . ArrayLike ) : \"\" \" Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters ---------- displacement_vector : npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero Raises ------ AttributeError Raises error if multiple displacements are supplied. Returns ------- k_trans : list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] k_rot : TYPE lenght 3 list of translational reaction coefficients [dM_x/dx__i, dM_y/dx__i, dM_z/dx__i] \"\" \" displacement = displacement_vector[displacement_vector !=0] if len(displacement)>1: raise AttributeError ( \"Expected vector with only one nonzero value,\" f \"instead got {displacement_vector}\" ) original = self . calculate_restoring_forces () self . PS . displace ( displacement_vector ) reaction = self . calculate_restoring_forces () self . PS . un_displace () k_trans = ( reaction [ 0 ] - original [ 0 ] ) / displacement k_rot = ( reaction [ 1 ] - original [ 1 ] ) / displacement return k_trans , k_rot calculate_restoring_forces def calculate_restoring_forces ( self , forces : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] = None ) calculates net forces and moments around the center of mass Parameters: Name Type Description Default forces npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. None Returns: Type Description npt.ArrayLike Net force on center of mass. View Source def calculate_restoring_forces ( self , forces : npt . ArrayLike = None ): \"\"\" calculates net forces and moments around the center of mass Parameters ---------- forces : npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. Returns ------- net_force : npt.ArrayLike Net force on center of mass. net_moments : npt.ArrayLike Net moments around center of mass. \"\"\" PS = self . ParticleSystem if type ( forces ) == type ( None ): forces = self . force_value () net_force = np . sum ( forces , axis = 0 ) COM = PS . calculate_center_of_mass () locations , _ = PS . x_v_current_3D moment_arms = PS . translate_mesh ( locations , - COM ) # note: this doesn't displace the PS, just applies a transformation on the 'locations' variable moments = np . cross ( moment_arms , forces ) net_moments = np . sum ( moments , axis = 0 ) return net_force , net_moments calculate_specular_force def calculate_specular_force ( self , area_vectors , intensity_vectors ) Calculates forces for particles of optical type 'specular' Todo Parameters: Name Type Description Default area_vectors npt.NDArray n_particles x 3 array of area vectors None intensity_vectors npt.NDArray n_particles x 3 array of laser beam intensity vectors None Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def calculate_specular_force ( self , area_vectors , intensity_vectors ): \"\"\" Calculates forces for particles of optical type 'specular' !!! TODO implement reflectivity coefficient Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # First we compute the incident power on the particle areas abs_area_vectors = area_vectors [:, 2 ] # assumes z + poynting vector abs_intensity_vectors = intensity_vectors [:, 2 ] # assumes z + poynting vector incident_power = abs_area_vectors * abs_intensity_vectors # To get the direction of the forces we need to normalise the area # vectors . For convenience we roll that into the force calculation of # dF = dP / c . We double it because the PhC is acting in reflection norms = np . linalg . norm ( area_vectors , axis = 1 ) forces = area_vectors . copy () for i in range ( 3 ): forces [:, i ] *= 2 * incident_power / ( c * norms ) return forces calculate_stability_coefficients def calculate_stability_coefficients ( self , displacement_range = [ 0.1 , 5 ] ) Calculates the stability coefficients for the particle system Parameters: Name Type Description Default displacement_range list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. None Returns: Type Description npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg View Source def calculate_stability_coefficients ( self , displacement_range = [ 0.1 , 5 ]): \"\"\" Calculates the stability coefficients for the particle system Parameters ---------- displacement_range : list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. Returns ------- stability_matrix : npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg \"\"\" q , alpha = displacement_range displacement_vectors = np . array ([[ q , 0 , 0 , 0 , 0 , 0 ], [ 0 , q , 0 , 0 , 0 , 0 ], [ 0 , 0 , q , 0 , 0 , 0 ], [ 0 , 0 , 0 , alpha , 0 , 0 ], [ 0 , 0 , 0 , 0 , alpha , 0 ], [ 0 , 0 , 0 , 0 , 0 , alpha ]]) jacobian = np . zeros (( 6 , 6 )) for i , vector in enumerate ( displacement_vectors ): jacobian [:, i ] = np . hstack ( self . calculate_force_gradient ( vector )) return jacobian create_optical_type_mask def create_optical_type_mask ( self ) loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises: Type Description AttributeError Raises error when particles have no optical type set. View Source def create_optical_type_mask ( self ) : \"\"\" loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises ------ AttributeError Raises error when particles have no optical type set. \"\"\" optical_type_list = [] error_index_list = [] for i , particle in enumerate ( self . ParticleSystem . particles ) : if hasattr ( particle , 'optical_type' ) : optical_type_list . append ( particle . optical_type ) else : error_index_list . append ( i ) if len ( error_index_list ) > 0 : raise AttributeError ( \"All particles should have an optical type\" \" set prior to calculation of optical forces.\" \" Currently the particles with indices\" f \" {error_index_list} have no property set\" ) optical_type_list = np . array ( optical_type_list ) self . optical_type_mask = {} for optical_type in ParticleOpticalPropertyType : mask = optical_type_list == optical_type if sum ( mask ) > 0 : self . optical_type_mask [ optical_type ] = mask create_phc_map def create_phc_map ( self , mask ) View Source def create_phc_map ( self , mask ) : filtered_particles = compress ( self . PS . particles , mask ) original_indices = [ i for i, m in enumerate(mask) if m ] self . optical_interpolators = [] # let 's check if it' s one or multiple PHC ' s self . phc_dict = defaultdict ( list ) for i , p in enumerate ( filtered_particles ) : self . optical_interpolators . append ( p . optical_interpolator ) #build dict of mask entries and which PhC they belong to . self . phc_dict [ p.optical_interpolator ] . append ( original_indices [ i ] ) for key in self . phc_dict . keys () : self . phc_dict [ key ] = self . create_submask ( self . phc_dict [ key ] ) create_submask def create_submask ( self , indice_list ) View Source def create_submask ( self , indice_list ) : length = len ( self . PS . particles ) submask = np . zeros ( length , dtype = bool ) for i in indice_list : submask [ i ] = True return submask force_value def force_value ( self ) Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def force_value ( self ) : \"\"\" Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" PS = self . ParticleSystem LB = self . LaserBeam area_vectors = PS . find_surface () area_vectors = np . nan_to_num ( area_vectors ) locations , _ = PS . x_v_current_3D forces = np . zeros ( locations . shape ) if not hasattr ( self , 'optical_type_mask' ) : self . create_optical_type_mask () # ! Note ! This bakes in implicitly that the orientation of the light # vector is in z + direction intensity_vectors = np . array ( [ [0,0,LB.intensity_profile(x,y) ] for x , y , z in locations ] ) polarisation_vectors = LB . polarization_map ( locations [ :,0 ] , locations [ :,1 ] ) for optical_type in self . optical_type_mask . keys () : if optical_type == ParticleOpticalPropertyType . SPECULAR : mask = self . optical_type_mask [ optical_type ] forces [ mask ] = self . calculate_specular_force ( area_vectors [ mask ] , intensity_vectors [ mask ] ) elif optical_type == ParticleOpticalPropertyType . AXICONGRATING : mask = self . optical_type_mask [ optical_type ] filtered_particles = compress ( PS . particles , mask ) axicon_angle = [ p.axicon_angle for p in filtered_particles ] forces [ mask ] = self . calculate_axicongrating_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , axicon_angle ) elif optical_type == ParticleOpticalPropertyType . ARBITRARY_PHC : mask = self . optical_type_mask [ optical_type ] if not hasattr ( self , 'optical_interpolators' ) : self . create_phc_map ( mask ) forces [ mask ] = self . calculate_arbitrary_phc_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , polarisation_vectors [ mask ] , self . optical_interpolators ) return forces ParticleOpticalPropertyType class ParticleOpticalPropertyType ( / , * args , ** kwargs ) Enumeration representing the various types of optical properties for the Particles Attributes Name Type Description Default SPECULAR str Indicates that the particle reflects light specularly None ARBITRARY_PHC str Indicates that the particle represents an arbitrary photonic crystal NOTE: scipy.interpolate.interpnd.LinearNDInterpolator has to be set on particle.optical_interpolator(elevation, azimuth, polarisation_angle) ->(elevation, azimuth, magnitude) None AXICONGRATING str Indicates that the particle scatter light like a cone NOTE: Directing angle should be set in the format of a rotation matrix for the relevant particles that represents [rx, ry] rotations of area vector on property particle.axicon_angle None View Source class ParticleOpticalPropertyType ( Enum ): \"\"\" Enumeration representing the various types of optical properties for the Particles Attributes ---------- SPECULAR : str Indicates that the particle reflects light specularly ARBITRARY_PHC : str Indicates that the particle represents an arbitrary photonic crystal NOTE: scipy.interpolate.interpnd.LinearNDInterpolator has to be set on particle.optical_interpolator(elevation, azimuth, polarisation_angle) ->(elevation, azimuth, magnitude) AXICONGRATING : str Indicates that the particle scatter light like a cone NOTE: Directing angle should be set in the format of a rotation matrix for the relevant particles that represents [rx, ry] rotations of area vector on property particle.axicon_angle \"\"\" SPECULAR = \"specular\" AXICONGRATING = \"axicongrating\" ARBITRARY_PHC = \"ARBITRARY_PHC\" Ancestors (in MRO) enum.Enum Class variables ARBITRARY_PHC AXICONGRATING SPECULAR name value","title":"Opticalforcecalculator"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#module-srcexternalforcesopticalforcecalculator","text":"Optical force calculation framework Created on Tue Nov 7 14:19:21 2023 View Source # -*- coding: utf-8 -*- \"\"\" Optical force calculation framework Created on Tue Nov 7 14:19:21 2023 @author: Mark Kalsbeek \"\"\" from enum import Enum from itertools import compress from collections import defaultdict import numpy as np import numpy.typing as npt import scipy as sp from scipy.constants import c from scipy.spatial.transform import Rotation from src.particleSystem.Force import Force import logging class OpticalForceCalculator ( Force ): \"\"\" Handles the calculation of forces arising from optical pressure \"\"\" def __init__ ( self , ParticleSystem , LaserBeam ): self . ParticleSystem = ParticleSystem self . PS = self . ParticleSystem #alias for convenience self . LaserBeam = LaserBeam if not hasattr ( self . ParticleSystem . particles [ 0 ], 'optical_type' ): raise AttributeError ( \"ParticleSystem does not have any optical properties set!\" ) super () . __init__ () return def __str__ ( self ): print ( \"OpticalForceCalculator object instantiated with attributes:\" ) print ( f \"ParticleSystem: \\n { self . ParticleSystem } \" ) print ( f \"LaserBeam: \\n { self . LaserBeam } \" ) return \"\" def force_value ( self ): \"\"\" Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" PS = self . ParticleSystem LB = self . LaserBeam area_vectors = PS . find_surface () area_vectors = np . nan_to_num ( area_vectors ) locations , _ = PS . x_v_current_3D forces = np . zeros ( locations . shape ) if not hasattr ( self , 'optical_type_mask' ): self . create_optical_type_mask () # ! Note ! This bakes in implicitly that the orientation of the light # vector is in z+ direction intensity_vectors = np . array ([[ 0 , 0 , LB . intensity_profile ( x , y )] for x , y , z in locations ]) polarisation_vectors = LB . polarization_map ( locations [:, 0 ], locations [:, 1 ]) for optical_type in self . optical_type_mask . keys (): if optical_type == ParticleOpticalPropertyType . SPECULAR : mask = self . optical_type_mask [ optical_type ] forces [ mask ] = self . calculate_specular_force ( area_vectors [ mask ], intensity_vectors [ mask ]) elif optical_type == ParticleOpticalPropertyType . AXICONGRATING : mask = self . optical_type_mask [ optical_type ] filtered_particles = compress ( PS . particles , mask ) axicon_angle = [ p . axicon_angle for p in filtered_particles ] forces [ mask ] = self . calculate_axicongrating_force ( area_vectors [ mask ], intensity_vectors [ mask ], axicon_angle ) elif optical_type == ParticleOpticalPropertyType . ARBITRARY_PHC : mask = self . optical_type_mask [ optical_type ] if not hasattr ( self , 'optical_interpolators' ): self . create_phc_map ( mask ) forces [ mask ] = self . calculate_arbitrary_phc_force ( area_vectors [ mask ], intensity_vectors [ mask ], polarisation_vectors [ mask ], self . optical_interpolators ) return forces def create_phc_map ( self , mask ): filtered_particles = compress ( self . PS . particles , mask ) original_indices = [ i for i , m in enumerate ( mask ) if m ] self . optical_interpolators = [] # let's check if it's one or multiple PHC's self . phc_dict = defaultdict ( list ) for i , p in enumerate ( filtered_particles ): self . optical_interpolators . append ( p . optical_interpolator ) #build dict of mask entries and which PhC they belong to. self . phc_dict [ p . optical_interpolator ] . append ( original_indices [ i ]) for key in self . phc_dict . keys (): self . phc_dict [ key ] = self . create_submask ( self . phc_dict [ key ]) def create_submask ( self , indice_list ): length = len ( self . PS . particles ) submask = np . zeros ( length , dtype = bool ) for i in indice_list : submask [ i ] = True return submask def calculate_specular_force ( self , area_vectors , intensity_vectors ): \"\"\" Calculates forces for particles of optical type 'specular' !!! TODO implement reflectivity coefficient Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # First we compute the incident power on the particle areas abs_area_vectors = area_vectors [:, 2 ] # assumes z+ poynting vector abs_intensity_vectors = intensity_vectors [:, 2 ] # assumes z+ poynting vector incident_power = abs_area_vectors * abs_intensity_vectors # To get the direction of the forces we need to normalise the area # vectors. For convenience we roll that into the force calculation of # dF = dP/c. We double it because the PhC is acting in reflection norms = np . linalg . norm ( area_vectors , axis = 1 ) forces = area_vectors . copy () for i in range ( 3 ): forces [:, i ] *= 2 * incident_power / ( c * norms ) return forces def calculate_axicongrating_force ( self , area_vectors , intensity_vectors , axicon_angle ): \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors axicon_angle : npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" rotation_super_matrix = sp . linalg . block_diag ( * axicon_angle ) forces = self . calculate_specular_force ( area_vectors , intensity_vectors ) forces = rotation_super_matrix . dot ( np . hstack ( forces ) . T ) forces = np . reshape ( forces , [ int ( forces . shape [ 0 ] / 3 ), 3 ]) # The forces need to be scaled to account for the fact that # |[1,1]| != |[1]|+|[1]| # We don't have acces to the angle, but we can make use of the cosine # rule: cos(alpha) = A.dot(B) / (|A| |B|) to get the angle between # z+ and the line of action of the force. unit_z = np . array ([ 0 , 0 , 1 ]) scaling_factor = np . matmul ( axicon_angle , unit_z ) . dot ( unit_z ) for i in range ( 3 ): forces [:, i ] *= scaling_factor return forces def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ): \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. intensity_vectors : npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # Convert area vector to spherical coordinates result = compute_spherical_coordinates ( area_vectors , polarisation_vectors ) polar_angles , azimuth_angles , polarisation_angles = result # Switch reference frame; made easier becasue we a coming from [0,0,1] # azimuth_angles += np.pi # azimuth_angles %= 2*np.pi # Condition them for the interpolator: wrapped_coordinates = wrap_spherical_coordinates ( polar_angles , azimuth_angles , polarisation_angles ) polar_angles , azimuth_angles , polarisation_angles = wrapped_coordinates incoming_ray = np . vstack (( polar_angles , azimuth_angles , polarisation_angles )) . T # Find directions of outgoing rays # Interpolator([polar_in, azimuth_in, polarization_in])->[polar_out, azimuth_out, magnitude] reflected_ray = np . zeros ( incoming_ray . shape ) for phc in self . phc_dict : submask = self . phc_dict [ phc ] reflected_ray [ submask ] = phc ( incoming_ray [ submask ]) # reflected_ray = [interp(incoming_ray[i]) # reflected_ray = [interp(tuple(incoming_ray[i])) # for i, interp # in enumerate(optical_interpolators)] # [polar_out, azimuth_out, magnitude] polar_angles_out , azimuth_angles_out , magnitudes = np . array ( reflected_ray ) . T # Switch reference frame again; made easier becasue we are going to [0,0,1] polar_angles_out += polar_angles reflected_vectors = spherical_to_cartesian ( polar_angles_out , azimuth_angles_out , magnitudes ) # Compute the incident power on the particle areas abs_area_vectors = area_vectors [:, 2 ] # assumes z+ poynting vector abs_intensity_vectors = intensity_vectors [:, 2 ] # assumes z+ poynting vector incident_power = abs_area_vectors * abs_intensity_vectors scattered_power = reflected_vectors * incident_power [:, np . newaxis ] net_power = np . hstack (( np . zeros (( incident_power . shape [ 0 ], 2 )), incident_power [:, np . newaxis ])) + scattered_power forces = net_power / c return forces def create_optical_type_mask ( self ): \"\"\" loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises ------ AttributeError Raises error when particles have no optical type set. \"\"\" optical_type_list = [] error_index_list = [] for i , particle in enumerate ( self . ParticleSystem . particles ): if hasattr ( particle , 'optical_type' ): optical_type_list . append ( particle . optical_type ) else : error_index_list . append ( i ) if len ( error_index_list ) > 0 : raise AttributeError ( \"All particles should have an optical type\" \" set prior to calculation of optical forces.\" \" Currently the particles with indices\" f \" { error_index_list } have no property set\" ) optical_type_list = np . array ( optical_type_list ) self . optical_type_mask = {} for optical_type in ParticleOpticalPropertyType : mask = optical_type_list == optical_type if sum ( mask ) > 0 : self . optical_type_mask [ optical_type ] = mask def calculate_stability_coefficients ( self , displacement_range = [ 0.1 , 5 ]): \"\"\" Calculates the stability coefficients for the particle system Parameters ---------- displacement_range : list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. Returns ------- stability_matrix : npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg \"\"\" q , alpha = displacement_range displacement_vectors = np . array ([[ q , 0 , 0 , 0 , 0 , 0 ], [ 0 , q , 0 , 0 , 0 , 0 ], [ 0 , 0 , q , 0 , 0 , 0 ], [ 0 , 0 , 0 , alpha , 0 , 0 ], [ 0 , 0 , 0 , 0 , alpha , 0 ], [ 0 , 0 , 0 , 0 , 0 , alpha ]]) jacobian = np . zeros (( 6 , 6 )) for i , vector in enumerate ( displacement_vectors ): jacobian [:, i ] = np . hstack ( self . calculate_force_gradient ( vector )) return jacobian def calculate_force_gradient ( self , displacement_vector : npt . ArrayLike ): \"\"\" Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters ---------- displacement_vector : npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero Raises ------ AttributeError Raises error if multiple displacements are supplied. Returns ------- k_trans : list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] k_rot : TYPE lenght 3 list of translational reaction coefficients [dM_x/dx__i, dM_y/dx__i, dM_z/dx__i] \"\"\" displacement = displacement_vector [ displacement_vector != 0 ] if len ( displacement ) > 1 : raise AttributeError ( \"Expected vector with only one nonzero value,\" f \"instead got { displacement_vector } \" ) original = self . calculate_restoring_forces () self . PS . displace ( displacement_vector ) reaction = self . calculate_restoring_forces () self . PS . un_displace () k_trans = ( reaction [ 0 ] - original [ 0 ]) / displacement k_rot = ( reaction [ 1 ] - original [ 1 ]) / displacement return k_trans , k_rot def calculate_restoring_forces ( self , forces : npt . ArrayLike = None ): \"\"\" calculates net forces and moments around the center of mass Parameters ---------- forces : npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. Returns ------- net_force : npt.ArrayLike Net force on center of mass. net_moments : npt.ArrayLike Net moments around center of mass. \"\"\" PS = self . ParticleSystem if type ( forces ) == type ( None ): forces = self . force_value () net_force = np . sum ( forces , axis = 0 ) COM = PS . calculate_center_of_mass () locations , _ = PS . x_v_current_3D moment_arms = PS . translate_mesh ( locations , - COM ) # note: this doesn't displace the PS, just applies a transformation on the 'locations' variable moments = np . cross ( moment_arms , forces ) net_moments = np . sum ( moments , axis = 0 ) return net_force , net_moments class ParticleOpticalPropertyType ( Enum ): \"\"\" Enumeration representing the various types of optical properties for the Particles Attributes ---------- SPECULAR : str Indicates that the particle reflects light specularly ARBITRARY_PHC : str Indicates that the particle represents an arbitrary photonic crystal NOTE: scipy.interpolate.interpnd.LinearNDInterpolator has to be set on particle.optical_interpolator(elevation, azimuth, polarisation_angle) ->(elevation, azimuth, magnitude) AXICONGRATING : str Indicates that the particle scatter light like a cone NOTE: Directing angle should be set in the format of a rotation matrix for the relevant particles that represents [rx, ry] rotations of area vector on property particle.axicon_angle \"\"\" SPECULAR = \"specular\" AXICONGRATING = \"axicongrating\" ARBITRARY_PHC = \"ARBITRARY_PHC\" vectorized_optical_type_retriever = np . vectorize ( lambda p : p . optical_type ) def compute_spherical_coordinates ( area_vectors : npt . NDArray , polarisation_vectors : npt . NDArray ) -> ( npt . NDArray , npt . NDArray , npt . NDArray ): \"\"\" Computes the polar angles, azimuth angles, and polarisation angles of the incoming ray and its polarisation relative to the orientation of area elements represented by area vectors. Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 2) representing the polarisation vectors of laser beams for n particles. Returns ------- polar_angles : npt.NDArray An array of polar angles of the area vectors relative to the z-axis [rad]. azimuth_angles : npt.NDArray An array of azimuth angles of the area vectors in the xy-plane [rad]. polarisation_angles : npt.NDArray An array of angles between the polarisation vectors and their projection onto the plane orthogonal to the area vectors [rad]. \"\"\" # Normalize the area vectors norm_area_vectors = area_vectors / np . linalg . norm ( area_vectors , axis = 1 )[:, np . newaxis ] # Compute polar angles using the dot product between area vectors and the z-axis polar_angles = np . arccos ( norm_area_vectors [:, 2 ]) # Compute azimuth angles azimuth_angles = np . arctan2 ( norm_area_vectors [:, 1 ], norm_area_vectors [:, 0 ]) # Compute the polarisation angle in cartesian space: polarisation_angles = np . arccos ( polarisation_vectors [:, 0 ]) return polar_angles , azimuth_angles , polarisation_angles def spherical_to_cartesian ( polar_angles : npt . NDArray , azimuth_angles : npt . NDArray , magnitudes : npt . NDArray ) -> npt . NDArray : \"\"\" Converts spherical coordinates back to Cartesian coordinates in the global frame, using the area vectors to define the local reference frames. Scales the resulting vectors by the magnitudes. Parameters ---------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes to scale the intensity of the resulting rays. area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles, used to define the local reference frames. Returns ------- cartesian_vectors : npt.NDArray An array of shape (n_particles, 3) representing the resulting Cartesian vectors in the global frame. \"\"\" # Convert spherical to Cartesian coordinates in the local frame x = magnitudes * np . sin ( polar_angles ) * np . cos ( azimuth_angles ) y = magnitudes * np . sin ( polar_angles ) * np . sin ( azimuth_angles ) z = magnitudes * np . cos ( polar_angles ) cartesian_vectors = np . vstack (( x , y , z )) . T return cartesian_vectors def cartesian_to_sphereical ( vectors : npt . NDArray ) -> npt . NDArray : \"\"\" Converts a set of vectors from cartesian to spherical coordinates Parameters ---------- vectors : npt.NDArray An array of shape (n_particles, 3) representing the vectors to convert. Returns ------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes of the vectors. \"\"\" x , y , z = vectors [:, 0 ], vectors [:, 1 ], vectors [:, 2 ] magnitudes = np . linalg . norm ( vectors , axis = 1 ) polar_angles = np . arccos ( z / magnitudes ) azimuth_angles = np . arctan2 ( y , x ) return polar_angles , azimuth_angles , magnitudes def wrap_spherical_coordinates ( theta : npt . NDArray , phi : npt . NDArray , pol : npt . NDArray = None ): \"\"\" wraps points in spherical coordinates to always stay within the interpolators defined range Parameters ---------- theta : npt.NDArray polar angle [rad] phi : npt.NDArray azimuthal angle [rad] pol : npt.NDArray polarisation angle [rad] Returns ------- theta : npt.NDArray polar angle phi : npt.NDArray azimuthal angle pol : npt.NDArray polarisation angle \"\"\" phi [ theta > np . pi ] += np . pi theta [ theta > np . pi ] = np . pi - theta [ theta > np . pi ] % np . pi phi [ theta < 0 ] += np . pi theta [ theta < 0 ] *=- 1 phi %= 2 * np . pi phi [ abs ( phi - 2 * np . pi ) < 1e-5 ] = 0 # wraps values that are _almost_ 2*np.pi if np . any ( pol != None ): x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) pol = np . arctan ( y / x ) return theta , phi , pol else : return theta , phi # quick test # !!! todo move to testing file theta = np . random . random ( 100 ) * 3 * np . pi - np . pi phi = np . random . random ( 100 ) * 3 * np . pi - np . pi pol = np . random . random ( 100 ) * 3 * np . pi - np . pi def test_wrap_spherical_coordinates ( dat ): mags = np . ones ( dat [ 0 ] . shape ) t1 = spherical_to_cartesian ( * wrap_spherical_coordinates ( * dat )[: 2 ], mags ) t2 = spherical_to_cartesian ( * dat [: 2 ], mags ) return ( t1 == t2 ) . all () test_wrap_spherical_coordinates (( theta , phi , pol )) if __name__ == \"__main__\" : from code_Validation.saddle_form import saddle_form from src.ExternalForces.LaserBeam import LaserBeam import matplotlib.pyplot as plt PS = saddle_form . instantiate_ps () #PS.stress_self() #for i in range(10): PS.simulate() for particle in PS . particles : particle . x [ 2 ] = 0 I_0 = 100e9 / ( 10 * 10 ) mu_x = 5 mu_y = 5 sigma = 5 LB = LaserBeam ( lambda x , y : I_0 * np . exp ( - 1 / 2 * (( x - mu_x ) / sigma ) ** 2 - 1 / 2 * (( y - mu_y ) / sigma ) ** 2 ), lambda x , y : [ 0 , 1 ]) LB = LaserBeam ( lambda x , y : np . ones ( x . shape ) * I_0 , lambda x , y : [ 0 , 1 ]) # One half of example will be 45 deg axicon angle directed towards (5,5) # other half will be specular reflection rots = [] for particle in PS . particles : particle . optical_type = ParticleOpticalPropertyType . SPECULAR if ( particle . x [ 0 ] - 5 ) ** 2 + ( particle . x [ 1 ] - 5 ) ** 2 >= 3 ** 2 : roty = 45 rotz = np . rad2deg ( np . arctan2 (( particle . x [ 1 ] - 5 ), ( particle . x [ 0 ] - 4.999 ))) particle . optical_type = ParticleOpticalPropertyType . AXICONGRATING #particle.axicon_angle = Rotation.from_euler('yz', [roty, rotz], degrees=True).as_matrix() particle . axicon_angle = Rotation . from_euler ( 'yz' , [ roty , rotz ], degrees = True ) . as_matrix () rots . append (( roty , rotz % 360 )) OFC = OpticalForceCalculator ( PS , LB ) forces = OFC . force_value () ax = PS . plot () points , _ = PS . x_v_current_3D x , y , z = points [:, 0 ], points [:, 1 ], points [:, 2 ] a_u = forces [:, 0 ] a_v = forces [:, 1 ] a_w = forces [:, 2 ] ax . scatter ( x , y , z ) ax . quiver ( x , y , z , a_u , a_v , a_w , length = 0.1 ) ax . set_box_aspect ([ 1 , 1 , 1 ]) ax . set_zlim ( - 5 , 5 ) #ax.set_zscale('symlog') #ax2 = fig.add_subplot(projection='3d') #LB.plot(ax2, x_range = [0,10], y_range=[0,10])","title":"Module src.ExternalForces.OpticalForceCalculator"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#variables","text":"c vectorized_optical_type_retriever","title":"Variables"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#functions","text":"","title":"Functions"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#cartesian_to_sphereical","text":"def cartesian_to_sphereical ( vectors : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] ) -> numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] Converts a set of vectors from cartesian to spherical coordinates Parameters: Name Type Description Default vectors npt.NDArray An array of shape (n_particles, 3) representing the vectors to convert. None Returns: Type Description npt.NDArray An array of polar angles in radians. View Source def cartesian_to_sphereical ( vectors : npt . NDArray ) -> npt . NDArray : \"\"\" Converts a set of vectors from cartesian to spherical coordinates Parameters ---------- vectors : npt.NDArray An array of shape (n_particles, 3) representing the vectors to convert. Returns ------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes of the vectors. \"\"\" x , y , z = vectors [ : , 0 ], vectors [ : , 1 ], vectors [ : , 2 ] magnitudes = np . linalg . norm ( vectors , axis = 1 ) polar_angles = np . arccos ( z / magnitudes ) azimuth_angles = np . arctan2 ( y , x ) return polar_angles , azimuth_angles , magnitudes","title":"cartesian_to_sphereical"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#compute_spherical_coordinates","text":"def compute_spherical_coordinates ( area_vectors : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], polarisation_vectors : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] ) -> ( numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]]) Computes the polar angles, azimuth angles, and polarisation angles of the incoming ray and its polarisation relative to the orientation of area elements represented by area vectors. Parameters: Name Type Description Default area_vectors npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. None polarisation_vectors npt.NDArray An array of shape (n_particles, 2) representing the polarisation vectors of laser beams for n particles. None Returns: Type Description npt.NDArray An array of polar angles of the area vectors relative to the z-axis [rad]. View Source def compute_spherical_coordinates ( area_vectors : npt . NDArray , polarisation_vectors : npt . NDArray ) -> ( npt . NDArray , npt . NDArray , npt . NDArray ) : \"\"\" Computes the polar angles, azimuth angles, and polarisation angles of the incoming ray and its polarisation relative to the orientation of area elements represented by area vectors. Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 2) representing the polarisation vectors of laser beams for n particles. Returns ------- polar_angles : npt.NDArray An array of polar angles of the area vectors relative to the z-axis [rad]. azimuth_angles : npt.NDArray An array of azimuth angles of the area vectors in the xy-plane [rad]. polarisation_angles : npt.NDArray An array of angles between the polarisation vectors and their projection onto the plane orthogonal to the area vectors [rad]. \"\"\" # Normalize the area vectors norm_area_vectors = area_vectors / np . linalg . norm ( area_vectors , axis = 1 ) [ :, np.newaxis ] # Compute polar angles using the dot product between area vectors and the z - axis polar_angles = np . arccos ( norm_area_vectors [ :, 2 ] ) # Compute azimuth angles azimuth_angles = np . arctan2 ( norm_area_vectors [ :,1 ] , norm_area_vectors [ :,0 ] ) # Compute the polarisation angle in cartesian space : polarisation_angles = np . arccos ( polarisation_vectors [ :,0 ] ) return polar_angles , azimuth_angles , polarisation_angles","title":"compute_spherical_coordinates"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#spherical_to_cartesian","text":"def spherical_to_cartesian ( polar_angles : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], azimuth_angles : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], magnitudes : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] ) -> numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] Converts spherical coordinates back to Cartesian coordinates in the global frame, using the area vectors to define the local reference frames. Scales the resulting vectors by the magnitudes. Parameters: Name Type Description Default polar_angles npt.NDArray An array of polar angles in radians. None azimuth_angles npt.NDArray An array of azimuth angles in radians. None magnitudes npt.NDArray An array of magnitudes to scale the intensity of the resulting rays. None area_vectors npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles, used to define the local reference frames. None Returns: Type Description npt.NDArray An array of shape (n_particles, 3) representing the resulting Cartesian vectors in the global frame. View Source def spherical_to_cartesian ( polar_angles : npt . NDArray , azimuth_angles : npt . NDArray , magnitudes : npt . NDArray ) -> npt . NDArray : \"\"\" Converts spherical coordinates back to Cartesian coordinates in the global frame, using the area vectors to define the local reference frames. Scales the resulting vectors by the magnitudes. Parameters ---------- polar_angles : npt.NDArray An array of polar angles in radians. azimuth_angles : npt.NDArray An array of azimuth angles in radians. magnitudes : npt.NDArray An array of magnitudes to scale the intensity of the resulting rays. area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles, used to define the local reference frames. Returns ------- cartesian_vectors : npt.NDArray An array of shape (n_particles, 3) representing the resulting Cartesian vectors in the global frame. \"\"\" # Convert spherical to Cartesian coordinates in the local frame x = magnitudes * np . sin ( polar_angles ) * np . cos ( azimuth_angles ) y = magnitudes * np . sin ( polar_angles ) * np . sin ( azimuth_angles ) z = magnitudes * np . cos ( polar_angles ) cartesian_vectors = np . vstack (( x , y , z )). T return cartesian_vectors","title":"spherical_to_cartesian"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#wrap_spherical_coordinates","text":"def wrap_spherical_coordinates ( theta : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], phi : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]], pol : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] = None ) wraps points in spherical coordinates to always stay within the interpolators defined range Parameters: Name Type Description Default theta npt.NDArray polar angle [rad] None phi npt.NDArray azimuthal angle [rad] None pol npt.NDArray polarisation angle [rad] None Returns: Type Description npt.NDArray polar angle View Source def wrap_spherical_coordinates ( theta : npt . NDArray , phi : npt . NDArray , pol : npt . NDArray = None ) : \"\"\" wraps points in spherical coordinates to always stay within the interpolators defined range Parameters ---------- theta : npt.NDArray polar angle [rad] phi : npt.NDArray azimuthal angle [rad] pol : npt.NDArray polarisation angle [rad] Returns ------- theta : npt.NDArray polar angle phi : npt.NDArray azimuthal angle pol : npt.NDArray polarisation angle \"\"\" phi [ theta>np.pi ] += np . pi theta [ theta>np.pi ]= np . pi - theta [ theta>np.pi ]% np . pi phi [ theta<0 ] += np . pi theta [ theta<0 ] *=- 1 phi %= 2 * np . pi phi [ abs(phi-2*np.pi)<1e-5 ]= 0 # wraps values that are _almost_ 2 * np . pi if np . any ( pol != None ) : x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) pol = np . arctan ( y / x ) return theta , phi , pol else : return theta , phi # quick test # !!! todo move to testing file theta = np . random . random ( 100 ) * 3 * np . pi - np . pi phi = np . random . random ( 100 ) * 3 * np . pi - np . pi pol = np . random . random ( 100 ) * 3 * np . pi - np . pi def test_wrap_spherical_coordinates ( dat ) : mags = np . ones ( dat [ 0 ] . shape ) t1 = spherical_to_cartesian ( * wrap_spherical_coordinates ( * dat ) [ :2 ] , mags ) t2 = spherical_to_cartesian ( * dat [ :2 ] , mags ) return ( t1 == t2 ). all () test_wrap_spherical_coordinates (( theta , phi , pol ))","title":"wrap_spherical_coordinates"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#classes","text":"","title":"Classes"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#opticalforcecalculator","text":"class OpticalForceCalculator ( ParticleSystem , LaserBeam ) Handles the calculation of forces arising from optical pressure View Source class OpticalForceCalculator ( Force ) : \"\"\" Handles the calculation of forces arising from optical pressure \"\"\" def __init__ ( self , ParticleSystem , LaserBeam ) : self . ParticleSystem = ParticleSystem self . PS = self . ParticleSystem #alias for convenience self . LaserBeam = LaserBeam if not hasattr ( self . ParticleSystem . particles [ 0 ] , 'optical_type' ) : raise AttributeError ( \"ParticleSystem does not have any optical properties set!\" ) super (). __init__ () return def __str__ ( self ) : print ( \"OpticalForceCalculator object instantiated with attributes:\" ) print ( f \"ParticleSystem: \\n {self.ParticleSystem}\" ) print ( f \"LaserBeam: \\n {self.LaserBeam}\" ) return \"\" def force_value ( self ) : \"\"\" Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" PS = self . ParticleSystem LB = self . LaserBeam area_vectors = PS . find_surface () area_vectors = np . nan_to_num ( area_vectors ) locations , _ = PS . x_v_current_3D forces = np . zeros ( locations . shape ) if not hasattr ( self , 'optical_type_mask' ) : self . create_optical_type_mask () # ! Note ! This bakes in implicitly that the orientation of the light # vector is in z + direction intensity_vectors = np . array ( [ [0,0,LB.intensity_profile(x,y) ] for x , y , z in locations ] ) polarisation_vectors = LB . polarization_map ( locations [ :,0 ] , locations [ :,1 ] ) for optical_type in self . optical_type_mask . keys () : if optical_type == ParticleOpticalPropertyType . SPECULAR : mask = self . optical_type_mask [ optical_type ] forces [ mask ] = self . calculate_specular_force ( area_vectors [ mask ] , intensity_vectors [ mask ] ) elif optical_type == ParticleOpticalPropertyType . AXICONGRATING : mask = self . optical_type_mask [ optical_type ] filtered_particles = compress ( PS . particles , mask ) axicon_angle = [ p.axicon_angle for p in filtered_particles ] forces [ mask ] = self . calculate_axicongrating_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , axicon_angle ) elif optical_type == ParticleOpticalPropertyType . ARBITRARY_PHC : mask = self . optical_type_mask [ optical_type ] if not hasattr ( self , 'optical_interpolators' ) : self . create_phc_map ( mask ) forces [ mask ] = self . calculate_arbitrary_phc_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , polarisation_vectors [ mask ] , self . optical_interpolators ) return forces def create_phc_map ( self , mask ) : filtered_particles = compress ( self . PS . particles , mask ) original_indices = [ i for i, m in enumerate(mask) if m ] self . optical_interpolators = [] # let 's check if it' s one or multiple PHC 's self.phc_dict = defaultdict(list) for i, p in enumerate(filtered_particles): self.optical_interpolators.append(p.optical_interpolator) #build dict of mask entries and which PhC they belong to. self.phc_dict[p.optical_interpolator].append(original_indices[i]) for key in self.phc_dict.keys(): self.phc_dict[key] = self.create_submask(self.phc_dict[key]) def create_submask(self, indice_list): length = len(self.PS.particles) submask = np.zeros(length, dtype=bool) for i in indice_list: submask[i] = True return submask def calculate_specular_force(self, area_vectors, intensity_vectors): \"\"\" Calculates forces for particles of optical type ' specular ' !!! TODO implement reflectivity coefficient Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # First we compute the incident power on the particle areas abs_area_vectors = area_vectors[:,2] # assumes z+ poynting vector abs_intensity_vectors = intensity_vectors[:,2] # assumes z+ poynting vector incident_power = abs_area_vectors * abs_intensity_vectors # To get the direction of the forces we need to normalise the area # vectors. For convenience we roll that into the force calculation of # dF = dP/c. We double it because the PhC is acting in reflection norms = np.linalg.norm(area_vectors, axis=1) forces = area_vectors.copy() for i in range(3): forces[:,i] *= 2*incident_power / (c*norms) return forces def calculate_axicongrating_force(self, area_vectors, intensity_vectors, axicon_angle): \"\"\" Calculates forces for particles of optical type ' axicon grating ' Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors axicon_angle : npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" rotation_super_matrix = sp.linalg.block_diag(*axicon_angle) forces = self.calculate_specular_force(area_vectors, intensity_vectors) forces = rotation_super_matrix.dot(np.hstack(forces).T) forces = np.reshape(forces, [int(forces.shape[0]/3),3]) # The forces need to be scaled to account for the fact that # |[1,1]| != |[1]|+|[1]| # We don' t have acces to the angle , but we can make use of the cosine # rule : cos ( alpha ) = A . dot ( B ) / ( | A | | B | ) to get the angle between # z + and the line of action of the force . unit_z = np . array ( [ 0,0,1 ] ) scaling_factor = np . matmul ( axicon_angle , unit_z ). dot ( unit_z ) for i in range ( 3 ) : forces [ :,i ]*= scaling_factor return forces def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ) : \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. intensity_vectors : npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # Convert area vector to spherical coordinates result = compute_spherical_coordinates ( area_vectors , polarisation_vectors ) polar_angles , azimuth_angles , polarisation_angles = result # Switch reference frame ; made easier becasue we a coming from [ 0,0,1 ] # azimuth_angles += np . pi # azimuth_angles %= 2 * np . pi # Condition them for the interpolator : wrapped_coordinates = wrap_spherical_coordinates ( polar_angles , azimuth_angles , polarisation_angles ) polar_angles , azimuth_angles , polarisation_angles = wrapped_coordinates incoming_ray = np . vstack (( polar_angles , azimuth_angles , polarisation_angles )). T # Find directions of outgoing rays # Interpolator ( [ polar_in, azimuth_in, polarization_in ] ) ->[ polar_out, azimuth_out, magnitude ] reflected_ray = np . zeros ( incoming_ray . shape ) for phc in self . phc_dict : submask = self . phc_dict [ phc ] reflected_ray [ submask ] = phc ( incoming_ray [ submask ] ) # reflected_ray = [ interp(incoming_ray[i ] ) # reflected_ray = [ interp(tuple(incoming_ray[i ] )) # for i , interp # in enumerate ( optical_interpolators ) ] # [ polar_out, azimuth_out, magnitude ] polar_angles_out , azimuth_angles_out , magnitudes = np . array ( reflected_ray ). T # Switch reference frame again ; made easier becasue we are going to [ 0,0,1 ] polar_angles_out += polar_angles reflected_vectors = spherical_to_cartesian ( polar_angles_out , azimuth_angles_out , magnitudes ) # Compute the incident power on the particle areas abs_area_vectors = area_vectors [ :,2 ] # assumes z + poynting vector abs_intensity_vectors = intensity_vectors [ :,2 ] # assumes z + poynting vector incident_power = abs_area_vectors * abs_intensity_vectors scattered_power = reflected_vectors * incident_power [ :,np.newaxis ] net_power = np . hstack (( np . zeros (( incident_power . shape [ 0 ] , 2 )), incident_power [ :,np.newaxis ] )) + scattered_power forces = net_power / c return forces def create_optical_type_mask ( self ) : \"\"\" loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises ------ AttributeError Raises error when particles have no optical type set. \"\"\" optical_type_list = [] error_index_list = [] for i , particle in enumerate ( self . ParticleSystem . particles ) : if hasattr ( particle , 'optical_type' ) : optical_type_list . append ( particle . optical_type ) else : error_index_list . append ( i ) if len ( error_index_list ) > 0 : raise AttributeError ( \"All particles should have an optical type\" \" set prior to calculation of optical forces.\" \" Currently the particles with indices\" f \" {error_index_list} have no property set\" ) optical_type_list = np . array ( optical_type_list ) self . optical_type_mask = {} for optical_type in ParticleOpticalPropertyType : mask = optical_type_list == optical_type if sum ( mask ) > 0 : self . optical_type_mask [ optical_type ] = mask def calculate_stability_coefficients ( self , displacement_range = [ 0.1, 5 ] ) : \"\"\" Calculates the stability coefficients for the particle system Parameters ---------- displacement_range : list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. Returns ------- stability_matrix : npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg \"\"\" q , alpha = displacement_range displacement_vectors = np . array ( [ [q,0,0,0,0,0 ] , [ 0,q,0,0,0,0 ] , [ 0,0,q,0,0,0 ] , [ 0,0,0,alpha,0,0 ] , [ 0,0,0,0,alpha,0 ] , [ 0,0,0,0,0,alpha ] ] ) jacobian = np . zeros (( 6 , 6 )) for i , vector in enumerate ( displacement_vectors ) : jacobian [ :,i ] = np . hstack ( self . calculate_force_gradient ( vector )) return jacobian def calculate_force_gradient ( self , displacement_vector : npt . ArrayLike ) : \"\"\" Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters ---------- displacement_vector : npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero Raises ------ AttributeError Raises error if multiple displacements are supplied. Returns ------- k_trans : list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] k_rot : TYPE lenght 3 list of translational reaction coefficients [dM_x/dx__i, dM_y/dx__i, dM_z/dx__i] \"\"\" displacement = displacement_vector [ displacement_vector !=0 ] if len ( displacement ) > 1 : raise AttributeError ( \"Expected vector with only one nonzero value,\" f \"instead got {displacement_vector}\" ) original = self . calculate_restoring_forces () self . PS . displace ( displacement_vector ) reaction = self . calculate_restoring_forces () self . PS . un_displace () k_trans = ( reaction [ 0 ] - original [ 0 ] ) / displacement k_rot = ( reaction [ 1 ] - original [ 1 ] ) / displacement return k_trans , k_rot def calculate_restoring_forces ( self , forces : npt . ArrayLike = None ) : \"\"\" calculates net forces and moments around the center of mass Parameters ---------- forces : npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. Returns ------- net_force : npt.ArrayLike Net force on center of mass. net_moments : npt.ArrayLike Net moments around center of mass. \"\"\" PS = self . ParticleSystem if type ( forces ) == type ( None ) : forces = self . force_value () net_force = np . sum ( forces , axis = 0 ) COM = PS . calculate_center_of_mass () locations , _ = PS . x_v_current_3D moment_arms = PS . translate_mesh ( locations , - COM ) # note : this doesn 't displace the PS, just applies a transformation on the ' locations ' variable moments = np . cross ( moment_arms , forces ) net_moments = np . sum ( moments , axis = 0 ) return net_force , net_moments","title":"OpticalForceCalculator"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#ancestors-in-mro","text":"src.particleSystem.Force.Force src.particleSystem.SystemObject.SystemObject abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#methods","text":"","title":"Methods"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#calculate_arbitrary_phc_force","text":"def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ) Calculates forces for particles of optical type 'axicon grating' Parameters: Name Type Description Default area_vectors npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. None intensity_vectors npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. None polarisation_vectors npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. None Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def calculate_arbitrary_phc_force ( self , area_vectors , intensity_vectors , polarisation_vectors , optical_interpolators ) : \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray An array of shape (n_particles, 3) representing the area vectors of n particles. intensity_vectors : npt.NDArray An array of shape (n_particles, 3) representing the intensity vectors of laser beams for n particles. polarisation_vectors : npt.NDArray An array of shape (n_particles, 3) representing the polarisation vectors of laser beams for n particles. Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # Convert area vector to spherical coordinates result = compute_spherical_coordinates ( area_vectors , polarisation_vectors ) polar_angles , azimuth_angles , polarisation_angles = result # Switch reference frame ; made easier becasue we a coming from [ 0,0,1 ] # azimuth_angles += np . pi # azimuth_angles %= 2 * np . pi # Condition them for the interpolator : wrapped_coordinates = wrap_spherical_coordinates ( polar_angles , azimuth_angles , polarisation_angles ) polar_angles , azimuth_angles , polarisation_angles = wrapped_coordinates incoming_ray = np . vstack (( polar_angles , azimuth_angles , polarisation_angles )). T # Find directions of outgoing rays # Interpolator ( [ polar_in, azimuth_in, polarization_in ] ) ->[ polar_out, azimuth_out, magnitude ] reflected_ray = np . zeros ( incoming_ray . shape ) for phc in self . phc_dict : submask = self . phc_dict [ phc ] reflected_ray [ submask ] = phc ( incoming_ray [ submask ] ) # reflected_ray = [ interp(incoming_ray[i ] ) # reflected_ray = [ interp(tuple(incoming_ray[i ] )) # for i , interp # in enumerate ( optical_interpolators ) ] # [ polar_out, azimuth_out, magnitude ] polar_angles_out , azimuth_angles_out , magnitudes = np . array ( reflected_ray ). T # Switch reference frame again ; made easier becasue we are going to [ 0,0,1 ] polar_angles_out += polar_angles reflected_vectors = spherical_to_cartesian ( polar_angles_out , azimuth_angles_out , magnitudes ) # Compute the incident power on the particle areas abs_area_vectors = area_vectors [ :,2 ] # assumes z + poynting vector abs_intensity_vectors = intensity_vectors [ :,2 ] # assumes z + poynting vector incident_power = abs_area_vectors * abs_intensity_vectors scattered_power = reflected_vectors * incident_power [ :,np.newaxis ] net_power = np . hstack (( np . zeros (( incident_power . shape [ 0 ] , 2 )), incident_power [ :,np.newaxis ] )) + scattered_power forces = net_power / c return forces","title":"calculate_arbitrary_phc_force"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#calculate_axicongrating_force","text":"def calculate_axicongrating_force ( self , area_vectors , intensity_vectors , axicon_angle ) Calculates forces for particles of optical type 'axicon grating' Parameters: Name Type Description Default area_vectors npt.NDArray n_particles x 3 array of area vectors None intensity_vectors npt.NDArray n_particles x 3 array of laser beam intensity vectors None axicon_angle npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces None Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def calculate_axicongrating_force ( self , area_vectors , intensity_vectors , axicon_angle ): \"\"\" Calculates forces for particles of optical type 'axicon grating' Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors axicon_angle : npt.NDArray 3 x 3 array representing a rotation of the surface normal vector this determines the directions of the resulting optical forces Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" rotation_super_matrix = sp . linalg . block_diag ( * axicon_angle ) forces = self . calculate_specular_force ( area_vectors , intensity_vectors ) forces = rotation_super_matrix . dot ( np . hstack ( forces ). T ) forces = np . reshape ( forces , [ int ( forces . shape [ 0 ] / 3 ), 3 ]) # The forces need to be scaled to account for the fact that # | [ 1 , 1 ] | != | [ 1 ] |+| [ 1 ] | # We don ' t have acces to the angle , but we can make use of the cosine # rule : cos ( alpha ) = A . dot ( B ) / ( | A | | B | ) to get the angle between # z + and the line of action of the force . unit_z = np . array ([ 0 , 0 , 1 ]) scaling_factor = np . matmul ( axicon_angle , unit_z ). dot ( unit_z ) for i in range ( 3 ): forces [:, i ] *= scaling_factor return forces","title":"calculate_axicongrating_force"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#calculate_force_gradient","text":"def calculate_force_gradient ( self , displacement_vector : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters: Name Type Description Default displacement_vector npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero None Returns: Type Description list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] Raises: Type Description AttributeError Raises error if multiple displacements are supplied. View Source def calculate_force_gradient ( self , displacement_vector : npt . ArrayLike ) : \"\" \" Calculates force and moment coefficients of ParticleSystems based on a 1 DOF displacement Parameters ---------- displacement_vector : npt.ArrayLike 1x6 vector ([x,y,z,rx,ry,rz]) representing the displacement. All but one should be equal to zero Raises ------ AttributeError Raises error if multiple displacements are supplied. Returns ------- k_trans : list lenght 3 list of translational reaction coefficients [dF_x/dx__i, dF_y/dx__i, dF_z/dx__i] k_rot : TYPE lenght 3 list of translational reaction coefficients [dM_x/dx__i, dM_y/dx__i, dM_z/dx__i] \"\" \" displacement = displacement_vector[displacement_vector !=0] if len(displacement)>1: raise AttributeError ( \"Expected vector with only one nonzero value,\" f \"instead got {displacement_vector}\" ) original = self . calculate_restoring_forces () self . PS . displace ( displacement_vector ) reaction = self . calculate_restoring_forces () self . PS . un_displace () k_trans = ( reaction [ 0 ] - original [ 0 ] ) / displacement k_rot = ( reaction [ 1 ] - original [ 1 ] ) / displacement return k_trans , k_rot","title":"calculate_force_gradient"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#calculate_restoring_forces","text":"def calculate_restoring_forces ( self , forces : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] = None ) calculates net forces and moments around the center of mass Parameters: Name Type Description Default forces npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. None Returns: Type Description npt.ArrayLike Net force on center of mass. View Source def calculate_restoring_forces ( self , forces : npt . ArrayLike = None ): \"\"\" calculates net forces and moments around the center of mass Parameters ---------- forces : npt.Arraylike Allows inputting the forces directly, but is calculated automatically when ommitted. Prevents doing double work in simulation context. Returns ------- net_force : npt.ArrayLike Net force on center of mass. net_moments : npt.ArrayLike Net moments around center of mass. \"\"\" PS = self . ParticleSystem if type ( forces ) == type ( None ): forces = self . force_value () net_force = np . sum ( forces , axis = 0 ) COM = PS . calculate_center_of_mass () locations , _ = PS . x_v_current_3D moment_arms = PS . translate_mesh ( locations , - COM ) # note: this doesn't displace the PS, just applies a transformation on the 'locations' variable moments = np . cross ( moment_arms , forces ) net_moments = np . sum ( moments , axis = 0 ) return net_force , net_moments","title":"calculate_restoring_forces"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#calculate_specular_force","text":"def calculate_specular_force ( self , area_vectors , intensity_vectors ) Calculates forces for particles of optical type 'specular' Todo Parameters: Name Type Description Default area_vectors npt.NDArray n_particles x 3 array of area vectors None intensity_vectors npt.NDArray n_particles x 3 array of laser beam intensity vectors None Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def calculate_specular_force ( self , area_vectors , intensity_vectors ): \"\"\" Calculates forces for particles of optical type 'specular' !!! TODO implement reflectivity coefficient Parameters ---------- area_vectors : npt.NDArray n_particles x 3 array of area vectors intensity_vectors : npt.NDArray n_particles x 3 array of laser beam intensity vectors Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" # First we compute the incident power on the particle areas abs_area_vectors = area_vectors [:, 2 ] # assumes z + poynting vector abs_intensity_vectors = intensity_vectors [:, 2 ] # assumes z + poynting vector incident_power = abs_area_vectors * abs_intensity_vectors # To get the direction of the forces we need to normalise the area # vectors . For convenience we roll that into the force calculation of # dF = dP / c . We double it because the PhC is acting in reflection norms = np . linalg . norm ( area_vectors , axis = 1 ) forces = area_vectors . copy () for i in range ( 3 ): forces [:, i ] *= 2 * incident_power / ( c * norms ) return forces","title":"calculate_specular_force"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#calculate_stability_coefficients","text":"def calculate_stability_coefficients ( self , displacement_range = [ 0.1 , 5 ] ) Calculates the stability coefficients for the particle system Parameters: Name Type Description Default displacement_range list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. None Returns: Type Description npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg View Source def calculate_stability_coefficients ( self , displacement_range = [ 0.1 , 5 ]): \"\"\" Calculates the stability coefficients for the particle system Parameters ---------- displacement_range : list list of length two representing the displacement magnitudes to perform the stability test. First value represents lateral displacement in meters. Second value represents tilt angle around the centre of mass in degrees. Returns ------- stability_matrix : npt.arraytype 6x6 matrix holding the stability terms of the system using notation convention of Jacobian. Unit of first three N/m, next three N/deg \"\"\" q , alpha = displacement_range displacement_vectors = np . array ([[ q , 0 , 0 , 0 , 0 , 0 ], [ 0 , q , 0 , 0 , 0 , 0 ], [ 0 , 0 , q , 0 , 0 , 0 ], [ 0 , 0 , 0 , alpha , 0 , 0 ], [ 0 , 0 , 0 , 0 , alpha , 0 ], [ 0 , 0 , 0 , 0 , 0 , alpha ]]) jacobian = np . zeros (( 6 , 6 )) for i , vector in enumerate ( displacement_vectors ): jacobian [:, i ] = np . hstack ( self . calculate_force_gradient ( vector )) return jacobian","title":"calculate_stability_coefficients"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#create_optical_type_mask","text":"def create_optical_type_mask ( self ) loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises: Type Description AttributeError Raises error when particles have no optical type set. View Source def create_optical_type_mask ( self ) : \"\"\" loops over particles and sets a dict of masks onto self formatted as {type:mask} This is used to efficiently split computation of the different particle types without resorting to repeated looping. Raises ------ AttributeError Raises error when particles have no optical type set. \"\"\" optical_type_list = [] error_index_list = [] for i , particle in enumerate ( self . ParticleSystem . particles ) : if hasattr ( particle , 'optical_type' ) : optical_type_list . append ( particle . optical_type ) else : error_index_list . append ( i ) if len ( error_index_list ) > 0 : raise AttributeError ( \"All particles should have an optical type\" \" set prior to calculation of optical forces.\" \" Currently the particles with indices\" f \" {error_index_list} have no property set\" ) optical_type_list = np . array ( optical_type_list ) self . optical_type_mask = {} for optical_type in ParticleOpticalPropertyType : mask = optical_type_list == optical_type if sum ( mask ) > 0 : self . optical_type_mask [ optical_type ] = mask","title":"create_optical_type_mask"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#create_phc_map","text":"def create_phc_map ( self , mask ) View Source def create_phc_map ( self , mask ) : filtered_particles = compress ( self . PS . particles , mask ) original_indices = [ i for i, m in enumerate(mask) if m ] self . optical_interpolators = [] # let 's check if it' s one or multiple PHC ' s self . phc_dict = defaultdict ( list ) for i , p in enumerate ( filtered_particles ) : self . optical_interpolators . append ( p . optical_interpolator ) #build dict of mask entries and which PhC they belong to . self . phc_dict [ p.optical_interpolator ] . append ( original_indices [ i ] ) for key in self . phc_dict . keys () : self . phc_dict [ key ] = self . create_submask ( self . phc_dict [ key ] )","title":"create_phc_map"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#create_submask","text":"def create_submask ( self , indice_list ) View Source def create_submask ( self , indice_list ) : length = len ( self . PS . particles ) submask = np . zeros ( length , dtype = bool ) for i in indice_list : submask [ i ] = True return submask","title":"create_submask"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#force_value","text":"def force_value ( self ) Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns: Type Description npt.NDArray flattened array of external forces of length 3 * n_particles. View Source def force_value ( self ) : \"\"\" Calculates optical forces based on optical properties of ParticleSystem and LaserBeam Returns ------- forces : npt.NDArray flattened array of external forces of length 3 * n_particles. \"\"\" PS = self . ParticleSystem LB = self . LaserBeam area_vectors = PS . find_surface () area_vectors = np . nan_to_num ( area_vectors ) locations , _ = PS . x_v_current_3D forces = np . zeros ( locations . shape ) if not hasattr ( self , 'optical_type_mask' ) : self . create_optical_type_mask () # ! Note ! This bakes in implicitly that the orientation of the light # vector is in z + direction intensity_vectors = np . array ( [ [0,0,LB.intensity_profile(x,y) ] for x , y , z in locations ] ) polarisation_vectors = LB . polarization_map ( locations [ :,0 ] , locations [ :,1 ] ) for optical_type in self . optical_type_mask . keys () : if optical_type == ParticleOpticalPropertyType . SPECULAR : mask = self . optical_type_mask [ optical_type ] forces [ mask ] = self . calculate_specular_force ( area_vectors [ mask ] , intensity_vectors [ mask ] ) elif optical_type == ParticleOpticalPropertyType . AXICONGRATING : mask = self . optical_type_mask [ optical_type ] filtered_particles = compress ( PS . particles , mask ) axicon_angle = [ p.axicon_angle for p in filtered_particles ] forces [ mask ] = self . calculate_axicongrating_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , axicon_angle ) elif optical_type == ParticleOpticalPropertyType . ARBITRARY_PHC : mask = self . optical_type_mask [ optical_type ] if not hasattr ( self , 'optical_interpolators' ) : self . create_phc_map ( mask ) forces [ mask ] = self . calculate_arbitrary_phc_force ( area_vectors [ mask ] , intensity_vectors [ mask ] , polarisation_vectors [ mask ] , self . optical_interpolators ) return forces","title":"force_value"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#particleopticalpropertytype","text":"class ParticleOpticalPropertyType ( / , * args , ** kwargs ) Enumeration representing the various types of optical properties for the Particles","title":"ParticleOpticalPropertyType"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#attributes","text":"Name Type Description Default SPECULAR str Indicates that the particle reflects light specularly None ARBITRARY_PHC str Indicates that the particle represents an arbitrary photonic crystal NOTE: scipy.interpolate.interpnd.LinearNDInterpolator has to be set on particle.optical_interpolator(elevation, azimuth, polarisation_angle) ->(elevation, azimuth, magnitude) None AXICONGRATING str Indicates that the particle scatter light like a cone NOTE: Directing angle should be set in the format of a rotation matrix for the relevant particles that represents [rx, ry] rotations of area vector on property particle.axicon_angle None View Source class ParticleOpticalPropertyType ( Enum ): \"\"\" Enumeration representing the various types of optical properties for the Particles Attributes ---------- SPECULAR : str Indicates that the particle reflects light specularly ARBITRARY_PHC : str Indicates that the particle represents an arbitrary photonic crystal NOTE: scipy.interpolate.interpnd.LinearNDInterpolator has to be set on particle.optical_interpolator(elevation, azimuth, polarisation_angle) ->(elevation, azimuth, magnitude) AXICONGRATING : str Indicates that the particle scatter light like a cone NOTE: Directing angle should be set in the format of a rotation matrix for the relevant particles that represents [rx, ry] rotations of area vector on property particle.axicon_angle \"\"\" SPECULAR = \"specular\" AXICONGRATING = \"axicongrating\" ARBITRARY_PHC = \"ARBITRARY_PHC\"","title":"Attributes"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#ancestors-in-mro_1","text":"enum.Enum","title":"Ancestors (in MRO)"},{"location":"reference/src/ExternalForces/OpticalForceCalculator/#class-variables","text":"ARBITRARY_PHC AXICONGRATING SPECULAR name value","title":"Class variables"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/","text":"Module src.ExternalForces.optical_interpolators.interpolators Created on Mon Mar 4 12:01:37 2024 View Source # -*- coding: utf-8 -*- \"\"\" Created on Mon Mar 4 12:01:37 2024 @author: Mark Kalsbeek \"\"\" from typing import Callable import logging from functools import lru_cache import os.path import numpy as np import numpy.typing as npt from scipy.interpolate import LinearNDInterpolator , RegularGridInterpolator from scipy.interpolate import griddata from scipy.spatial import KDTree import matplotlib.pyplot as plt from src.particleSystem.ParticleSystem import ParticleSystem from src.ExternalForces.OpticalForceCalculator import wrap_spherical_coordinates # Setup path for abs. file imports my_path = os . path . abspath ( os . path . dirname ( __file__ )) PhC_library = { 'dummy' : 'dummy.csv' , 'Gao' : 'PhC_Gao_et_al.csv' , 'Mark_2' : 'Mark_2_export.csv' , 'Mark_3' : 'Mark_3_export.csv' , 'Mark_4' : 'Mark_4_export.csv' , 'Mark_4.1' : 'Mark_4.1_export.csv' , 'Mark_5' : 'Mark_5_export.csv' , 'Mark_6' : 'Mark_6.csv' , 'Mark_7' : 'Mark_7_export.csv' , 'Mark_8' : 'Mark_8_export.csv' , 'Mark_9' : 'Mark_9_export.csv' } def create_interpolator_specular () -> Callable : polar_in = np . linspace ( 0 , np . pi , 10 ) azimuth_in = np . linspace ( 0 , 2 * np . pi , 10 ) polarization_in = np . linspace ( 0 , np . pi / 2 , 10 ) polar_in , azimuth_in , polarization_in = np . meshgrid ( polar_in , azimuth_in , polarization_in ) polar_in = polar_in . reshape ([ 1000 , 1 ]) azimuth_in = azimuth_in . reshape ([ 1000 , 1 ]) polarization_in = polarization_in . reshape ([ 1000 , 1 ]) incidence = np . hstack (( polar_in , azimuth_in , polarization_in )) polar_out = polar_in azimuth_out = np . pi + azimuth_in azimuth_out = azimuth_out % ( 2 * np . pi ) magnitude = np . ones ( azimuth_out . shape ) out = np . hstack (( polar_out , azimuth_out , magnitude )) optical_interpolator = LinearNDInterpolator ( incidence , out ) return optical_interpolator def create_interpolator ( fname : str , rotation : float = 0 ) -> Callable : \"\"\" create interpolator from simulation data Parameters ---------- fname : string Path to the data. rotation : float Rotation around z+ axis of photonic crystal. Allows to represent crystal in different oriantations. [rad] Returns ------- Callable Interpolator for optical behaviour. \"\"\" path = os . path . join ( my_path , fname ) data = np . loadtxt ( path , delimiter = ',' , comments = '#' ) incidence = data [:,: 3 ] out = data [:, 3 :] if not np . any ( np . pi * 2 in incidence [:, 1 ]): mask = incidence [:, 1 ] == 0 in_dupes = incidence . copy ()[ mask ] out_dupes = out . copy ()[ mask ] in_dupes [:, 1 ] += 2 * np . pi incidence = np . vstack (( incidence , in_dupes )) out = np . vstack (( out , out_dupes )) return linear_interpolator ( incidence , out , rotation , name = fname ) class linear_interpolator (): \"\"\" maps [theta, phi, pol] to [theta, phi, mag] cache_values : bool enables lru caching for call function. Note, you only want to use caching if you are feeding coordinate tuples. Breaks when numpy arrays are fed in! \"\"\" def __init__ ( self , coordinates , values , rotation , cache_values = False , name = None ): self . coordinates = coordinates self . cache_values = cache_values self . values = values self . tree = KDTree ( coordinates ) self . rotation = rotation self . interp = LinearNDInterpolator ( coordinates , values ) if self . cache_values : self . __call__ = lru_cache ( maxsize = None )( self . __call__ ) def __call__ ( self , coordinates ): #coordinates = coordinates.copy()-np.array([0,self.rotation,self.rotation]) coordinates = coordinates - np . array ([ 0 , self . rotation , self . rotation ]) if len ( coordinates . shape ) > 1 : coordinates = np . round ( coordinates , 8 ) coordinates [:, 1 ] %= 2 * np . pi pol = coordinates [:, 2 ] x = np . abs ( np . cos ( pol )) y = np . abs ( np . sin ( pol )) coordinates [:, 2 ] = np . arctan ( y / x ) v = self . interp ( coordinates ) v [:, 1 ] += self . rotation v [:, 1 ] %= 2 * np . pi if np . any ( np . isnan ( v )): for i , line in enumerate ( v ): if np . any ( np . isnan ( line )): logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates [ i ,:])) v = np . nan_to_num ( v ) else : coordinates [ 1 ] %= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) v = self . interp ( coordinates )[ 0 ] v [ 1 ] += self . rotation v [ 1 ] %= 2 * np . pi if any ( np . isnan ( v )): logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates )) return v def old__call__ ( self , coordinates ): coordinates = coordinates . copy () - np . array ([ 0 , self . rotation , self . rotation ]) coordinates [ 1 ] %= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) dist , ind = self . tree . query ( coordinates , k = 2 ) d1 , d2 = dist . T v1 , v2 = self . values [ ind ] if d1 == 0 : return v1 elif d2 == 0 : return v2 else : v = ( d1 ) / ( d1 + d2 ) * ( v2 - v1 ) + v1 #print(self.rotation, coordinates, v) v [ 1 ] += self . rotation v [ 1 ] %= 2 * np . pi return v def check_interpolator ( interp , coordinates , ax = None ): theta , phi , pol = coordinates theta_out , phi_out , pol_out = wrap_spherical_coordinates ( * [ np . array ( i , dtype = float ) for i in coordinates ]) theta_out , phi_out , mag_out = interp ([ theta_out , phi_out , pol_out ]) in_x = np . sin ( theta ) * np . cos ( phi ) in_y = np . sin ( theta ) * np . sin ( phi ) in_z = np . cos ( theta ) out_x = np . sin ( theta_out ) * np . cos ( phi_out ) * mag_out out_y = np . sin ( theta_out ) * np . sin ( phi_out ) * mag_out out_z = np . cos ( theta_out ) * mag_out if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax . set_xlim (( - 1 , 1 )) ax . set_ylim (( - 1 , 1 )) ax . set_zlim (( - 1 , 1 )) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) ax . set_zlabel ( 'z' ) ax . set_aspect ( 'equal' ) ax . quiver ( 0 , 0 , 0 , - in_x , - in_y , - in_z , label = 'incident ray' , color = 'y' , pivot = 'tip' ) ax . quiver ( 0 , 0 , 0 , out_x , out_y , out_z , label = 'net scattered ray' , color = 'r' , pivot = 'tail' ) ax . legend () # PhC_specular = create_interpolator_specular() # PhC_Gao = create_interpolator(crystal_dict['Gao']) if __name__ == '__main__' : dummy = create_interpolator ( PhC_library [ 'dummy' ], 0 ) dummy = create_interpolator ( PhC_library [ 'Mark_4.1' ], 0 ) fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) for theta in np . linspace ( np . deg2rad ( - 15 ), np . deg2rad ( 15 ), 5 ): vec = [ theta , np . pi , 0 ] check_interpolator ( dummy , vec , ax ) print ( vec , \" \\t \" , dummy ( vec )) print ( wrap_spherical_coordinates ( * [ np . array ( i , dtype = float ) for i in vec ])) fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax . set_title ( 'Demonstrate sampled points' ) ax . set_xlim (( - 0.5 , 0.5 )) ax . set_ylim (( - 0.5 , 0.5 )) ax . set_zlim (( - 1 , 1 )) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) ax . set_zlabel ( 'z' ) ax . set_aspect ( 'equal' ) mask = np . isclose ( dummy . coordinates [:, 2 ], np . pi / 2 ) out = dummy . values [ mask ] incidence = dummy . coordinates [ mask ] theta = incidence [:, 0 ] phi = incidence [:, 1 ] n_x = np . sin ( theta ) * np . cos ( phi ) n_y = np . sin ( theta ) * np . sin ( phi ) n_z = np . cos ( theta ) theta_out = out [:, 0 ] phi_out = out [:, 1 ] mag_out = out [:, 2 ] s_x = np . sin ( theta_out ) * np . cos ( phi_out ) * mag_out s_y = np . sin ( theta_out ) * np . sin ( phi_out ) * mag_out s_z = np . cos ( theta_out ) * mag_out ax . quiver ( 0 , 0 , 0 , - n_x , - n_y , - n_z , label = 'incident ray' , color = 'y' , pivot = 'tip' ) ax . quiver ( 0 , 0 , 0 , s_x , s_y , s_z , label = 'net scattered ray' , color = 'r' , pivot = 'tail' ) ax . legend () Variables PhC_library my_path Functions check_interpolator def check_interpolator ( interp , coordinates , ax = None ) View Source def check_interpolator ( interp , coordinates , ax = None ): theta , phi , pol = coordinates theta_out , phi_out , pol_out = wrap_spherical_coordinates ( * [ np . array ( i , dtype = float ) for i in coordinates ]) theta_out , phi_out , mag_out = interp ([ theta_out , phi_out , pol_out ]) in_x = np . sin ( theta ) * np . cos ( phi ) in_y = np . sin ( theta ) * np . sin ( phi ) in_z = np . cos ( theta ) out_x = np . sin ( theta_out ) * np . cos ( phi_out ) * mag_out out_y = np . sin ( theta_out ) * np . sin ( phi_out ) * mag_out out_z = np . cos ( theta_out ) * mag_out if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = ' 3 d ' ) ax . set_xlim (( - 1 , 1 )) ax . set_ylim (( - 1 , 1 )) ax . set_zlim (( - 1 , 1 )) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) ax . set_zlabel ( 'z' ) ax . set_aspect ( ' equal ' ) ax . quiver ( 0 , 0 , 0 , - in_x , - in_y , - in_z , label = ' incident ray ' , color = 'y' , pivot = ' tip ' ) ax . quiver ( 0 , 0 , 0 , out_x , out_y , out_z , label = ' net scattered ray ' , color = 'r' , pivot = ' tail ' ) ax . legend () create_interpolator def create_interpolator ( fname : str , rotation : float = 0 ) -> Callable create interpolator from simulation data Parameters: Name Type Description Default fname string Path to the data. None rotation float Rotation around z+ axis of photonic crystal. Allows to represent crystal in different oriantations. [rad] None Returns: Type Description Callable Interpolator for optical behaviour. View Source def create_interpolator ( fname : str , rotation : float = 0 ) -> Callable : \"\"\" create interpolator from simulation data Parameters ---------- fname : string Path to the data. rotation : float Rotation around z+ axis of photonic crystal. Allows to represent crystal in different oriantations. [rad] Returns ------- Callable Interpolator for optical behaviour. \"\"\" path = os . path . join ( my_path , fname ) data = np . loadtxt ( path , delimiter = ',' , comments = '#' ) incidence = data [ :,:3 ] out = data [ :,3: ] if not np . any ( np . pi * 2 in incidence [ :,1 ] ) : mask = incidence [ :,1 ] == 0 in_dupes = incidence . copy () [ mask ] out_dupes = out . copy () [ mask ] in_dupes [ :,1 ] += 2 * np . pi incidence = np . vstack (( incidence , in_dupes )) out = np . vstack (( out , out_dupes )) return linear_interpolator ( incidence , out , rotation , name = fname ) create_interpolator_specular def create_interpolator_specular ( ) -> Callable View Source def create_interpolator_specular () -> Callable : polar_in = np . linspace ( 0 , np . pi , 10 ) azimuth_in = np . linspace ( 0 , 2 * np . pi , 10 ) polarization_in = np . linspace ( 0 , np . pi / 2 , 10 ) polar_in , azimuth_in , polarization_in = np . meshgrid ( polar_in , azimuth_in , polarization_in ) polar_in = polar_in . reshape ([ 1000 , 1 ]) azimuth_in = azimuth_in . reshape ([ 1000 , 1 ]) polarization_in = polarization_in . reshape ([ 1000 , 1 ]) incidence = np . hstack (( polar_in , azimuth_in , polarization_in )) polar_out = polar_in azimuth_out = np . pi + azimuth_in azimuth_out = azimuth_out % ( 2 * np . pi ) magnitude = np . ones ( azimuth_out . shape ) out = np . hstack (( polar_out , azimuth_out , magnitude )) optical_interpolator = LinearNDInterpolator ( incidence , out ) return optical_interpolator Classes linear_interpolator class linear_interpolator ( coordinates , values , rotation , cache_values = False , name = None ) maps [theta, phi, pol] to [theta, phi, mag] cache_values : bool enables lru caching for call function. Note, you only want to use caching if you are feeding coordinate tuples. Breaks when numpy arrays are fed in! View Source class linear_interpolator () : \"\"\" maps [theta, phi, pol] to [theta, phi, mag] cache_values : bool enables lru caching for call function. Note, you only want to use caching if you are feeding coordinate tuples. Breaks when numpy arrays are fed in! \"\"\" def __init__ ( self , coordinates , values , rotation , cache_values = False , name = None ) : self . coordinates = coordinates self . cache_values = cache_values self . values = values self . tree = KDTree ( coordinates ) self . rotation = rotation self . interp = LinearNDInterpolator ( coordinates , values ) if self . cache_values : self . __call__ = lru_cache ( maxsize = None )( self . __call__ ) def __call__ ( self , coordinates ) : #coordinates = coordinates . copy () - np . array ( [ 0,self.rotation,self.rotation ] ) coordinates = coordinates - np . array ( [ 0,self.rotation,self.rotation ] ) if len ( coordinates . shape ) > 1 : coordinates = np . round ( coordinates , 8 ) coordinates [ :,1 ]%= 2 * np . pi pol = coordinates [ :,2 ] x = np . abs ( np . cos ( pol )) y = np . abs ( np . sin ( pol )) coordinates [ :,2 ] = np . arctan ( y / x ) v = self . interp ( coordinates ) v [ :,1 ]+= self . rotation v [ :,1 ]%= 2 * np . pi if np . any ( np . isnan ( v )) : for i , line in enumerate ( v ) : if np . any ( np . isnan ( line )) : logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates [ i,: ] )) v = np . nan_to_num ( v ) else : coordinates [ 1 ]%= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) v = self . interp ( coordinates ) [ 0 ] v [ 1 ]+= self . rotation v [ 1 ]%= 2 * np . pi if any ( np . isnan ( v )) : logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates )) return v def old__call__ ( self , coordinates ) : coordinates = coordinates . copy () - np . array ( [ 0,self.rotation,self.rotation ] ) coordinates [ 1 ]%= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) dist , ind = self . tree . query ( coordinates , k = 2 ) d1 , d2 = dist . T v1 , v2 = self . values [ ind ] if d1 == 0 : return v1 elif d2 == 0 : return v2 else : v = ( d1 ) / ( d1 + d2 ) * ( v2 - v1 ) + v1 #print ( self . rotation , coordinates , v ) v [ 1 ]+= self . rotation v [ 1 ]%= 2 * np . pi return v Methods old__call__ def old__call__ ( self , coordinates ) View Source def old__call__ ( self , coordinates ) : coordinates = coordinates . copy () - np . array ( [ 0,self.rotation,self.rotation ] ) coordinates [ 1 ]%= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) dist , ind = self . tree . query ( coordinates , k = 2 ) d1 , d2 = dist . T v1 , v2 = self . values [ ind ] if d1 == 0 : return v1 elif d2 == 0 : return v2 else : v = ( d1 ) / ( d1 + d2 ) * ( v2 - v1 ) + v1 #print ( self . rotation , coordinates , v ) v [ 1 ]+= self . rotation v [ 1 ]%= 2 * np . pi return v","title":"Interpolators"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#module-srcexternalforcesoptical_interpolatorsinterpolators","text":"Created on Mon Mar 4 12:01:37 2024 View Source # -*- coding: utf-8 -*- \"\"\" Created on Mon Mar 4 12:01:37 2024 @author: Mark Kalsbeek \"\"\" from typing import Callable import logging from functools import lru_cache import os.path import numpy as np import numpy.typing as npt from scipy.interpolate import LinearNDInterpolator , RegularGridInterpolator from scipy.interpolate import griddata from scipy.spatial import KDTree import matplotlib.pyplot as plt from src.particleSystem.ParticleSystem import ParticleSystem from src.ExternalForces.OpticalForceCalculator import wrap_spherical_coordinates # Setup path for abs. file imports my_path = os . path . abspath ( os . path . dirname ( __file__ )) PhC_library = { 'dummy' : 'dummy.csv' , 'Gao' : 'PhC_Gao_et_al.csv' , 'Mark_2' : 'Mark_2_export.csv' , 'Mark_3' : 'Mark_3_export.csv' , 'Mark_4' : 'Mark_4_export.csv' , 'Mark_4.1' : 'Mark_4.1_export.csv' , 'Mark_5' : 'Mark_5_export.csv' , 'Mark_6' : 'Mark_6.csv' , 'Mark_7' : 'Mark_7_export.csv' , 'Mark_8' : 'Mark_8_export.csv' , 'Mark_9' : 'Mark_9_export.csv' } def create_interpolator_specular () -> Callable : polar_in = np . linspace ( 0 , np . pi , 10 ) azimuth_in = np . linspace ( 0 , 2 * np . pi , 10 ) polarization_in = np . linspace ( 0 , np . pi / 2 , 10 ) polar_in , azimuth_in , polarization_in = np . meshgrid ( polar_in , azimuth_in , polarization_in ) polar_in = polar_in . reshape ([ 1000 , 1 ]) azimuth_in = azimuth_in . reshape ([ 1000 , 1 ]) polarization_in = polarization_in . reshape ([ 1000 , 1 ]) incidence = np . hstack (( polar_in , azimuth_in , polarization_in )) polar_out = polar_in azimuth_out = np . pi + azimuth_in azimuth_out = azimuth_out % ( 2 * np . pi ) magnitude = np . ones ( azimuth_out . shape ) out = np . hstack (( polar_out , azimuth_out , magnitude )) optical_interpolator = LinearNDInterpolator ( incidence , out ) return optical_interpolator def create_interpolator ( fname : str , rotation : float = 0 ) -> Callable : \"\"\" create interpolator from simulation data Parameters ---------- fname : string Path to the data. rotation : float Rotation around z+ axis of photonic crystal. Allows to represent crystal in different oriantations. [rad] Returns ------- Callable Interpolator for optical behaviour. \"\"\" path = os . path . join ( my_path , fname ) data = np . loadtxt ( path , delimiter = ',' , comments = '#' ) incidence = data [:,: 3 ] out = data [:, 3 :] if not np . any ( np . pi * 2 in incidence [:, 1 ]): mask = incidence [:, 1 ] == 0 in_dupes = incidence . copy ()[ mask ] out_dupes = out . copy ()[ mask ] in_dupes [:, 1 ] += 2 * np . pi incidence = np . vstack (( incidence , in_dupes )) out = np . vstack (( out , out_dupes )) return linear_interpolator ( incidence , out , rotation , name = fname ) class linear_interpolator (): \"\"\" maps [theta, phi, pol] to [theta, phi, mag] cache_values : bool enables lru caching for call function. Note, you only want to use caching if you are feeding coordinate tuples. Breaks when numpy arrays are fed in! \"\"\" def __init__ ( self , coordinates , values , rotation , cache_values = False , name = None ): self . coordinates = coordinates self . cache_values = cache_values self . values = values self . tree = KDTree ( coordinates ) self . rotation = rotation self . interp = LinearNDInterpolator ( coordinates , values ) if self . cache_values : self . __call__ = lru_cache ( maxsize = None )( self . __call__ ) def __call__ ( self , coordinates ): #coordinates = coordinates.copy()-np.array([0,self.rotation,self.rotation]) coordinates = coordinates - np . array ([ 0 , self . rotation , self . rotation ]) if len ( coordinates . shape ) > 1 : coordinates = np . round ( coordinates , 8 ) coordinates [:, 1 ] %= 2 * np . pi pol = coordinates [:, 2 ] x = np . abs ( np . cos ( pol )) y = np . abs ( np . sin ( pol )) coordinates [:, 2 ] = np . arctan ( y / x ) v = self . interp ( coordinates ) v [:, 1 ] += self . rotation v [:, 1 ] %= 2 * np . pi if np . any ( np . isnan ( v )): for i , line in enumerate ( v ): if np . any ( np . isnan ( line )): logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates [ i ,:])) v = np . nan_to_num ( v ) else : coordinates [ 1 ] %= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) v = self . interp ( coordinates )[ 0 ] v [ 1 ] += self . rotation v [ 1 ] %= 2 * np . pi if any ( np . isnan ( v )): logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates )) return v def old__call__ ( self , coordinates ): coordinates = coordinates . copy () - np . array ([ 0 , self . rotation , self . rotation ]) coordinates [ 1 ] %= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) dist , ind = self . tree . query ( coordinates , k = 2 ) d1 , d2 = dist . T v1 , v2 = self . values [ ind ] if d1 == 0 : return v1 elif d2 == 0 : return v2 else : v = ( d1 ) / ( d1 + d2 ) * ( v2 - v1 ) + v1 #print(self.rotation, coordinates, v) v [ 1 ] += self . rotation v [ 1 ] %= 2 * np . pi return v def check_interpolator ( interp , coordinates , ax = None ): theta , phi , pol = coordinates theta_out , phi_out , pol_out = wrap_spherical_coordinates ( * [ np . array ( i , dtype = float ) for i in coordinates ]) theta_out , phi_out , mag_out = interp ([ theta_out , phi_out , pol_out ]) in_x = np . sin ( theta ) * np . cos ( phi ) in_y = np . sin ( theta ) * np . sin ( phi ) in_z = np . cos ( theta ) out_x = np . sin ( theta_out ) * np . cos ( phi_out ) * mag_out out_y = np . sin ( theta_out ) * np . sin ( phi_out ) * mag_out out_z = np . cos ( theta_out ) * mag_out if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax . set_xlim (( - 1 , 1 )) ax . set_ylim (( - 1 , 1 )) ax . set_zlim (( - 1 , 1 )) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) ax . set_zlabel ( 'z' ) ax . set_aspect ( 'equal' ) ax . quiver ( 0 , 0 , 0 , - in_x , - in_y , - in_z , label = 'incident ray' , color = 'y' , pivot = 'tip' ) ax . quiver ( 0 , 0 , 0 , out_x , out_y , out_z , label = 'net scattered ray' , color = 'r' , pivot = 'tail' ) ax . legend () # PhC_specular = create_interpolator_specular() # PhC_Gao = create_interpolator(crystal_dict['Gao']) if __name__ == '__main__' : dummy = create_interpolator ( PhC_library [ 'dummy' ], 0 ) dummy = create_interpolator ( PhC_library [ 'Mark_4.1' ], 0 ) fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) for theta in np . linspace ( np . deg2rad ( - 15 ), np . deg2rad ( 15 ), 5 ): vec = [ theta , np . pi , 0 ] check_interpolator ( dummy , vec , ax ) print ( vec , \" \\t \" , dummy ( vec )) print ( wrap_spherical_coordinates ( * [ np . array ( i , dtype = float ) for i in vec ])) fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax . set_title ( 'Demonstrate sampled points' ) ax . set_xlim (( - 0.5 , 0.5 )) ax . set_ylim (( - 0.5 , 0.5 )) ax . set_zlim (( - 1 , 1 )) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) ax . set_zlabel ( 'z' ) ax . set_aspect ( 'equal' ) mask = np . isclose ( dummy . coordinates [:, 2 ], np . pi / 2 ) out = dummy . values [ mask ] incidence = dummy . coordinates [ mask ] theta = incidence [:, 0 ] phi = incidence [:, 1 ] n_x = np . sin ( theta ) * np . cos ( phi ) n_y = np . sin ( theta ) * np . sin ( phi ) n_z = np . cos ( theta ) theta_out = out [:, 0 ] phi_out = out [:, 1 ] mag_out = out [:, 2 ] s_x = np . sin ( theta_out ) * np . cos ( phi_out ) * mag_out s_y = np . sin ( theta_out ) * np . sin ( phi_out ) * mag_out s_z = np . cos ( theta_out ) * mag_out ax . quiver ( 0 , 0 , 0 , - n_x , - n_y , - n_z , label = 'incident ray' , color = 'y' , pivot = 'tip' ) ax . quiver ( 0 , 0 , 0 , s_x , s_y , s_z , label = 'net scattered ray' , color = 'r' , pivot = 'tail' ) ax . legend ()","title":"Module src.ExternalForces.optical_interpolators.interpolators"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#variables","text":"PhC_library my_path","title":"Variables"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#functions","text":"","title":"Functions"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#check_interpolator","text":"def check_interpolator ( interp , coordinates , ax = None ) View Source def check_interpolator ( interp , coordinates , ax = None ): theta , phi , pol = coordinates theta_out , phi_out , pol_out = wrap_spherical_coordinates ( * [ np . array ( i , dtype = float ) for i in coordinates ]) theta_out , phi_out , mag_out = interp ([ theta_out , phi_out , pol_out ]) in_x = np . sin ( theta ) * np . cos ( phi ) in_y = np . sin ( theta ) * np . sin ( phi ) in_z = np . cos ( theta ) out_x = np . sin ( theta_out ) * np . cos ( phi_out ) * mag_out out_y = np . sin ( theta_out ) * np . sin ( phi_out ) * mag_out out_z = np . cos ( theta_out ) * mag_out if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = ' 3 d ' ) ax . set_xlim (( - 1 , 1 )) ax . set_ylim (( - 1 , 1 )) ax . set_zlim (( - 1 , 1 )) ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) ax . set_zlabel ( 'z' ) ax . set_aspect ( ' equal ' ) ax . quiver ( 0 , 0 , 0 , - in_x , - in_y , - in_z , label = ' incident ray ' , color = 'y' , pivot = ' tip ' ) ax . quiver ( 0 , 0 , 0 , out_x , out_y , out_z , label = ' net scattered ray ' , color = 'r' , pivot = ' tail ' ) ax . legend ()","title":"check_interpolator"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#create_interpolator","text":"def create_interpolator ( fname : str , rotation : float = 0 ) -> Callable create interpolator from simulation data Parameters: Name Type Description Default fname string Path to the data. None rotation float Rotation around z+ axis of photonic crystal. Allows to represent crystal in different oriantations. [rad] None Returns: Type Description Callable Interpolator for optical behaviour. View Source def create_interpolator ( fname : str , rotation : float = 0 ) -> Callable : \"\"\" create interpolator from simulation data Parameters ---------- fname : string Path to the data. rotation : float Rotation around z+ axis of photonic crystal. Allows to represent crystal in different oriantations. [rad] Returns ------- Callable Interpolator for optical behaviour. \"\"\" path = os . path . join ( my_path , fname ) data = np . loadtxt ( path , delimiter = ',' , comments = '#' ) incidence = data [ :,:3 ] out = data [ :,3: ] if not np . any ( np . pi * 2 in incidence [ :,1 ] ) : mask = incidence [ :,1 ] == 0 in_dupes = incidence . copy () [ mask ] out_dupes = out . copy () [ mask ] in_dupes [ :,1 ] += 2 * np . pi incidence = np . vstack (( incidence , in_dupes )) out = np . vstack (( out , out_dupes )) return linear_interpolator ( incidence , out , rotation , name = fname )","title":"create_interpolator"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#create_interpolator_specular","text":"def create_interpolator_specular ( ) -> Callable View Source def create_interpolator_specular () -> Callable : polar_in = np . linspace ( 0 , np . pi , 10 ) azimuth_in = np . linspace ( 0 , 2 * np . pi , 10 ) polarization_in = np . linspace ( 0 , np . pi / 2 , 10 ) polar_in , azimuth_in , polarization_in = np . meshgrid ( polar_in , azimuth_in , polarization_in ) polar_in = polar_in . reshape ([ 1000 , 1 ]) azimuth_in = azimuth_in . reshape ([ 1000 , 1 ]) polarization_in = polarization_in . reshape ([ 1000 , 1 ]) incidence = np . hstack (( polar_in , azimuth_in , polarization_in )) polar_out = polar_in azimuth_out = np . pi + azimuth_in azimuth_out = azimuth_out % ( 2 * np . pi ) magnitude = np . ones ( azimuth_out . shape ) out = np . hstack (( polar_out , azimuth_out , magnitude )) optical_interpolator = LinearNDInterpolator ( incidence , out ) return optical_interpolator","title":"create_interpolator_specular"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#classes","text":"","title":"Classes"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#linear_interpolator","text":"class linear_interpolator ( coordinates , values , rotation , cache_values = False , name = None ) maps [theta, phi, pol] to [theta, phi, mag] cache_values : bool enables lru caching for call function. Note, you only want to use caching if you are feeding coordinate tuples. Breaks when numpy arrays are fed in! View Source class linear_interpolator () : \"\"\" maps [theta, phi, pol] to [theta, phi, mag] cache_values : bool enables lru caching for call function. Note, you only want to use caching if you are feeding coordinate tuples. Breaks when numpy arrays are fed in! \"\"\" def __init__ ( self , coordinates , values , rotation , cache_values = False , name = None ) : self . coordinates = coordinates self . cache_values = cache_values self . values = values self . tree = KDTree ( coordinates ) self . rotation = rotation self . interp = LinearNDInterpolator ( coordinates , values ) if self . cache_values : self . __call__ = lru_cache ( maxsize = None )( self . __call__ ) def __call__ ( self , coordinates ) : #coordinates = coordinates . copy () - np . array ( [ 0,self.rotation,self.rotation ] ) coordinates = coordinates - np . array ( [ 0,self.rotation,self.rotation ] ) if len ( coordinates . shape ) > 1 : coordinates = np . round ( coordinates , 8 ) coordinates [ :,1 ]%= 2 * np . pi pol = coordinates [ :,2 ] x = np . abs ( np . cos ( pol )) y = np . abs ( np . sin ( pol )) coordinates [ :,2 ] = np . arctan ( y / x ) v = self . interp ( coordinates ) v [ :,1 ]+= self . rotation v [ :,1 ]%= 2 * np . pi if np . any ( np . isnan ( v )) : for i , line in enumerate ( v ) : if np . any ( np . isnan ( line )) : logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates [ i,: ] )) v = np . nan_to_num ( v ) else : coordinates [ 1 ]%= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) v = self . interp ( coordinates ) [ 0 ] v [ 1 ]+= self . rotation v [ 1 ]%= 2 * np . pi if any ( np . isnan ( v )) : logging . warning ( \"Interpolation error resulting in nan values for input \" + str ( coordinates )) return v def old__call__ ( self , coordinates ) : coordinates = coordinates . copy () - np . array ( [ 0,self.rotation,self.rotation ] ) coordinates [ 1 ]%= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) dist , ind = self . tree . query ( coordinates , k = 2 ) d1 , d2 = dist . T v1 , v2 = self . values [ ind ] if d1 == 0 : return v1 elif d2 == 0 : return v2 else : v = ( d1 ) / ( d1 + d2 ) * ( v2 - v1 ) + v1 #print ( self . rotation , coordinates , v ) v [ 1 ]+= self . rotation v [ 1 ]%= 2 * np . pi return v","title":"linear_interpolator"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#methods","text":"","title":"Methods"},{"location":"reference/src/ExternalForces/optical_interpolators/interpolators/#old__call__","text":"def old__call__ ( self , coordinates ) View Source def old__call__ ( self , coordinates ) : coordinates = coordinates . copy () - np . array ( [ 0,self.rotation,self.rotation ] ) coordinates [ 1 ]%= 2 * np . pi pol = coordinates [ 2 ] x = abs ( np . cos ( pol )) y = abs ( np . sin ( pol )) coordinates [ 2 ] = np . arctan ( y / x ) dist , ind = self . tree . query ( coordinates , k = 2 ) d1 , d2 = dist . T v1 , v2 = self . values [ ind ] if d1 == 0 : return v1 elif d2 == 0 : return v2 else : v = ( d1 ) / ( d1 + d2 ) * ( v2 - v1 ) + v1 #print ( self . rotation , coordinates , v ) v [ 1 ]+= self . rotation v [ 1 ]%= 2 * np . pi return v","title":"old__call__"},{"location":"reference/src/Mesh/mesh_functions/","text":"Module src.Mesh.mesh_functions Created on Fri Dec 15 12:27:53 2023 View Source # -*- coding : utf - 8 -*- \"\"\" Created on Fri Dec 15 12:27:53 2023 @author: Mark Kalsbeek \"\"\" import numpy as np from scipy . spatial . transform import Rotation as R from .. particleSystem . SpringDamper import SpringDamperType params = { # model parameters \"k\" : 1 , # [ N / m ] spring stiffness \"k_d\" : 1 , # [ N / m ] spring stiffness \"c\" : 1 , # [ N s / m ] damping coefficient \"m_segment\" : 1 , # [ kg ] mass of each node } def mesh_square ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_square_cross ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_square_cross_sparse ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further flip = True for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections if flip : connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) flip = False else : connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) flip = True else : flip = not flip # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_square_concentric ( length , mesh_edge_length , params = params , fix_outer = False ) : n_long = int ( length / mesh_edge_length + 1 ) x_space = np . linspace ( - length / 2 , length / 2 , n_long ) y_space = x_space mesh = np . meshgrid ( x_space , y_space ) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : if ( abs ( xyz [ 0 ]) == length / 2 and abs ( xyz [ 1 ]) == length / 2 ) and fix_outer : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], True ]) else : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] dia_counter = [ 0 , n_long - 2 ] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis if abs ( node [ 0 ][ 0 ]) > abs ( node [ 0 ][ 1 ]) : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if abs ( node [ 0 ][ 0 ]) >= abs ( node [ 0 ][ 1 ]) and node [ 0 ][ 1 ] < 0 : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if dia_counter [ 0 ] == i : #cross connections dia_counter [ 0 ] += n_long + 1 connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) if dia_counter [ 1 ] == i : dia_counter [ 1 ] += n_long - 1 connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long) and abs(node[0][0])<=abs(node[0][1]) and node[0][0]<0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) elif ( i + 1 ) %(n_long) and abs(node[0][0])<abs(node[0][1]) and node[0][0]>=0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_airbag_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False ) : if sparse : meshfunct = mesh_square_cross_sparse else : meshfunct = mesh_square_cross if width == 0 : width = length initial_conditions , connections = meshfunct ( length , width , mesh_edge_length , params ) # We iterate over the particle and set specific constraint conditions # to match the symmetry of the airbag being cut into 8 pieces for particle in initial_conditions : # sequence of if / elif statements matters becuase some of the used # critera can override others . # Fixing s . t . center node only move in z axis if ( particle [ 0 ] == [ 0 , 0 , 0 ]). all () : particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( 'line' ) elif particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ] == 0 : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( 'line' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ] == length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( 'line' ) elif ( ( particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ] > 0 ) or ( particle [ 0 ][ 1 ] == width and particle [ 0 ][ 0 ] > 0 ) ) : particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( 'plane' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ] > 0 and particle [ 0 ][ 1 ] < length : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( 'plane' ) elif particle [ 0 ][ 1 ] == 0 and particle [ 0 ][ 0 ] > 0 and particle [ 0 ][ 0 ] < length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( 'plane' ) if noncompressive : linktype = SpringDamperType . NONCOMPRESSIVE for link in connections : link . append ( linktype ) return connections , initial_conditions def mesh_phc_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False , fix_outer = True , center_lightsail = True ) : required = [ 'E_x' , 'E_y' , \"G\" , \"thickness\" ] for key in required : if not key in params . keys () : raise KeyError ( f \"{key} missing from params\" ) if width == 0 : width = length n_wide = int ( width / mesh_edge_length + 1 ) # x count n_long = int ( length / mesh_edge_length + 1 ) # y count x_length = width / n_wide y_length = length / n_long # Calculate k's from the given stifnesses # First calculate the diagnonal, it is required in the calculation of the orthogonal ones params[\"k_d\"] = params[\"G\"] * params[\"thickness\"] * x_length / (y_length*n_wide/np.sqrt(2)) params[\"k_x\"] = params[\"E_x\"] * params[\"thickness\"] params[\"k_y\"] = params[\"E_y\"] * params[\"thickness\"] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params[\"k_x\"]*= params[\"k_x\"]*n_long / (params[\"k_x\"]*n_long + params[\"k_d\"]*np.sqrt(2)*n_long) params[\"k_y\"]*= params[\"k_y\"]*n_wide / (params[\"k_y\"]*n_wide + params[\"k_d\"]*np.sqrt(2)*n_wide) # Perform the meshing mesh = np.meshgrid(np.linspace(0, length, n_long), np.linspace(0, width, n_wide)) initial_conditions = [] xy_coordinates = np.column_stack(list(zip(mesh[0],mesh[1]))).T xyz_coordinates = np.column_stack((xy_coordinates,np.zeros(len(xy_coordinates)).T)) for xyz in xyz_coordinates: if (fix_outer and (xyz[0] == 0 or xyz[0] == length or xyz[1] == 0 or xyz[1] == width)): initial_conditions.append([xyz, np.zeros(3), params['m_segment'], True]) else: initial_conditions.append([xyz, np.zeros(3), params['m_segment'], False]) neglect_diagonals = False if params[\"G\"] == 0: neglect_diagonals = True connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i, node in enumerate(initial_conditions[:-n_long]): # adding connextions in y-axis connections.append([i, i+n_long, params['k_y'], params['c']]) if (i+1)%(n_long) and not neglect_diagonals: #cross connections connections.append([i, i+n_long+1, params['k_d'], params['c']]) connections.append([i+1, i+n_long, params['k_d'], params['c']]) # We can do the same for the connections between the columns for i, node in enumerate(initial_conditions): # adding connections in x-axis if (i+1)%(n_long): # Using modulus operator to exclude the nodes at the end of a row connections.append([i, i+1, params['k_x'], params['c']]) if noncompressive: linktype = SpringDamperType.NONCOMPRESSIVE for link in connections: link.append(linktype) if center_lightsail: offset = np.array([width/2, length/2,0]) for p in initial_conditions: p[0] -= offset return connections, initial_conditions def mesh_circle_square_cross(radius, mesh_edge_length, params = params, fix_outer = False, edge = 0): n_wide = int(radius/ mesh_edge_length + 1) n_long = n_wide mesh = np.meshgrid(np.linspace(-radius, radius, n_long), np.linspace(-radius, radius, n_wide)) initial_conditions = [] xy_coordinates = np.column_stack(list(zip(mesh[0],mesh[1]))).T xyz_coordinates = np.column_stack((xy_coordinates,np.zeros(len(xy_coordinates)).T)) for xyz in xyz_coordinates: initial_conditions.append([xyz, np.zeros(3), params['m_segment'], False]) connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i, node in enumerate(initial_conditions[:-n_long]): # adding connextions in y-axis connections.append([i, i+n_long, params['k'], params['c']]) if (i+1)%(n_long): #cross connections connections.append([i, i+n_long+1, params['k_d'], params['c']]) connections.append([i+1, i+n_long, params['k_d'], params['c']]) # We can do the same for the connections between the columns for i, node in enumerate(initial_conditions): # adding connections in x-axis if (i+1)%(n_long): # Using modulus operator to exclude the nodes at the end of a row connections.append([i, i+1, params['k'], params['c']]) # Now to trim the excess nodes and connections mask = xy_coordinates[:,0]**2 + xy_coordinates[:,1]**2 <= radius**2 dumplist = [] for i, keepit in enumerate(mask): if not keepit: initial_conditions[i][3]= True # print(f' Iterating point { i } ') for j, link in enumerate(connections): if i in link[:2]: # print(f'dumping link { j } for being connected to { i } : { link } ') dumplist.append(j) dumplist = list(set(dumplist)) dumplist = sorted(dumplist)[::-1] # print(f'dumplist length : { len ( set ( dumplist ))} \\n { dumplist [ ::- 1 ]} ') # print(f'connections length : { len ( connections )} ') for i in dumplist: del connections[i] #for i, item in enumerate(initial_conditions): # if mask[i]: # del initial_conditions[i] if fix_outer: if edge == 0: edge = mesh_edge_length * 1.5 inner = xy_coordinates[:,0]**2 + xy_coordinates[:,1]**2 <= (radius-edge)**2 for i, freeit in enumerate(inner): if not freeit: initial_conditions[i][3]= True return connections, initial_conditions def mesh_round_phc_square_cross(radius, mesh_edge_length=1/10, params=None, noncompressive=False, sparse=False, fix_outer=True, edge=0): if params is None: params = {} required = [' E_x ', ' E_y ', \"G\", \"thickness\", \"m_segment\", \"c\"] for key in required: if key not in params.keys(): raise KeyError(f\"{key} missing from params\") # Calculating grid dimensions n_wide = int(2*radius / mesh_edge_length) + 1 n_long = n_wide y_length = radius/n_long x_length = y_length mesh = np.meshgrid(np.linspace(-radius, radius, n_long), np.linspace(-radius, radius, n_wide)) xy_coordinates = np.column_stack([mesh[0].flatten(), mesh[1].flatten()]) mask = xy_coordinates[:,0]**2 + xy_coordinates[:,1]**2 <= radius**2 filtered_xy_coordinates = xy_coordinates[mask] xyz_coordinates = np.column_stack((filtered_xy_coordinates, np.zeros(len(filtered_xy_coordinates)))) initial_conditions = [[xyz, np.zeros(3), params['m_segment'], False] for xyz in xyz_coordinates] # Calculate k's from the given stifnesses # First calculate the diagnonal , it is required in the calculation of the orthogonal ones params [ \"k_d\" ] = params [ \"G\" ] * params [ \"thickness\" ] * x_length / ( y_length * n_wide / np . sqrt ( 2 )) params [ \"k_x\" ] = params [ \"E_x\" ] * params [ \"thickness\" ] params [ \"k_y\" ] = params [ \"E_y\" ] * params [ \"thickness\" ] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params [ \"k_x\" ] *= params [ \"k_x\" ] * n_long / ( params [ \"k_x\" ] * n_long + params [ \"k_d\" ] * np . sqrt ( 2 ) * n_long ) params [ \"k_y\" ] *= params [ \"k_y\" ] * n_wide / ( params [ \"k_y\" ] * n_wide + params [ \"k_d\" ] * np . sqrt ( 2 ) * n_wide ) connections = [] for i , cond_i in enumerate ( initial_conditions ) : for j , cond_j in enumerate ( initial_conditions [ i + 1 : ], start = i + 1 ) : distance = np . linalg . norm ( cond_i [ 0 ][ : 2 ] - cond_j [ 0 ][ : 2 ]) / 1.01 if distance <= mesh_edge_length : # Direct neighbors k_value = params [ 'k_x' ] if cond_i [ 0 ][ 1 ] == cond_j [ 0 ][ 1 ] else params [ 'k_y' ] connection = [ i , j , k_value , params [ 'c' ]] if noncompressive : connection . append ( SpringDamperType . NONCOMPRESSIVE ) connections . append ( connection ) elif distance <= mesh_edge_length * np . sqrt ( 2 ) and params [ \"G\" ]! = 0 : # Diagonal connections only if G ! = 0 connection = [ i , j , params [ 'k_d' ], params [ 'c' ]] if noncompressive : connection . append ( SpringDamperType . NONCOMPRESSIVE ) connections . append ( connection ) # Optionally fix the outer nodes if fix_outer : if edge == 0 : edge = mesh_edge_length * 1.5 for i , cond in enumerate ( initial_conditions ) : if np . linalg . norm ( cond [ 0 ][ : 2 ]) >= radius - edge : initial_conditions [ i ][ 3 ] = True # Mark as fixed / non - movable return connections , initial_conditions def mesh_rotate_and_trim ( initial_conditions , connections , angle ) : \"\"\" NOTE: Input mesh is expected to be square! \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype ='float64' ) for particle in initial_conditions : center_of_mass+=particle [ 0 ] center_of_mass = center_of_mass / len ( initial_conditions ) x_cleaned = np . array ([ i [ 0 ] for i in initial_conditions ]) x_range , y_range , z_range = np . ptp ( x_cleaned , axis = 0 ) # rotation shrinks size of inscribed rectangle # Going for constant angle for consistent size factor = np . cos ( np . deg2rad ( 45 )) x_range *= factor y_range *= factor rotation_matrix = R . from_euler ( 'z' , angle , degrees = True ). as_matrix () for particle in initial_conditions : particle [ 0 ] -= center_of_mass particle [ 0 ] = rotation_matrix . dot ( particle [ 0 ]) dumplist = set () for i , link in enumerate ( connections ) : xyz_0 = initial_conditions [ link [ 0 ]][ 0 ] xyz_1 = initial_conditions [ link [ 1 ]][ 0 ] if abs ( xyz_0 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_0 [ 1 ]) > y_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 1 ]) > y_range / 2 : dumplist . add ( i ) dumplist = list ( dumplist ) dumplist . sort () for i in dumplist [ ::- 1 ] : del connections [ i ] return connections , initial_conditions def ps_fix_opposite_boundaries_x ( ParticleSystem , margin = 0.075 ) : \"\"\" Fixes two boundaries in preparation for unidirectional pull test \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype ='float64' ) for particle in ParticleSystem . particles : center_of_mass+=particle . x center_of_mass = center_of_mass / len ( ParticleSystem . particles ) x_cleaned = np . array ([ particle . x [ 0 ] for particle in ParticleSystem . particles ]) x_range = np . ptp ( x_cleaned , axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) boundary_x_min = [] boundary_x_plus = [] for i , particle in enumerate ( ParticleSystem . particles ) : if abs ( particle . x [ 0 ]) > (( x_range / 2 ) * ( 1 - margin )) : particle . set_fixed ( True ) if particle . x [ 0 ] > 0 : boundary_x_plus . append ( i ) else : boundary_x_min . append ( i ) boundaries = [ boundary_x_min , boundary_x_plus ] return ParticleSystem , boundaries def ps_stretch_in_x ( ParticleSystem , boundary , displacement ) : for indice in boundary : particle = ParticleSystem . particles [ indice ] new_pos = particle . x new_pos [ 0 ] += displacement particle . update_pos ( new_pos ) def ps_find_reaction_of_boundary ( ParticleSystem , boundary ) : # !!! ATTENTION !!! DRAFT CODE ! COMPLETLY UNTESTED ! internal_forces = ParticleSystem . _ ParticleSystem__one_d_force_vector () reaction = np . array ([ 0.0 , 0.0 , 0.0 ]) for indice in boundary : reaction += internal_forces [ indice * 3 : indice * 3 + 3 ] return reaction def ps_find_mid_strip_y ( ParticleSystem , width = 1 ) : center_of_mass = np . mean ( ParticleSystem . x_v_current_3D [ 0 ], axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) midstrip = [] for i , particle in enumerate ( ParticleSystem . particles ) : pos = particle . x if abs ( pos [ 0 ]) <= width / 2 : midstrip . append ( i ) return midstrip def ps_find_strip_dimentions ( ParticleSystem , midstrip ) : positions = [] for indice in midstrip : particle = ParticleSystem . particles [ indice ] positions . append ( particle . x ) positions = np . array ( positions ) point_to_point_range = np . ptp ( positions , axis = 0 ) return point_to_point_range if __ name__ == '__main__' : from src . particleSystem . ParticleSystem import ParticleSystem import matplotlib . pyplot as plt params = { # model parameters \"k\" : 1 , # [ N / m ] spring stiffness \"k_d\" : 1 , # [ N / m ] spring stiffness for diagonal elements \"c\" : 1 , # [ N s / m ] damping coefficient \"m_segment\" : 1 , # [ kg ] mass of each node # simulation settings \"dt\" : 0.1 , # [ s ] simulation timestep \"t_steps\" : 1000 , # [ - ] number of simulated time steps \"abs_tol\" : 1 e - 50 , # [ m / s ] absolute error tolerance iterative solver \"rel_tol\" : 1 e - 5 , # [ - ] relative error tolerance iterative solver \"max_iter\" : 1 e5 , # [ - ] maximum number of iterations \"E_x\" : 100 e9 , # [ Pa ] \"E_y\" : 100 e9 , # [ Pa ] \"G\" : 0 , # [ Pa ] \"thickness\" : 100 e - 9 # [ m ] } # !!! Don 't forget to add new meshing functions to this list! meshing_functions = [mesh_square, mesh_square_cross, mesh_square_cross_sparse, mesh_airbag_square_cross, mesh_square_concentric, mesh_circle_square_cross, mesh_round_phc_square_cross] inputs = [16,8,1, params] nplots = len(meshing_functions) + 1 cols = int(np.sqrt(nplots)) +1 rows = nplots // cols if nplots % cols !=0: rows +=1 fig = plt.figure() pslist = [] for i, function in enumerate(meshing_functions): ax = fig.add_subplot(rows, cols,i+1,projection=' 3 d') ax.set_box_aspect([1,1,1]) if i ==4: inputs = inputs[1:] initial_conditions, connections = function(*inputs) PS = ParticleSystem(connections, initial_conditions, params) pslist.append(PS) PS.plot(ax) ax.set_title(function.__name__) initial_conditions, connections = mesh_square_cross(20,20,1,params) initial_conditions, connections = mesh_rotate_and_trim(initial_conditions, connections, 45/2) PS = ParticleSystem(connections, initial_conditions,params) PS, boundaries = ps_fix_opposite_boundaries_x(PS, margin = 0.175) ps_stretch_in_x(PS, boundaries[1], 1) pslist.append(PS) ax = fig.add_subplot(rows, cols, nplots, projection=' 3 d ' ) PS . plot ( ax ) ax . set_title (( mesh_square_cross . __ name__ , mesh_rotate_and_trim . __ name__ , ps_fix_opposite_boundaries_x . __ name__ , ps_stretch_in_x . __ name__ )) Variables params Functions mesh_airbag_square_cross def mesh_airbag_square_cross ( length , width = 0 , mesh_edge_length = 0.1 , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, noncompressive = False , sparse = False ) View Source def mesh_airbag_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False ): if sparse : meshfunct = mesh_square_cross_sparse else : meshfunct = mesh_square_cross if width == 0 : width = length initial_conditions , connections = meshfunct ( length , width , mesh_edge_length , params ) # We iterate over the particle and set specific constraint conditions # to match the symmetry of the airbag being cut into 8 pieces for particle in initial_conditions : # sequence of if / elif statements matters becuase some of the used # critera can override others . # Fixing s . t . center node only move in z axis if ( particle [ 0 ] == [ 0 , 0 , 0 ]). all (): particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( ' line ' ) elif particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ] == 0 : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( ' line ' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ] == length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( ' line ' ) elif ( ( particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ]> 0 ) or ( particle [ 0 ][ 1 ] == width and particle [ 0 ][ 0 ]> 0 ) ): particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( ' plane ' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ]> 0 and particle [ 0 ][ 1 ]< length : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( ' plane ' ) elif particle [ 0 ][ 1 ] == 0 and particle [ 0 ][ 0 ]> 0 and particle [ 0 ][ 0 ]< length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( ' plane ' ) if noncompressive : linktype = SpringDamperType . NONCOMPRESSIVE for link in connections : link . append ( linktype ) return connections , initial_conditions mesh_circle_square_cross def mesh_circle_square_cross ( radius , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, fix_outer = False , edge = 0 ) View Source def mesh_circle_square_cross ( radius , mesh_edge_length , params = params , fix_outer = False , edge = 0 ) : n_wide = int ( radius / mesh_edge_length + 1 ) n_long = n_wide mesh = np . meshgrid ( np . linspace ( - radius , radius , n_long ), np . linspace ( - radius , radius , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) # Now to trim the excess nodes and connections mask = xy_coordinates [ : , 0 ] ** 2 + xy_coordinates [ : , 1 ] ** 2 <= radius** 2 dumplist = [] for i , keepit in enumerate ( mask ) : if not keepit : initial_conditions [ i ][ 3 ] = True # print ( f'Iterating point {i}' ) for j , link in enumerate ( connections ) : if i in link [ : 2 ] : # print ( f'dumping link {j} for being connected to {i}: {link}' ) dumplist . append ( j ) dumplist = list ( set ( dumplist )) dumplist = sorted ( dumplist )[ ::- 1 ] # print ( f'dumplist length: {len(set(dumplist))}\\n{dumplist[::-1]}' ) # print ( f'connections length: {len(connections)}' ) for i in dumplist : del connections [ i ] #for i , item in enumerate ( initial_conditions ) : # if mask [ i ] : # del initial_conditions [ i ] if fix_outer : if edge == 0 : edge = mesh_edge_length * 1.5 inner = xy_coordinates [ : , 0 ] ** 2 + xy_coordinates [ : , 1 ] ** 2 <= ( radius - edge ) ** 2 for i , freeit in enumerate ( inner ) : if not freeit : initial_conditions [ i ][ 3 ] = True return connections , initial_conditions mesh_phc_square_cross def mesh_phc_square_cross ( length , width = 0 , mesh_edge_length = 0.1 , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, noncompressive = False , sparse = False , fix_outer = True , center_lightsail = True ) View Source def mesh_phc_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False , fix_outer = True , center_lightsail = True ) : required = [ 'E_x' , 'E_y' , \"G\" , \"thickness\" ] for key in required : if not key in params . keys () : raise KeyError ( f \"{key} missing from params\" ) if width == 0 : width = length n_wide = int ( width / mesh_edge_length + 1 ) # x count n_long = int ( length / mesh_edge_length + 1 ) # y count x_length = width / n_wide y_length = length / n_long # Calculate k's from the given stifnesses # First calculate the diagnonal, it is required in the calculation of the orthogonal ones params[\"k_d\"] = params[\"G\"] * params[\"thickness\"] * x_length / (y_length*n_wide/np.sqrt(2)) params[\"k_x\"] = params[\"E_x\"] * params[\"thickness\"] params[\"k_y\"] = params[\"E_y\"] * params[\"thickness\"] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params[\"k_x\"]*= params[\"k_x\"]*n_long / (params[\"k_x\"]*n_long + params[\"k_d\"]*np.sqrt(2)*n_long) params[\"k_y\"]*= params[\"k_y\"]*n_wide / (params[\"k_y\"]*n_wide + params[\"k_d\"]*np.sqrt(2)*n_wide) # Perform the meshing mesh = np.meshgrid(np.linspace(0, length, n_long), np.linspace(0, width, n_wide)) initial_conditions = [] xy_coordinates = np.column_stack(list(zip(mesh[0],mesh[1]))).T xyz_coordinates = np.column_stack((xy_coordinates,np.zeros(len(xy_coordinates)).T)) for xyz in xyz_coordinates: if (fix_outer and (xyz[0] == 0 or xyz[0] == length or xyz[1] == 0 or xyz[1] == width)): initial_conditions.append([xyz, np.zeros(3), params['m_segment'], True]) else: initial_conditions.append([xyz, np.zeros(3), params['m_segment'], False]) neglect_diagonals = False if params[\"G\"] == 0: neglect_diagonals = True connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i, node in enumerate(initial_conditions[:-n_long]): # adding connextions in y-axis connections.append([i, i+n_long, params['k_y'], params['c']]) if (i+1)%(n_long) and not neglect_diagonals: #cross connections connections.append([i, i+n_long+1, params['k_d'], params['c']]) connections.append([i+1, i+n_long, params['k_d'], params['c']]) # We can do the same for the connections between the columns for i, node in enumerate(initial_conditions): # adding connections in x-axis if (i+1)%(n_long): # Using modulus operator to exclude the nodes at the end of a row connections.append([i, i+1, params['k_x'], params['c ' ]]) if noncompressive : linktype = SpringDamperType . NONCOMPRESSIVE for link in connections : link . append ( linktype ) if center_lightsail : offset = np . array ([ width / 2 , length / 2 , 0 ]) for p in initial_conditions : p [ 0 ] -= offset return connections , initial_conditions mesh_rotate_and_trim def mesh_rotate_and_trim ( initial_conditions , connections , angle ) NOTE: Input mesh is expected to be square! View Source def mesh_rotate_and_trim ( initial_conditions , connections , angle ) : \"\"\" NOTE: Input mesh is expected to be square! \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype ='float64' ) for particle in initial_conditions : center_of_mass+=particle [ 0 ] center_of_mass = center_of_mass / len ( initial_conditions ) x_cleaned = np . array ([ i [ 0 ] for i in initial_conditions ]) x_range , y_range , z_range = np . ptp ( x_cleaned , axis = 0 ) # rotation shrinks size of inscribed rectangle # Going for constant angle for consistent size factor = np . cos ( np . deg2rad ( 45 )) x_range *= factor y_range *= factor rotation_matrix = R . from_euler ( 'z' , angle , degrees = True ). as_matrix () for particle in initial_conditions : particle [ 0 ] -= center_of_mass particle [ 0 ] = rotation_matrix . dot ( particle [ 0 ]) dumplist = set () for i , link in enumerate ( connections ) : xyz_0 = initial_conditions [ link [ 0 ]][ 0 ] xyz_1 = initial_conditions [ link [ 1 ]][ 0 ] if abs ( xyz_0 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_0 [ 1 ]) > y_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 1 ]) > y_range / 2 : dumplist . add ( i ) dumplist = list ( dumplist ) dumplist . sort () for i in dumplist [ ::- 1 ] : del connections [ i ] return connections , initial_conditions mesh_round_phc_square_cross def mesh_round_phc_square_cross ( radius , mesh_edge_length = 0.1 , params = None , noncompressive = False , sparse = False , fix_outer = True , edge = 0 ) View Source def mesh_round_phc_square_cross ( radius , mesh_edge_length = 1 / 10 , params = None , noncompressive = False , sparse = False , fix_outer = True , edge = 0 ) : if params is None : params = {} required = [ 'E_x', 'E_y', \"G\", \"thickness\", \"m_segment\", \"c\" ] for key in required : if key not in params . keys () : raise KeyError ( f \"{key} missing from params\" ) # Calculating grid dimensions n_wide = int ( 2 * radius / mesh_edge_length ) + 1 n_long = n_wide y_length = radius / n_long x_length = y_length mesh = np . meshgrid ( np . linspace ( - radius , radius , n_long ), np . linspace ( - radius , radius , n_wide )) xy_coordinates = np . column_stack ( [ mesh[0 ] . flatten (), mesh [ 1 ] . flatten () ] ) mask = xy_coordinates [ :,0 ]** 2 + xy_coordinates [ :,1 ]** 2 <= radius ** 2 filtered_xy_coordinates = xy_coordinates [ mask ] xyz_coordinates = np . column_stack (( filtered_xy_coordinates , np . zeros ( len ( filtered_xy_coordinates )))) initial_conditions = [ [xyz, np.zeros(3), params['m_segment' ] , False ] for xyz in xyz_coordinates ] # Calculate k 's from the given stifnesses # First calculate the diagnonal, it is required in the calculation of the orthogonal ones params[\"k_d\"] = params[\"G\"] * params[\"thickness\"] * x_length / (y_length*n_wide/np.sqrt(2)) params[\"k_x\"] = params[\"E_x\"] * params[\"thickness\"] params[\"k_y\"] = params[\"E_y\"] * params[\"thickness\"] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params[\"k_x\"]*= params[\"k_x\"]*n_long / (params[\"k_x\"]*n_long + params[\"k_d\"]*np.sqrt(2)*n_long) params[\"k_y\"]*= params[\"k_y\"]*n_wide / (params[\"k_y\"]*n_wide + params[\"k_d\"]*np.sqrt(2)*n_wide) connections = [] for i, cond_i in enumerate(initial_conditions): for j, cond_j in enumerate(initial_conditions[i+1:], start=i+1): distance = np.linalg.norm(cond_i[0][:2] - cond_j[0][:2])/1.01 if distance <= mesh_edge_length: # Direct neighbors k_value = params[' k_x '] if cond_i[0][1] == cond_j[0][1] else params[' k_y '] connection = [i, j, k_value, params[' c ']] if noncompressive: connection.append(SpringDamperType.NONCOMPRESSIVE) connections.append(connection) elif distance <= mesh_edge_length * np.sqrt(2) and params[\"G\"]!=0: # Diagonal connections only if G != 0 connection = [i, j, params[' k_d '], params[' c ']] if noncompressive : connection . append ( SpringDamperType . NONCOMPRESSIVE ) connections . append ( connection ) # Optionally fix the outer nodes if fix_outer : if edge == 0 : edge = mesh_edge_length * 1.5 for i , cond in enumerate ( initial_conditions ) : if np . linalg . norm ( cond [ 0 ][ :2 ] ) >= radius - edge : initial_conditions [ i ][ 3 ] = True # Mark as fixed / non - movable return connections , initial_conditions mesh_square def mesh_square ( length , width , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 } ) View Source def mesh_square ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions mesh_square_concentric def mesh_square_concentric ( length , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, fix_outer = False ) View Source def mesh_square_concentric ( length , mesh_edge_length , params = params , fix_outer = False ) : n_long = int ( length / mesh_edge_length + 1 ) x_space = np . linspace ( - length / 2 , length / 2 , n_long ) y_space = x_space mesh = np . meshgrid ( x_space , y_space ) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : if ( abs ( xyz [ 0 ]) == length / 2 and abs ( xyz [ 1 ]) == length / 2 ) and fix_outer : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], True ]) else : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] dia_counter = [ 0 , n_long - 2 ] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis if abs ( node [ 0 ][ 0 ]) > abs ( node [ 0 ][ 1 ]) : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if abs ( node [ 0 ][ 0 ]) >= abs ( node [ 0 ][ 1 ]) and node [ 0 ][ 1 ] < 0 : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if dia_counter [ 0 ] == i : #cross connections dia_counter [ 0 ] += n_long + 1 connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) if dia_counter [ 1 ] == i : dia_counter [ 1 ] += n_long - 1 connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long) and abs(node[0][0])<=abs(node[0][1]) and node[0][0]<0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) elif ( i + 1 ) %(n_long) and abs(node[0][0])<abs(node[0][1]) and node[0][0]>=0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions mesh_square_cross def mesh_square_cross ( length , width , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 } ) View Source def mesh_square_cross ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions mesh_square_cross_sparse def mesh_square_cross_sparse ( length , width , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 } ) View Source def mesh_square_cross_sparse ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further flip = True for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections if flip : connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) flip = False else : connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) flip = True else : flip = not flip # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions ps_find_mid_strip_y def ps_find_mid_strip_y ( ParticleSystem , width = 1 ) View Source def ps_find_mid_strip_y ( ParticleSystem , width = 1 ): center_of_mass = np . mean ( ParticleSystem . x_v_current_3D [ 0 ], axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) midstrip = [] for i , particle in enumerate ( ParticleSystem . particles ): pos = particle . x if abs ( pos [ 0 ]) <= width / 2 : midstrip . append ( i ) return midstrip ps_find_reaction_of_boundary def ps_find_reaction_of_boundary ( ParticleSystem , boundary ) View Source def ps_find_reaction_of_boundary ( ParticleSystem , boundary ) : # !!! ATTENTION !!! DRAFT CODE ! COMPLETLY UNTESTED ! internal_forces = ParticleSystem . _ParticleSystem__one_d_force_vector () reaction = np . array ( [ 0 . 0 , 0 . 0 , 0 . 0 ] ) for indice in boundary : reaction += internal_forces [ indice * 3 : indice * 3 + 3 ] return reaction ps_find_strip_dimentions def ps_find_strip_dimentions ( ParticleSystem , midstrip ) View Source def ps_find_strip_dimentions ( ParticleSystem , midstrip ) : positions = [] for indice in midstrip : particle = ParticleSystem . particles [ indice ] positions . append ( particle . x ) positions = np . array ( positions ) point_to_point_range = np . ptp ( positions , axis = 0 ) return point_to_point_range ps_fix_opposite_boundaries_x def ps_fix_opposite_boundaries_x ( ParticleSystem , margin = 0.075 ) Fixes two boundaries in preparation for unidirectional pull test View Source def ps_fix_opposite_boundaries_x ( ParticleSystem , margin = 0.075 ): \"\"\" Fixes two boundaries in preparation for unidirectional pull test \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype = 'float64' ) for particle in ParticleSystem . particles : center_of_mass += particle . x center_of_mass = center_of_mass / len ( ParticleSystem . particles ) x_cleaned = np . array ([ particle . x [ 0 ] for particle in ParticleSystem . particles ]) x_range = np . ptp ( x_cleaned , axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) boundary_x_min = [] boundary_x_plus = [] for i , particle in enumerate ( ParticleSystem . particles ): if abs ( particle . x [ 0 ]) > (( x_range / 2 ) * ( 1 - margin )): particle . set_fixed ( True ) if particle . x [ 0 ] > 0 : boundary_x_plus . append ( i ) else : boundary_x_min . append ( i ) boundaries = [ boundary_x_min , boundary_x_plus ] return ParticleSystem , boundaries ps_stretch_in_x def ps_stretch_in_x ( ParticleSystem , boundary , displacement ) View Source def ps_stretch_in_x ( ParticleSystem , boundary , displacement ) : for indice in boundary : particle = ParticleSystem . particles [ indice ] new_pos = particle . x new_pos [ 0 ] += displacement particle . update_pos ( new_pos )","title":"Mesh Functions"},{"location":"reference/src/Mesh/mesh_functions/#module-srcmeshmesh_functions","text":"Created on Fri Dec 15 12:27:53 2023 View Source # -*- coding : utf - 8 -*- \"\"\" Created on Fri Dec 15 12:27:53 2023 @author: Mark Kalsbeek \"\"\" import numpy as np from scipy . spatial . transform import Rotation as R from .. particleSystem . SpringDamper import SpringDamperType params = { # model parameters \"k\" : 1 , # [ N / m ] spring stiffness \"k_d\" : 1 , # [ N / m ] spring stiffness \"c\" : 1 , # [ N s / m ] damping coefficient \"m_segment\" : 1 , # [ kg ] mass of each node } def mesh_square ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_square_cross ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_square_cross_sparse ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further flip = True for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections if flip : connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) flip = False else : connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) flip = True else : flip = not flip # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_square_concentric ( length , mesh_edge_length , params = params , fix_outer = False ) : n_long = int ( length / mesh_edge_length + 1 ) x_space = np . linspace ( - length / 2 , length / 2 , n_long ) y_space = x_space mesh = np . meshgrid ( x_space , y_space ) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : if ( abs ( xyz [ 0 ]) == length / 2 and abs ( xyz [ 1 ]) == length / 2 ) and fix_outer : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], True ]) else : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] dia_counter = [ 0 , n_long - 2 ] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis if abs ( node [ 0 ][ 0 ]) > abs ( node [ 0 ][ 1 ]) : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if abs ( node [ 0 ][ 0 ]) >= abs ( node [ 0 ][ 1 ]) and node [ 0 ][ 1 ] < 0 : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if dia_counter [ 0 ] == i : #cross connections dia_counter [ 0 ] += n_long + 1 connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) if dia_counter [ 1 ] == i : dia_counter [ 1 ] += n_long - 1 connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long) and abs(node[0][0])<=abs(node[0][1]) and node[0][0]<0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) elif ( i + 1 ) %(n_long) and abs(node[0][0])<abs(node[0][1]) and node[0][0]>=0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions def mesh_airbag_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False ) : if sparse : meshfunct = mesh_square_cross_sparse else : meshfunct = mesh_square_cross if width == 0 : width = length initial_conditions , connections = meshfunct ( length , width , mesh_edge_length , params ) # We iterate over the particle and set specific constraint conditions # to match the symmetry of the airbag being cut into 8 pieces for particle in initial_conditions : # sequence of if / elif statements matters becuase some of the used # critera can override others . # Fixing s . t . center node only move in z axis if ( particle [ 0 ] == [ 0 , 0 , 0 ]). all () : particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( 'line' ) elif particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ] == 0 : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( 'line' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ] == length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( 'line' ) elif ( ( particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ] > 0 ) or ( particle [ 0 ][ 1 ] == width and particle [ 0 ][ 0 ] > 0 ) ) : particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( 'plane' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ] > 0 and particle [ 0 ][ 1 ] < length : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( 'plane' ) elif particle [ 0 ][ 1 ] == 0 and particle [ 0 ][ 0 ] > 0 and particle [ 0 ][ 0 ] < length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( 'plane' ) if noncompressive : linktype = SpringDamperType . NONCOMPRESSIVE for link in connections : link . append ( linktype ) return connections , initial_conditions def mesh_phc_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False , fix_outer = True , center_lightsail = True ) : required = [ 'E_x' , 'E_y' , \"G\" , \"thickness\" ] for key in required : if not key in params . keys () : raise KeyError ( f \"{key} missing from params\" ) if width == 0 : width = length n_wide = int ( width / mesh_edge_length + 1 ) # x count n_long = int ( length / mesh_edge_length + 1 ) # y count x_length = width / n_wide y_length = length / n_long # Calculate k's from the given stifnesses # First calculate the diagnonal, it is required in the calculation of the orthogonal ones params[\"k_d\"] = params[\"G\"] * params[\"thickness\"] * x_length / (y_length*n_wide/np.sqrt(2)) params[\"k_x\"] = params[\"E_x\"] * params[\"thickness\"] params[\"k_y\"] = params[\"E_y\"] * params[\"thickness\"] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params[\"k_x\"]*= params[\"k_x\"]*n_long / (params[\"k_x\"]*n_long + params[\"k_d\"]*np.sqrt(2)*n_long) params[\"k_y\"]*= params[\"k_y\"]*n_wide / (params[\"k_y\"]*n_wide + params[\"k_d\"]*np.sqrt(2)*n_wide) # Perform the meshing mesh = np.meshgrid(np.linspace(0, length, n_long), np.linspace(0, width, n_wide)) initial_conditions = [] xy_coordinates = np.column_stack(list(zip(mesh[0],mesh[1]))).T xyz_coordinates = np.column_stack((xy_coordinates,np.zeros(len(xy_coordinates)).T)) for xyz in xyz_coordinates: if (fix_outer and (xyz[0] == 0 or xyz[0] == length or xyz[1] == 0 or xyz[1] == width)): initial_conditions.append([xyz, np.zeros(3), params['m_segment'], True]) else: initial_conditions.append([xyz, np.zeros(3), params['m_segment'], False]) neglect_diagonals = False if params[\"G\"] == 0: neglect_diagonals = True connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i, node in enumerate(initial_conditions[:-n_long]): # adding connextions in y-axis connections.append([i, i+n_long, params['k_y'], params['c']]) if (i+1)%(n_long) and not neglect_diagonals: #cross connections connections.append([i, i+n_long+1, params['k_d'], params['c']]) connections.append([i+1, i+n_long, params['k_d'], params['c']]) # We can do the same for the connections between the columns for i, node in enumerate(initial_conditions): # adding connections in x-axis if (i+1)%(n_long): # Using modulus operator to exclude the nodes at the end of a row connections.append([i, i+1, params['k_x'], params['c']]) if noncompressive: linktype = SpringDamperType.NONCOMPRESSIVE for link in connections: link.append(linktype) if center_lightsail: offset = np.array([width/2, length/2,0]) for p in initial_conditions: p[0] -= offset return connections, initial_conditions def mesh_circle_square_cross(radius, mesh_edge_length, params = params, fix_outer = False, edge = 0): n_wide = int(radius/ mesh_edge_length + 1) n_long = n_wide mesh = np.meshgrid(np.linspace(-radius, radius, n_long), np.linspace(-radius, radius, n_wide)) initial_conditions = [] xy_coordinates = np.column_stack(list(zip(mesh[0],mesh[1]))).T xyz_coordinates = np.column_stack((xy_coordinates,np.zeros(len(xy_coordinates)).T)) for xyz in xyz_coordinates: initial_conditions.append([xyz, np.zeros(3), params['m_segment'], False]) connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i, node in enumerate(initial_conditions[:-n_long]): # adding connextions in y-axis connections.append([i, i+n_long, params['k'], params['c']]) if (i+1)%(n_long): #cross connections connections.append([i, i+n_long+1, params['k_d'], params['c']]) connections.append([i+1, i+n_long, params['k_d'], params['c']]) # We can do the same for the connections between the columns for i, node in enumerate(initial_conditions): # adding connections in x-axis if (i+1)%(n_long): # Using modulus operator to exclude the nodes at the end of a row connections.append([i, i+1, params['k'], params['c']]) # Now to trim the excess nodes and connections mask = xy_coordinates[:,0]**2 + xy_coordinates[:,1]**2 <= radius**2 dumplist = [] for i, keepit in enumerate(mask): if not keepit: initial_conditions[i][3]= True # print(f' Iterating point { i } ') for j, link in enumerate(connections): if i in link[:2]: # print(f'dumping link { j } for being connected to { i } : { link } ') dumplist.append(j) dumplist = list(set(dumplist)) dumplist = sorted(dumplist)[::-1] # print(f'dumplist length : { len ( set ( dumplist ))} \\n { dumplist [ ::- 1 ]} ') # print(f'connections length : { len ( connections )} ') for i in dumplist: del connections[i] #for i, item in enumerate(initial_conditions): # if mask[i]: # del initial_conditions[i] if fix_outer: if edge == 0: edge = mesh_edge_length * 1.5 inner = xy_coordinates[:,0]**2 + xy_coordinates[:,1]**2 <= (radius-edge)**2 for i, freeit in enumerate(inner): if not freeit: initial_conditions[i][3]= True return connections, initial_conditions def mesh_round_phc_square_cross(radius, mesh_edge_length=1/10, params=None, noncompressive=False, sparse=False, fix_outer=True, edge=0): if params is None: params = {} required = [' E_x ', ' E_y ', \"G\", \"thickness\", \"m_segment\", \"c\"] for key in required: if key not in params.keys(): raise KeyError(f\"{key} missing from params\") # Calculating grid dimensions n_wide = int(2*radius / mesh_edge_length) + 1 n_long = n_wide y_length = radius/n_long x_length = y_length mesh = np.meshgrid(np.linspace(-radius, radius, n_long), np.linspace(-radius, radius, n_wide)) xy_coordinates = np.column_stack([mesh[0].flatten(), mesh[1].flatten()]) mask = xy_coordinates[:,0]**2 + xy_coordinates[:,1]**2 <= radius**2 filtered_xy_coordinates = xy_coordinates[mask] xyz_coordinates = np.column_stack((filtered_xy_coordinates, np.zeros(len(filtered_xy_coordinates)))) initial_conditions = [[xyz, np.zeros(3), params['m_segment'], False] for xyz in xyz_coordinates] # Calculate k's from the given stifnesses # First calculate the diagnonal , it is required in the calculation of the orthogonal ones params [ \"k_d\" ] = params [ \"G\" ] * params [ \"thickness\" ] * x_length / ( y_length * n_wide / np . sqrt ( 2 )) params [ \"k_x\" ] = params [ \"E_x\" ] * params [ \"thickness\" ] params [ \"k_y\" ] = params [ \"E_y\" ] * params [ \"thickness\" ] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params [ \"k_x\" ] *= params [ \"k_x\" ] * n_long / ( params [ \"k_x\" ] * n_long + params [ \"k_d\" ] * np . sqrt ( 2 ) * n_long ) params [ \"k_y\" ] *= params [ \"k_y\" ] * n_wide / ( params [ \"k_y\" ] * n_wide + params [ \"k_d\" ] * np . sqrt ( 2 ) * n_wide ) connections = [] for i , cond_i in enumerate ( initial_conditions ) : for j , cond_j in enumerate ( initial_conditions [ i + 1 : ], start = i + 1 ) : distance = np . linalg . norm ( cond_i [ 0 ][ : 2 ] - cond_j [ 0 ][ : 2 ]) / 1.01 if distance <= mesh_edge_length : # Direct neighbors k_value = params [ 'k_x' ] if cond_i [ 0 ][ 1 ] == cond_j [ 0 ][ 1 ] else params [ 'k_y' ] connection = [ i , j , k_value , params [ 'c' ]] if noncompressive : connection . append ( SpringDamperType . NONCOMPRESSIVE ) connections . append ( connection ) elif distance <= mesh_edge_length * np . sqrt ( 2 ) and params [ \"G\" ]! = 0 : # Diagonal connections only if G ! = 0 connection = [ i , j , params [ 'k_d' ], params [ 'c' ]] if noncompressive : connection . append ( SpringDamperType . NONCOMPRESSIVE ) connections . append ( connection ) # Optionally fix the outer nodes if fix_outer : if edge == 0 : edge = mesh_edge_length * 1.5 for i , cond in enumerate ( initial_conditions ) : if np . linalg . norm ( cond [ 0 ][ : 2 ]) >= radius - edge : initial_conditions [ i ][ 3 ] = True # Mark as fixed / non - movable return connections , initial_conditions def mesh_rotate_and_trim ( initial_conditions , connections , angle ) : \"\"\" NOTE: Input mesh is expected to be square! \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype ='float64' ) for particle in initial_conditions : center_of_mass+=particle [ 0 ] center_of_mass = center_of_mass / len ( initial_conditions ) x_cleaned = np . array ([ i [ 0 ] for i in initial_conditions ]) x_range , y_range , z_range = np . ptp ( x_cleaned , axis = 0 ) # rotation shrinks size of inscribed rectangle # Going for constant angle for consistent size factor = np . cos ( np . deg2rad ( 45 )) x_range *= factor y_range *= factor rotation_matrix = R . from_euler ( 'z' , angle , degrees = True ). as_matrix () for particle in initial_conditions : particle [ 0 ] -= center_of_mass particle [ 0 ] = rotation_matrix . dot ( particle [ 0 ]) dumplist = set () for i , link in enumerate ( connections ) : xyz_0 = initial_conditions [ link [ 0 ]][ 0 ] xyz_1 = initial_conditions [ link [ 1 ]][ 0 ] if abs ( xyz_0 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_0 [ 1 ]) > y_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 1 ]) > y_range / 2 : dumplist . add ( i ) dumplist = list ( dumplist ) dumplist . sort () for i in dumplist [ ::- 1 ] : del connections [ i ] return connections , initial_conditions def ps_fix_opposite_boundaries_x ( ParticleSystem , margin = 0.075 ) : \"\"\" Fixes two boundaries in preparation for unidirectional pull test \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype ='float64' ) for particle in ParticleSystem . particles : center_of_mass+=particle . x center_of_mass = center_of_mass / len ( ParticleSystem . particles ) x_cleaned = np . array ([ particle . x [ 0 ] for particle in ParticleSystem . particles ]) x_range = np . ptp ( x_cleaned , axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) boundary_x_min = [] boundary_x_plus = [] for i , particle in enumerate ( ParticleSystem . particles ) : if abs ( particle . x [ 0 ]) > (( x_range / 2 ) * ( 1 - margin )) : particle . set_fixed ( True ) if particle . x [ 0 ] > 0 : boundary_x_plus . append ( i ) else : boundary_x_min . append ( i ) boundaries = [ boundary_x_min , boundary_x_plus ] return ParticleSystem , boundaries def ps_stretch_in_x ( ParticleSystem , boundary , displacement ) : for indice in boundary : particle = ParticleSystem . particles [ indice ] new_pos = particle . x new_pos [ 0 ] += displacement particle . update_pos ( new_pos ) def ps_find_reaction_of_boundary ( ParticleSystem , boundary ) : # !!! ATTENTION !!! DRAFT CODE ! COMPLETLY UNTESTED ! internal_forces = ParticleSystem . _ ParticleSystem__one_d_force_vector () reaction = np . array ([ 0.0 , 0.0 , 0.0 ]) for indice in boundary : reaction += internal_forces [ indice * 3 : indice * 3 + 3 ] return reaction def ps_find_mid_strip_y ( ParticleSystem , width = 1 ) : center_of_mass = np . mean ( ParticleSystem . x_v_current_3D [ 0 ], axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) midstrip = [] for i , particle in enumerate ( ParticleSystem . particles ) : pos = particle . x if abs ( pos [ 0 ]) <= width / 2 : midstrip . append ( i ) return midstrip def ps_find_strip_dimentions ( ParticleSystem , midstrip ) : positions = [] for indice in midstrip : particle = ParticleSystem . particles [ indice ] positions . append ( particle . x ) positions = np . array ( positions ) point_to_point_range = np . ptp ( positions , axis = 0 ) return point_to_point_range if __ name__ == '__main__' : from src . particleSystem . ParticleSystem import ParticleSystem import matplotlib . pyplot as plt params = { # model parameters \"k\" : 1 , # [ N / m ] spring stiffness \"k_d\" : 1 , # [ N / m ] spring stiffness for diagonal elements \"c\" : 1 , # [ N s / m ] damping coefficient \"m_segment\" : 1 , # [ kg ] mass of each node # simulation settings \"dt\" : 0.1 , # [ s ] simulation timestep \"t_steps\" : 1000 , # [ - ] number of simulated time steps \"abs_tol\" : 1 e - 50 , # [ m / s ] absolute error tolerance iterative solver \"rel_tol\" : 1 e - 5 , # [ - ] relative error tolerance iterative solver \"max_iter\" : 1 e5 , # [ - ] maximum number of iterations \"E_x\" : 100 e9 , # [ Pa ] \"E_y\" : 100 e9 , # [ Pa ] \"G\" : 0 , # [ Pa ] \"thickness\" : 100 e - 9 # [ m ] } # !!! Don 't forget to add new meshing functions to this list! meshing_functions = [mesh_square, mesh_square_cross, mesh_square_cross_sparse, mesh_airbag_square_cross, mesh_square_concentric, mesh_circle_square_cross, mesh_round_phc_square_cross] inputs = [16,8,1, params] nplots = len(meshing_functions) + 1 cols = int(np.sqrt(nplots)) +1 rows = nplots // cols if nplots % cols !=0: rows +=1 fig = plt.figure() pslist = [] for i, function in enumerate(meshing_functions): ax = fig.add_subplot(rows, cols,i+1,projection=' 3 d') ax.set_box_aspect([1,1,1]) if i ==4: inputs = inputs[1:] initial_conditions, connections = function(*inputs) PS = ParticleSystem(connections, initial_conditions, params) pslist.append(PS) PS.plot(ax) ax.set_title(function.__name__) initial_conditions, connections = mesh_square_cross(20,20,1,params) initial_conditions, connections = mesh_rotate_and_trim(initial_conditions, connections, 45/2) PS = ParticleSystem(connections, initial_conditions,params) PS, boundaries = ps_fix_opposite_boundaries_x(PS, margin = 0.175) ps_stretch_in_x(PS, boundaries[1], 1) pslist.append(PS) ax = fig.add_subplot(rows, cols, nplots, projection=' 3 d ' ) PS . plot ( ax ) ax . set_title (( mesh_square_cross . __ name__ , mesh_rotate_and_trim . __ name__ , ps_fix_opposite_boundaries_x . __ name__ , ps_stretch_in_x . __ name__ ))","title":"Module src.Mesh.mesh_functions"},{"location":"reference/src/Mesh/mesh_functions/#variables","text":"params","title":"Variables"},{"location":"reference/src/Mesh/mesh_functions/#functions","text":"","title":"Functions"},{"location":"reference/src/Mesh/mesh_functions/#mesh_airbag_square_cross","text":"def mesh_airbag_square_cross ( length , width = 0 , mesh_edge_length = 0.1 , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, noncompressive = False , sparse = False ) View Source def mesh_airbag_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False ): if sparse : meshfunct = mesh_square_cross_sparse else : meshfunct = mesh_square_cross if width == 0 : width = length initial_conditions , connections = meshfunct ( length , width , mesh_edge_length , params ) # We iterate over the particle and set specific constraint conditions # to match the symmetry of the airbag being cut into 8 pieces for particle in initial_conditions : # sequence of if / elif statements matters becuase some of the used # critera can override others . # Fixing s . t . center node only move in z axis if ( particle [ 0 ] == [ 0 , 0 , 0 ]). all (): particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( ' line ' ) elif particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ] == 0 : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( ' line ' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ] == length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( ' line ' ) elif ( ( particle [ 0 ][ 0 ] == length and particle [ 0 ][ 1 ]> 0 ) or ( particle [ 0 ][ 1 ] == width and particle [ 0 ][ 0 ]> 0 ) ): particle [ 3 ] = True particle . append ([ 0 , 0 , 1 ]) particle . append ( ' plane ' ) elif particle [ 0 ][ 0 ] == 0 and particle [ 0 ][ 1 ]> 0 and particle [ 0 ][ 1 ]< length : particle [ 3 ] = True particle . append ([ 1 , 0 , 0 ]) particle . append ( ' plane ' ) elif particle [ 0 ][ 1 ] == 0 and particle [ 0 ][ 0 ]> 0 and particle [ 0 ][ 0 ]< length : particle [ 3 ] = True particle . append ([ 0 , 1 , 0 ]) particle . append ( ' plane ' ) if noncompressive : linktype = SpringDamperType . NONCOMPRESSIVE for link in connections : link . append ( linktype ) return connections , initial_conditions","title":"mesh_airbag_square_cross"},{"location":"reference/src/Mesh/mesh_functions/#mesh_circle_square_cross","text":"def mesh_circle_square_cross ( radius , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, fix_outer = False , edge = 0 ) View Source def mesh_circle_square_cross ( radius , mesh_edge_length , params = params , fix_outer = False , edge = 0 ) : n_wide = int ( radius / mesh_edge_length + 1 ) n_long = n_wide mesh = np . meshgrid ( np . linspace ( - radius , radius , n_long ), np . linspace ( - radius , radius , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) # Now to trim the excess nodes and connections mask = xy_coordinates [ : , 0 ] ** 2 + xy_coordinates [ : , 1 ] ** 2 <= radius** 2 dumplist = [] for i , keepit in enumerate ( mask ) : if not keepit : initial_conditions [ i ][ 3 ] = True # print ( f'Iterating point {i}' ) for j , link in enumerate ( connections ) : if i in link [ : 2 ] : # print ( f'dumping link {j} for being connected to {i}: {link}' ) dumplist . append ( j ) dumplist = list ( set ( dumplist )) dumplist = sorted ( dumplist )[ ::- 1 ] # print ( f'dumplist length: {len(set(dumplist))}\\n{dumplist[::-1]}' ) # print ( f'connections length: {len(connections)}' ) for i in dumplist : del connections [ i ] #for i , item in enumerate ( initial_conditions ) : # if mask [ i ] : # del initial_conditions [ i ] if fix_outer : if edge == 0 : edge = mesh_edge_length * 1.5 inner = xy_coordinates [ : , 0 ] ** 2 + xy_coordinates [ : , 1 ] ** 2 <= ( radius - edge ) ** 2 for i , freeit in enumerate ( inner ) : if not freeit : initial_conditions [ i ][ 3 ] = True return connections , initial_conditions","title":"mesh_circle_square_cross"},{"location":"reference/src/Mesh/mesh_functions/#mesh_phc_square_cross","text":"def mesh_phc_square_cross ( length , width = 0 , mesh_edge_length = 0.1 , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, noncompressive = False , sparse = False , fix_outer = True , center_lightsail = True ) View Source def mesh_phc_square_cross ( length , width = 0 , mesh_edge_length = 1 / 10 , params = params , noncompressive = False , sparse = False , fix_outer = True , center_lightsail = True ) : required = [ 'E_x' , 'E_y' , \"G\" , \"thickness\" ] for key in required : if not key in params . keys () : raise KeyError ( f \"{key} missing from params\" ) if width == 0 : width = length n_wide = int ( width / mesh_edge_length + 1 ) # x count n_long = int ( length / mesh_edge_length + 1 ) # y count x_length = width / n_wide y_length = length / n_long # Calculate k's from the given stifnesses # First calculate the diagnonal, it is required in the calculation of the orthogonal ones params[\"k_d\"] = params[\"G\"] * params[\"thickness\"] * x_length / (y_length*n_wide/np.sqrt(2)) params[\"k_x\"] = params[\"E_x\"] * params[\"thickness\"] params[\"k_y\"] = params[\"E_y\"] * params[\"thickness\"] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params[\"k_x\"]*= params[\"k_x\"]*n_long / (params[\"k_x\"]*n_long + params[\"k_d\"]*np.sqrt(2)*n_long) params[\"k_y\"]*= params[\"k_y\"]*n_wide / (params[\"k_y\"]*n_wide + params[\"k_d\"]*np.sqrt(2)*n_wide) # Perform the meshing mesh = np.meshgrid(np.linspace(0, length, n_long), np.linspace(0, width, n_wide)) initial_conditions = [] xy_coordinates = np.column_stack(list(zip(mesh[0],mesh[1]))).T xyz_coordinates = np.column_stack((xy_coordinates,np.zeros(len(xy_coordinates)).T)) for xyz in xyz_coordinates: if (fix_outer and (xyz[0] == 0 or xyz[0] == length or xyz[1] == 0 or xyz[1] == width)): initial_conditions.append([xyz, np.zeros(3), params['m_segment'], True]) else: initial_conditions.append([xyz, np.zeros(3), params['m_segment'], False]) neglect_diagonals = False if params[\"G\"] == 0: neglect_diagonals = True connections = [] #We know that all the nodes are connected to those of the next row, which is grid_length+1 units further for i, node in enumerate(initial_conditions[:-n_long]): # adding connextions in y-axis connections.append([i, i+n_long, params['k_y'], params['c']]) if (i+1)%(n_long) and not neglect_diagonals: #cross connections connections.append([i, i+n_long+1, params['k_d'], params['c']]) connections.append([i+1, i+n_long, params['k_d'], params['c']]) # We can do the same for the connections between the columns for i, node in enumerate(initial_conditions): # adding connections in x-axis if (i+1)%(n_long): # Using modulus operator to exclude the nodes at the end of a row connections.append([i, i+1, params['k_x'], params['c ' ]]) if noncompressive : linktype = SpringDamperType . NONCOMPRESSIVE for link in connections : link . append ( linktype ) if center_lightsail : offset = np . array ([ width / 2 , length / 2 , 0 ]) for p in initial_conditions : p [ 0 ] -= offset return connections , initial_conditions","title":"mesh_phc_square_cross"},{"location":"reference/src/Mesh/mesh_functions/#mesh_rotate_and_trim","text":"def mesh_rotate_and_trim ( initial_conditions , connections , angle ) NOTE: Input mesh is expected to be square! View Source def mesh_rotate_and_trim ( initial_conditions , connections , angle ) : \"\"\" NOTE: Input mesh is expected to be square! \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype ='float64' ) for particle in initial_conditions : center_of_mass+=particle [ 0 ] center_of_mass = center_of_mass / len ( initial_conditions ) x_cleaned = np . array ([ i [ 0 ] for i in initial_conditions ]) x_range , y_range , z_range = np . ptp ( x_cleaned , axis = 0 ) # rotation shrinks size of inscribed rectangle # Going for constant angle for consistent size factor = np . cos ( np . deg2rad ( 45 )) x_range *= factor y_range *= factor rotation_matrix = R . from_euler ( 'z' , angle , degrees = True ). as_matrix () for particle in initial_conditions : particle [ 0 ] -= center_of_mass particle [ 0 ] = rotation_matrix . dot ( particle [ 0 ]) dumplist = set () for i , link in enumerate ( connections ) : xyz_0 = initial_conditions [ link [ 0 ]][ 0 ] xyz_1 = initial_conditions [ link [ 1 ]][ 0 ] if abs ( xyz_0 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_0 [ 1 ]) > y_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 0 ]) > x_range / 2 : dumplist . add ( i ) elif abs ( xyz_1 [ 1 ]) > y_range / 2 : dumplist . add ( i ) dumplist = list ( dumplist ) dumplist . sort () for i in dumplist [ ::- 1 ] : del connections [ i ] return connections , initial_conditions","title":"mesh_rotate_and_trim"},{"location":"reference/src/Mesh/mesh_functions/#mesh_round_phc_square_cross","text":"def mesh_round_phc_square_cross ( radius , mesh_edge_length = 0.1 , params = None , noncompressive = False , sparse = False , fix_outer = True , edge = 0 ) View Source def mesh_round_phc_square_cross ( radius , mesh_edge_length = 1 / 10 , params = None , noncompressive = False , sparse = False , fix_outer = True , edge = 0 ) : if params is None : params = {} required = [ 'E_x', 'E_y', \"G\", \"thickness\", \"m_segment\", \"c\" ] for key in required : if key not in params . keys () : raise KeyError ( f \"{key} missing from params\" ) # Calculating grid dimensions n_wide = int ( 2 * radius / mesh_edge_length ) + 1 n_long = n_wide y_length = radius / n_long x_length = y_length mesh = np . meshgrid ( np . linspace ( - radius , radius , n_long ), np . linspace ( - radius , radius , n_wide )) xy_coordinates = np . column_stack ( [ mesh[0 ] . flatten (), mesh [ 1 ] . flatten () ] ) mask = xy_coordinates [ :,0 ]** 2 + xy_coordinates [ :,1 ]** 2 <= radius ** 2 filtered_xy_coordinates = xy_coordinates [ mask ] xyz_coordinates = np . column_stack (( filtered_xy_coordinates , np . zeros ( len ( filtered_xy_coordinates )))) initial_conditions = [ [xyz, np.zeros(3), params['m_segment' ] , False ] for xyz in xyz_coordinates ] # Calculate k 's from the given stifnesses # First calculate the diagnonal, it is required in the calculation of the orthogonal ones params[\"k_d\"] = params[\"G\"] * params[\"thickness\"] * x_length / (y_length*n_wide/np.sqrt(2)) params[\"k_x\"] = params[\"E_x\"] * params[\"thickness\"] params[\"k_y\"] = params[\"E_y\"] * params[\"thickness\"] # Now we have to reduce the influence of the orthogonal springs in order to account for the # contribution of the diagonal ones params[\"k_x\"]*= params[\"k_x\"]*n_long / (params[\"k_x\"]*n_long + params[\"k_d\"]*np.sqrt(2)*n_long) params[\"k_y\"]*= params[\"k_y\"]*n_wide / (params[\"k_y\"]*n_wide + params[\"k_d\"]*np.sqrt(2)*n_wide) connections = [] for i, cond_i in enumerate(initial_conditions): for j, cond_j in enumerate(initial_conditions[i+1:], start=i+1): distance = np.linalg.norm(cond_i[0][:2] - cond_j[0][:2])/1.01 if distance <= mesh_edge_length: # Direct neighbors k_value = params[' k_x '] if cond_i[0][1] == cond_j[0][1] else params[' k_y '] connection = [i, j, k_value, params[' c ']] if noncompressive: connection.append(SpringDamperType.NONCOMPRESSIVE) connections.append(connection) elif distance <= mesh_edge_length * np.sqrt(2) and params[\"G\"]!=0: # Diagonal connections only if G != 0 connection = [i, j, params[' k_d '], params[' c ']] if noncompressive : connection . append ( SpringDamperType . NONCOMPRESSIVE ) connections . append ( connection ) # Optionally fix the outer nodes if fix_outer : if edge == 0 : edge = mesh_edge_length * 1.5 for i , cond in enumerate ( initial_conditions ) : if np . linalg . norm ( cond [ 0 ][ :2 ] ) >= radius - edge : initial_conditions [ i ][ 3 ] = True # Mark as fixed / non - movable return connections , initial_conditions","title":"mesh_round_phc_square_cross"},{"location":"reference/src/Mesh/mesh_functions/#mesh_square","text":"def mesh_square ( length , width , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 } ) View Source def mesh_square ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions","title":"mesh_square"},{"location":"reference/src/Mesh/mesh_functions/#mesh_square_concentric","text":"def mesh_square_concentric ( length , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 }, fix_outer = False ) View Source def mesh_square_concentric ( length , mesh_edge_length , params = params , fix_outer = False ) : n_long = int ( length / mesh_edge_length + 1 ) x_space = np . linspace ( - length / 2 , length / 2 , n_long ) y_space = x_space mesh = np . meshgrid ( x_space , y_space ) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : if ( abs ( xyz [ 0 ]) == length / 2 and abs ( xyz [ 1 ]) == length / 2 ) and fix_outer : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], True ]) else : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] dia_counter = [ 0 , n_long - 2 ] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis if abs ( node [ 0 ][ 0 ]) > abs ( node [ 0 ][ 1 ]) : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if abs ( node [ 0 ][ 0 ]) >= abs ( node [ 0 ][ 1 ]) and node [ 0 ][ 1 ] < 0 : connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if dia_counter [ 0 ] == i : #cross connections dia_counter [ 0 ] += n_long + 1 connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) if dia_counter [ 1 ] == i : dia_counter [ 1 ] += n_long - 1 connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long) and abs(node[0][0])<=abs(node[0][1]) and node[0][0]<0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) elif ( i + 1 ) %(n_long) and abs(node[0][0])<abs(node[0][1]) and node[0][0]>=0: # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions","title":"mesh_square_concentric"},{"location":"reference/src/Mesh/mesh_functions/#mesh_square_cross","text":"def mesh_square_cross ( length , width , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 } ) View Source def mesh_square_cross ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions","title":"mesh_square_cross"},{"location":"reference/src/Mesh/mesh_functions/#mesh_square_cross_sparse","text":"def mesh_square_cross_sparse ( length , width , mesh_edge_length , params = { 'k' : 1 , 'k_d' : 1 , 'c' : 1 , 'm_segment' : 1 } ) View Source def mesh_square_cross_sparse ( length , width , mesh_edge_length , params = params ) : n_wide = int ( width / mesh_edge_length + 1 ) n_long = int ( length / mesh_edge_length + 1 ) mesh = np . meshgrid ( np . linspace ( 0 , length , n_long ), np . linspace ( 0 , width , n_wide )) initial_conditions = [] xy_coordinates = np . column_stack ( list ( zip ( mesh [ 0 ], mesh [ 1 ]))). T xyz_coordinates = np . column_stack (( xy_coordinates , np . zeros ( len ( xy_coordinates )). T )) for xyz in xyz_coordinates : initial_conditions . append ([ xyz , np . zeros ( 3 ), params [ 'm_segment' ], False ]) connections = [] # We know that all the nodes are connected to those of the next row , which is grid_length + 1 units further flip = True for i , node in enumerate ( initial_conditions [ :- n_long ]) : # adding connextions in y - axis connections . append ([ i , i + n_long , params [ 'k' ], params [ 'c' ]]) if ( i + 1 ) %(n_long): #cross connections if flip : connections . append ([ i , i + n_long + 1 , params [ 'k_d' ], params [ 'c' ]]) flip = False else : connections . append ([ i + 1 , i + n_long , params [ 'k_d' ], params [ 'c' ]]) flip = True else : flip = not flip # We can do the same for the connections between the columns for i , node in enumerate ( initial_conditions ) : # adding connections in x - axis if ( i + 1 ) %(n_long): # Using modulus operator to exclude the nodes at the end of a row connections . append ([ i , i + 1 , params [ 'k' ], params [ 'c' ]]) return connections , initial_conditions","title":"mesh_square_cross_sparse"},{"location":"reference/src/Mesh/mesh_functions/#ps_find_mid_strip_y","text":"def ps_find_mid_strip_y ( ParticleSystem , width = 1 ) View Source def ps_find_mid_strip_y ( ParticleSystem , width = 1 ): center_of_mass = np . mean ( ParticleSystem . x_v_current_3D [ 0 ], axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) midstrip = [] for i , particle in enumerate ( ParticleSystem . particles ): pos = particle . x if abs ( pos [ 0 ]) <= width / 2 : midstrip . append ( i ) return midstrip","title":"ps_find_mid_strip_y"},{"location":"reference/src/Mesh/mesh_functions/#ps_find_reaction_of_boundary","text":"def ps_find_reaction_of_boundary ( ParticleSystem , boundary ) View Source def ps_find_reaction_of_boundary ( ParticleSystem , boundary ) : # !!! ATTENTION !!! DRAFT CODE ! COMPLETLY UNTESTED ! internal_forces = ParticleSystem . _ParticleSystem__one_d_force_vector () reaction = np . array ( [ 0 . 0 , 0 . 0 , 0 . 0 ] ) for indice in boundary : reaction += internal_forces [ indice * 3 : indice * 3 + 3 ] return reaction","title":"ps_find_reaction_of_boundary"},{"location":"reference/src/Mesh/mesh_functions/#ps_find_strip_dimentions","text":"def ps_find_strip_dimentions ( ParticleSystem , midstrip ) View Source def ps_find_strip_dimentions ( ParticleSystem , midstrip ) : positions = [] for indice in midstrip : particle = ParticleSystem . particles [ indice ] positions . append ( particle . x ) positions = np . array ( positions ) point_to_point_range = np . ptp ( positions , axis = 0 ) return point_to_point_range","title":"ps_find_strip_dimentions"},{"location":"reference/src/Mesh/mesh_functions/#ps_fix_opposite_boundaries_x","text":"def ps_fix_opposite_boundaries_x ( ParticleSystem , margin = 0.075 ) Fixes two boundaries in preparation for unidirectional pull test View Source def ps_fix_opposite_boundaries_x ( ParticleSystem , margin = 0.075 ): \"\"\" Fixes two boundaries in preparation for unidirectional pull test \"\"\" center_of_mass = np . array ([ 0 , 0 , 0 ], dtype = 'float64' ) for particle in ParticleSystem . particles : center_of_mass += particle . x center_of_mass = center_of_mass / len ( ParticleSystem . particles ) x_cleaned = np . array ([ particle . x [ 0 ] for particle in ParticleSystem . particles ]) x_range = np . ptp ( x_cleaned , axis = 0 ) for particle in ParticleSystem . particles : particle . update_pos_unsafe ( particle . x - center_of_mass ) boundary_x_min = [] boundary_x_plus = [] for i , particle in enumerate ( ParticleSystem . particles ): if abs ( particle . x [ 0 ]) > (( x_range / 2 ) * ( 1 - margin )): particle . set_fixed ( True ) if particle . x [ 0 ] > 0 : boundary_x_plus . append ( i ) else : boundary_x_min . append ( i ) boundaries = [ boundary_x_min , boundary_x_plus ] return ParticleSystem , boundaries","title":"ps_fix_opposite_boundaries_x"},{"location":"reference/src/Mesh/mesh_functions/#ps_stretch_in_x","text":"def ps_stretch_in_x ( ParticleSystem , boundary , displacement ) View Source def ps_stretch_in_x ( ParticleSystem , boundary , displacement ) : for indice in boundary : particle = ParticleSystem . particles [ indice ] new_pos = particle . x new_pos [ 0 ] += displacement particle . update_pos ( new_pos )","title":"ps_stretch_in_x"},{"location":"reference/src/particleSystem/Particle/","text":"Module src.particleSystem.Particle Child Class 'Particle', for particle objects to be instantiated in ParticleSystem View Source \"\"\" Child Class 'Particle', for particle objects to be instantiated in ParticleSystem \"\"\" from .SystemObject import SystemObject import numpy as np import numpy.typing as npt class Particle ( SystemObject ): def __init__ ( self , x : npt . ArrayLike , v : npt . ArrayLike , m : float , fixed : bool , constraint : npt . NDArray = None , constraint_type : str = 'free' ): \"\"\" Object that holds particle data Parameters ---------- x : npt.ArrayLike Position (x,y,z) in meter v : npt.ArrayLike Velocity (x,y,z) in meters per second m : float Mass in kilograms fixed : bool Wether or not the particle is fixed constraint : npt.NDArray, optional Desrcribes specific constraint if particle is fixed. The default is None. This indicates that it's fixed in all three dimentions. constraint_type : str, optional Describes constraint type. Can be free, point, line or plane Can be left default for fixed points, as they're indicated by passing constraint = [0,0,0] Raises ------ AttributeError Raises error if constraint is set incorrectly. Returns ------- None. \"\"\" self . __x = np . array ( x , dtype = 'float64' ) self . __v = np . array ( v , dtype = 'float64' ) self . __m = m self . __fixed = fixed self . __constraint = None self . __constraint_type = constraint_type . lower () self . connections = [] if self . __fixed : self . validate_constraint ( constraint ) self . constraint_projection () super () . __init__ () def __str__ ( self ): return ( f \"Particle Object, position [m]: [ { self . __x [ 0 ] } , { self . __x [ 1 ] } , { self . __x [ 2 ] } ], \" f \"velocity [m/s]: [ { self . __v [ 0 ] } , { self . __v [ 1 ] } , { self . __v [ 2 ] } ], mass [kg]: { self . __m } \" f \", fixed: { self . __fixed } , { self . __constraint =} , { self . __constraint_type =} \" ) def validate_constraint ( self , constraint ): \"Checks if constraint is entered correctly, raises exception if otherwise\" if self . __fixed : if constraint == None : constraint = [ 0 , 0 , 0 ] self . __constraint_type = 'point' if self . __constraint_type not in [ 'point' , 'line' , 'plane' ]: raise AttributeError ( f \"Incorrect constraint type set, expected\" f \" line or plane, got \" f \" { self . __constraint_type } \" ) try : self . __constraint = np . array ( constraint , dtype = float ) . reshape ( 1 , 3 ) except ( ValueError , TypeError ) as e : raise AttributeError ( f \"Particle set as 'fixed' but constraint \" f \"not set correctly. Expecting (1,3) \" f \"npt.Arraylike, instead got \" f \" { constraint =} . Error: { e } \" ) else : self . __constraint = None def constraint_projection ( self ): if np . sum ( self . __constraint == 0 ) == 3 : self . constraint_projection_matrix = np . zeros (( 3 , 3 )) else : normalised_constraint = self . __constraint / np . linalg . norm ( self . __constraint ) if self . __constraint_type == 'plane' : projection_matrix = np . eye ( 3 ) - np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix elif self . __constraint_type == 'line' : projection_matrix = np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix def update_pos ( self , new_pos : npt . ArrayLike ): if not self . __fixed : self . __x = np . array ( new_pos ) else : self . __x += self . constraint_projection_matrix . dot ( np . array ( new_pos ) - self . __x ) def update_pos_unsafe ( self , new_pos : npt . ArrayLike ): \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __x = np . array ( new_pos ) def update_vel ( self , new_vel : npt . ArrayLike ): if not self . __fixed : self . __v = np . array ( new_vel ) else : self . __v += self . constraint_projection_matrix . dot ( np . array ( new_vel ) - self . __v ) def update_vel_unsafe ( self , new_vel : npt . ArrayLike ): \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __v = np . array ( new_vel ) @property def x ( self ): return self . __x @property def v ( self ): return self . __v @property def m ( self ): return self . __m def set_m ( self , m ): self . __m = m @property def fixed ( self ): return self . __fixed def set_fixed ( self , fixed , constraint = None , constraint_type = 'free' ): self . __fixed = fixed self . __constraint_type = constraint_type self . validate_constraint ( constraint ) if self . __fixed : self . constraint_projection () @property def constraint_type ( self ): return self . __constraint_type if __name__ == \"__main__\" : position = [ 0 , 0 , 0 ] velocity = [ 0 , 0 , 0 ] mass = 1 fixed1 = False fixed2 = True constraint2 = [ - 1 , 0 , 1 ] constraint_type2 = 'line' p1 = Particle ( position , velocity , mass , fixed1 ) p2 = Particle ( position , velocity , mass , fixed2 , constraint2 , constraint_type2 ) print ( 'Starting positions' ) print ( p1 ) print ( p2 , ' \\n ' ) updated_pos = [ 0 , 1 , 1 ] updated_vel = [ 0 , 0 , 1 ] p1 . update_pos ( updated_pos ) p1 . update_vel ( updated_vel ) p2 . update_pos ( updated_pos ) p2 . update_vel ( updated_vel ) print ( 'Updated positions' ) print ( p1 ) print ( p2 ) Classes Particle class Particle ( x : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], v : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], m : float , fixed : bool , constraint : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] = None , constraint_type : str = 'free' ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Particle ( SystemObject ) : def __init__ ( self , x : npt . ArrayLike , v : npt . ArrayLike , m : float , fixed : bool , constraint : npt . NDArray = None , constraint_type : str = 'free' ) : \"\"\" Object that holds particle data Parameters ---------- x : npt.ArrayLike Position (x,y,z) in meter v : npt.ArrayLike Velocity (x,y,z) in meters per second m : float Mass in kilograms fixed : bool Wether or not the particle is fixed constraint : npt.NDArray, optional Desrcribes specific constraint if particle is fixed. The default is None. This indicates that it's fixed in all three dimentions. constraint_type : str, optional Describes constraint type. Can be free, point, line or plane Can be left default for fixed points, as they're indicated by passing constraint = [0,0,0] Raises ------ AttributeError Raises error if constraint is set incorrectly. Returns ------- None. \"\"\" self . __x = np . array ( x , dtype = 'float64' ) self . __v = np . array ( v , dtype = 'float64' ) self . __m = m self . __fixed = fixed self . __constraint = None self . __constraint_type = constraint_type . lower () self . connections = [] if self . __fixed : self . validate_constraint ( constraint ) self . constraint_projection () super (). __init__ () def __str__ ( self ) : return ( f \"Particle Object, position [m]: [{self.__x[0]}, {self.__x[1]}, {self.__x[2]}], \" f \"velocity [m/s]: [{self.__v[0]}, {self.__v[1]}, {self.__v[2]}], mass [kg]: {self.__m}\" f \", fixed: {self.__fixed}, {self.__constraint=}, {self.__constraint_type=}\" ) def validate_constraint ( self , constraint ) : \"Checks if constraint is entered correctly, raises exception if otherwise\" if self . __fixed : if constraint == None : constraint = [ 0,0,0 ] self . __constraint_type = 'point' if self . __constraint_type not in [ 'point', 'line', 'plane' ] : raise AttributeError ( f \"Incorrect constraint type set, expected\" f \" line or plane, got \" f \"{self.__constraint_type}\" ) try : self . __constraint = np . array ( constraint , dtype = float ). reshape ( 1 , 3 ) except ( ValueError , TypeError ) as e : raise AttributeError ( f \"Particle set as 'fixed' but constraint \" f \"not set correctly. Expecting (1,3) \" f \"npt.Arraylike, instead got \" f \"{constraint=}. Error: {e}\" ) else : self . __constraint = None def constraint_projection ( self ) : if np . sum ( self . __constraint == 0 ) == 3 : self . constraint_projection_matrix = np . zeros (( 3 , 3 )) else : normalised_constraint = self . __constraint / np . linalg . norm ( self . __constraint ) if self . __constraint_type == 'plane' : projection_matrix = np . eye ( 3 ) - np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix elif self . __constraint_type == 'line' : projection_matrix = np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix def update_pos ( self , new_pos : npt . ArrayLike ) : if not self . __fixed : self . __x = np . array ( new_pos ) else : self . __x += self . constraint_projection_matrix . dot ( np . array ( new_pos ) - self . __x ) def update_pos_unsafe ( self , new_pos : npt . ArrayLike ) : \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __x = np . array ( new_pos ) def update_vel ( self , new_vel : npt . ArrayLike ) : if not self . __fixed : self . __v = np . array ( new_vel ) else : self . __v += self . constraint_projection_matrix . dot ( np . array ( new_vel ) - self . __v ) def update_vel_unsafe ( self , new_vel : npt . ArrayLike ) : \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __v = np . array ( new_vel ) @property def x ( self ) : return self . __x @property def v ( self ) : return self . __v @property def m ( self ) : return self . __m def set_m ( self , m ) : self . __m = m @property def fixed ( self ) : return self . __fixed def set_fixed ( self , fixed , constraint = None , constraint_type = 'free' ) : self . __fixed = fixed self . __constraint_type = constraint_type self . validate_constraint ( constraint ) if self . __fixed : self . constraint_projection () @property def constraint_type ( self ) : return self . __constraint_type Ancestors (in MRO) src.particleSystem.SystemObject.SystemObject abc.ABC Instance variables constraint_type fixed m v x Methods constraint_projection def constraint_projection ( self ) View Source def constraint_projection ( self ): if np . sum ( self . __constraint == 0 ) == 3 : self . constraint_projection_matrix = np . zeros (( 3 , 3 )) else : normalised_constraint = self . __constraint / np . linalg . norm ( self . __constraint ) if self . __constraint_type == ' plane ' : projection_matrix = np . eye ( 3 ) - np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix elif self . __constraint_type == ' line ' : projection_matrix = np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix set_fixed def set_fixed ( self , fixed , constraint = None , constraint_type = 'free' ) View Source def set_fixed ( self , fixed , constraint = None , constraint_type = ' free ' ): self . __fixed = fixed self . __constraint_type = constraint_type self . validate_constraint ( constraint ) if self . __fixed : self . constraint_projection () set_m def set_m ( self , m ) View Source def set_m(self, m): self.__m = m update_pos def update_pos ( self , new_pos : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_pos ( self , new_pos : npt . ArrayLike ): if not self . __fixed : self . __x = np . array ( new_pos ) else : self . __x += self . constraint_projection_matrix . dot ( np . array ( new_pos ) - self . __x ) update_pos_unsafe def update_pos_unsafe ( self , new_pos : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) position update method that will override locations of fixed nodes View Source def update_pos_unsafe(self, new_pos : npt.ArrayLike): \"\"\"position update method that will override locations of fixed nodes\"\"\" self.__x = np.array(new_pos) update_vel def update_vel ( self , new_vel : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_vel ( self , new_vel : npt . ArrayLike ): if not self . __fixed : self . __v = np . array ( new_vel ) else : self . __v += self . constraint_projection_matrix . dot ( np . array ( new_vel ) - self . __v ) update_vel_unsafe def update_vel_unsafe ( self , new_vel : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) position update method that will override locations of fixed nodes View Source def update_vel_unsafe(self, new_vel : npt.ArrayLike): \"\"\"position update method that will override locations of fixed nodes\"\"\" self.__v = np.array(new_vel) validate_constraint def validate_constraint ( self , constraint ) Checks if constraint is entered correctly, raises exception if otherwise View Source def validate_constraint ( self , constraint ): \"Checks if constraint is entered correctly, raises exception if otherwise\" if self . __fixed : if constraint == None : constraint = [ 0 , 0 , 0 ] self . __constraint_type = ' point ' if self . __constraint_type not in [ ' point ' , ' line ' , ' plane ' ]: raise AttributeError ( f \"Incorrect constraint type set, expected\" f \" line or plane, got \" f \"{self.__constraint_type}\" ) try : self . __constraint = np . array ( constraint , dtype = float ). reshape ( 1 , 3 ) except ( ValueError , TypeError ) as e : raise AttributeError ( f \"Particle set as 'fixed' but constraint \" f \"not set correctly. Expecting (1,3) \" f \"npt.Arraylike, instead got \" f \"{constraint=}. Error: {e}\" ) else : self . __constraint = None","title":"Particle"},{"location":"reference/src/particleSystem/Particle/#module-srcparticlesystemparticle","text":"Child Class 'Particle', for particle objects to be instantiated in ParticleSystem View Source \"\"\" Child Class 'Particle', for particle objects to be instantiated in ParticleSystem \"\"\" from .SystemObject import SystemObject import numpy as np import numpy.typing as npt class Particle ( SystemObject ): def __init__ ( self , x : npt . ArrayLike , v : npt . ArrayLike , m : float , fixed : bool , constraint : npt . NDArray = None , constraint_type : str = 'free' ): \"\"\" Object that holds particle data Parameters ---------- x : npt.ArrayLike Position (x,y,z) in meter v : npt.ArrayLike Velocity (x,y,z) in meters per second m : float Mass in kilograms fixed : bool Wether or not the particle is fixed constraint : npt.NDArray, optional Desrcribes specific constraint if particle is fixed. The default is None. This indicates that it's fixed in all three dimentions. constraint_type : str, optional Describes constraint type. Can be free, point, line or plane Can be left default for fixed points, as they're indicated by passing constraint = [0,0,0] Raises ------ AttributeError Raises error if constraint is set incorrectly. Returns ------- None. \"\"\" self . __x = np . array ( x , dtype = 'float64' ) self . __v = np . array ( v , dtype = 'float64' ) self . __m = m self . __fixed = fixed self . __constraint = None self . __constraint_type = constraint_type . lower () self . connections = [] if self . __fixed : self . validate_constraint ( constraint ) self . constraint_projection () super () . __init__ () def __str__ ( self ): return ( f \"Particle Object, position [m]: [ { self . __x [ 0 ] } , { self . __x [ 1 ] } , { self . __x [ 2 ] } ], \" f \"velocity [m/s]: [ { self . __v [ 0 ] } , { self . __v [ 1 ] } , { self . __v [ 2 ] } ], mass [kg]: { self . __m } \" f \", fixed: { self . __fixed } , { self . __constraint =} , { self . __constraint_type =} \" ) def validate_constraint ( self , constraint ): \"Checks if constraint is entered correctly, raises exception if otherwise\" if self . __fixed : if constraint == None : constraint = [ 0 , 0 , 0 ] self . __constraint_type = 'point' if self . __constraint_type not in [ 'point' , 'line' , 'plane' ]: raise AttributeError ( f \"Incorrect constraint type set, expected\" f \" line or plane, got \" f \" { self . __constraint_type } \" ) try : self . __constraint = np . array ( constraint , dtype = float ) . reshape ( 1 , 3 ) except ( ValueError , TypeError ) as e : raise AttributeError ( f \"Particle set as 'fixed' but constraint \" f \"not set correctly. Expecting (1,3) \" f \"npt.Arraylike, instead got \" f \" { constraint =} . Error: { e } \" ) else : self . __constraint = None def constraint_projection ( self ): if np . sum ( self . __constraint == 0 ) == 3 : self . constraint_projection_matrix = np . zeros (( 3 , 3 )) else : normalised_constraint = self . __constraint / np . linalg . norm ( self . __constraint ) if self . __constraint_type == 'plane' : projection_matrix = np . eye ( 3 ) - np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix elif self . __constraint_type == 'line' : projection_matrix = np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix def update_pos ( self , new_pos : npt . ArrayLike ): if not self . __fixed : self . __x = np . array ( new_pos ) else : self . __x += self . constraint_projection_matrix . dot ( np . array ( new_pos ) - self . __x ) def update_pos_unsafe ( self , new_pos : npt . ArrayLike ): \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __x = np . array ( new_pos ) def update_vel ( self , new_vel : npt . ArrayLike ): if not self . __fixed : self . __v = np . array ( new_vel ) else : self . __v += self . constraint_projection_matrix . dot ( np . array ( new_vel ) - self . __v ) def update_vel_unsafe ( self , new_vel : npt . ArrayLike ): \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __v = np . array ( new_vel ) @property def x ( self ): return self . __x @property def v ( self ): return self . __v @property def m ( self ): return self . __m def set_m ( self , m ): self . __m = m @property def fixed ( self ): return self . __fixed def set_fixed ( self , fixed , constraint = None , constraint_type = 'free' ): self . __fixed = fixed self . __constraint_type = constraint_type self . validate_constraint ( constraint ) if self . __fixed : self . constraint_projection () @property def constraint_type ( self ): return self . __constraint_type if __name__ == \"__main__\" : position = [ 0 , 0 , 0 ] velocity = [ 0 , 0 , 0 ] mass = 1 fixed1 = False fixed2 = True constraint2 = [ - 1 , 0 , 1 ] constraint_type2 = 'line' p1 = Particle ( position , velocity , mass , fixed1 ) p2 = Particle ( position , velocity , mass , fixed2 , constraint2 , constraint_type2 ) print ( 'Starting positions' ) print ( p1 ) print ( p2 , ' \\n ' ) updated_pos = [ 0 , 1 , 1 ] updated_vel = [ 0 , 0 , 1 ] p1 . update_pos ( updated_pos ) p1 . update_vel ( updated_vel ) p2 . update_pos ( updated_pos ) p2 . update_vel ( updated_vel ) print ( 'Updated positions' ) print ( p1 ) print ( p2 )","title":"Module src.particleSystem.Particle"},{"location":"reference/src/particleSystem/Particle/#classes","text":"","title":"Classes"},{"location":"reference/src/particleSystem/Particle/#particle","text":"class Particle ( x : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], v : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], m : float , fixed : bool , constraint : numpy . ndarray [ typing . Any , numpy . dtype [ + _ScalarType_co ]] = None , constraint_type : str = 'free' ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Particle ( SystemObject ) : def __init__ ( self , x : npt . ArrayLike , v : npt . ArrayLike , m : float , fixed : bool , constraint : npt . NDArray = None , constraint_type : str = 'free' ) : \"\"\" Object that holds particle data Parameters ---------- x : npt.ArrayLike Position (x,y,z) in meter v : npt.ArrayLike Velocity (x,y,z) in meters per second m : float Mass in kilograms fixed : bool Wether or not the particle is fixed constraint : npt.NDArray, optional Desrcribes specific constraint if particle is fixed. The default is None. This indicates that it's fixed in all three dimentions. constraint_type : str, optional Describes constraint type. Can be free, point, line or plane Can be left default for fixed points, as they're indicated by passing constraint = [0,0,0] Raises ------ AttributeError Raises error if constraint is set incorrectly. Returns ------- None. \"\"\" self . __x = np . array ( x , dtype = 'float64' ) self . __v = np . array ( v , dtype = 'float64' ) self . __m = m self . __fixed = fixed self . __constraint = None self . __constraint_type = constraint_type . lower () self . connections = [] if self . __fixed : self . validate_constraint ( constraint ) self . constraint_projection () super (). __init__ () def __str__ ( self ) : return ( f \"Particle Object, position [m]: [{self.__x[0]}, {self.__x[1]}, {self.__x[2]}], \" f \"velocity [m/s]: [{self.__v[0]}, {self.__v[1]}, {self.__v[2]}], mass [kg]: {self.__m}\" f \", fixed: {self.__fixed}, {self.__constraint=}, {self.__constraint_type=}\" ) def validate_constraint ( self , constraint ) : \"Checks if constraint is entered correctly, raises exception if otherwise\" if self . __fixed : if constraint == None : constraint = [ 0,0,0 ] self . __constraint_type = 'point' if self . __constraint_type not in [ 'point', 'line', 'plane' ] : raise AttributeError ( f \"Incorrect constraint type set, expected\" f \" line or plane, got \" f \"{self.__constraint_type}\" ) try : self . __constraint = np . array ( constraint , dtype = float ). reshape ( 1 , 3 ) except ( ValueError , TypeError ) as e : raise AttributeError ( f \"Particle set as 'fixed' but constraint \" f \"not set correctly. Expecting (1,3) \" f \"npt.Arraylike, instead got \" f \"{constraint=}. Error: {e}\" ) else : self . __constraint = None def constraint_projection ( self ) : if np . sum ( self . __constraint == 0 ) == 3 : self . constraint_projection_matrix = np . zeros (( 3 , 3 )) else : normalised_constraint = self . __constraint / np . linalg . norm ( self . __constraint ) if self . __constraint_type == 'plane' : projection_matrix = np . eye ( 3 ) - np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix elif self . __constraint_type == 'line' : projection_matrix = np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix def update_pos ( self , new_pos : npt . ArrayLike ) : if not self . __fixed : self . __x = np . array ( new_pos ) else : self . __x += self . constraint_projection_matrix . dot ( np . array ( new_pos ) - self . __x ) def update_pos_unsafe ( self , new_pos : npt . ArrayLike ) : \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __x = np . array ( new_pos ) def update_vel ( self , new_vel : npt . ArrayLike ) : if not self . __fixed : self . __v = np . array ( new_vel ) else : self . __v += self . constraint_projection_matrix . dot ( np . array ( new_vel ) - self . __v ) def update_vel_unsafe ( self , new_vel : npt . ArrayLike ) : \"\"\"position update method that will override locations of fixed nodes\"\"\" self . __v = np . array ( new_vel ) @property def x ( self ) : return self . __x @property def v ( self ) : return self . __v @property def m ( self ) : return self . __m def set_m ( self , m ) : self . __m = m @property def fixed ( self ) : return self . __fixed def set_fixed ( self , fixed , constraint = None , constraint_type = 'free' ) : self . __fixed = fixed self . __constraint_type = constraint_type self . validate_constraint ( constraint ) if self . __fixed : self . constraint_projection () @property def constraint_type ( self ) : return self . __constraint_type","title":"Particle"},{"location":"reference/src/particleSystem/Particle/#ancestors-in-mro","text":"src.particleSystem.SystemObject.SystemObject abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/src/particleSystem/Particle/#instance-variables","text":"constraint_type fixed m v x","title":"Instance variables"},{"location":"reference/src/particleSystem/Particle/#methods","text":"","title":"Methods"},{"location":"reference/src/particleSystem/Particle/#constraint_projection","text":"def constraint_projection ( self ) View Source def constraint_projection ( self ): if np . sum ( self . __constraint == 0 ) == 3 : self . constraint_projection_matrix = np . zeros (( 3 , 3 )) else : normalised_constraint = self . __constraint / np . linalg . norm ( self . __constraint ) if self . __constraint_type == ' plane ' : projection_matrix = np . eye ( 3 ) - np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix elif self . __constraint_type == ' line ' : projection_matrix = np . outer ( normalised_constraint , normalised_constraint ) self . constraint_projection_matrix = projection_matrix","title":"constraint_projection"},{"location":"reference/src/particleSystem/Particle/#set_fixed","text":"def set_fixed ( self , fixed , constraint = None , constraint_type = 'free' ) View Source def set_fixed ( self , fixed , constraint = None , constraint_type = ' free ' ): self . __fixed = fixed self . __constraint_type = constraint_type self . validate_constraint ( constraint ) if self . __fixed : self . constraint_projection ()","title":"set_fixed"},{"location":"reference/src/particleSystem/Particle/#set_m","text":"def set_m ( self , m ) View Source def set_m(self, m): self.__m = m","title":"set_m"},{"location":"reference/src/particleSystem/Particle/#update_pos","text":"def update_pos ( self , new_pos : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_pos ( self , new_pos : npt . ArrayLike ): if not self . __fixed : self . __x = np . array ( new_pos ) else : self . __x += self . constraint_projection_matrix . dot ( np . array ( new_pos ) - self . __x )","title":"update_pos"},{"location":"reference/src/particleSystem/Particle/#update_pos_unsafe","text":"def update_pos_unsafe ( self , new_pos : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) position update method that will override locations of fixed nodes View Source def update_pos_unsafe(self, new_pos : npt.ArrayLike): \"\"\"position update method that will override locations of fixed nodes\"\"\" self.__x = np.array(new_pos)","title":"update_pos_unsafe"},{"location":"reference/src/particleSystem/Particle/#update_vel","text":"def update_vel ( self , new_vel : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_vel ( self , new_vel : npt . ArrayLike ): if not self . __fixed : self . __v = np . array ( new_vel ) else : self . __v += self . constraint_projection_matrix . dot ( np . array ( new_vel ) - self . __v )","title":"update_vel"},{"location":"reference/src/particleSystem/Particle/#update_vel_unsafe","text":"def update_vel_unsafe ( self , new_vel : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) position update method that will override locations of fixed nodes View Source def update_vel_unsafe(self, new_vel : npt.ArrayLike): \"\"\"position update method that will override locations of fixed nodes\"\"\" self.__v = np.array(new_vel)","title":"update_vel_unsafe"},{"location":"reference/src/particleSystem/Particle/#validate_constraint","text":"def validate_constraint ( self , constraint ) Checks if constraint is entered correctly, raises exception if otherwise View Source def validate_constraint ( self , constraint ): \"Checks if constraint is entered correctly, raises exception if otherwise\" if self . __fixed : if constraint == None : constraint = [ 0 , 0 , 0 ] self . __constraint_type = ' point ' if self . __constraint_type not in [ ' point ' , ' line ' , ' plane ' ]: raise AttributeError ( f \"Incorrect constraint type set, expected\" f \" line or plane, got \" f \"{self.__constraint_type}\" ) try : self . __constraint = np . array ( constraint , dtype = float ). reshape ( 1 , 3 ) except ( ValueError , TypeError ) as e : raise AttributeError ( f \"Particle set as 'fixed' but constraint \" f \"not set correctly. Expecting (1,3) \" f \"npt.Arraylike, instead got \" f \"{constraint=}. Error: {e}\" ) else : self . __constraint = None","title":"validate_constraint"},{"location":"reference/src/particleSystem/ParticleSystem/","text":"Module src.particleSystem.ParticleSystem ParticleSystem framework ... View Source \"\"\" ParticleSystem framework ... \"\"\" import logging import numpy as np import numpy . typing as npt from scipy . sparse . linalg import bicgstab import scipy . sparse as sps from scipy . spatial import Delaunay from scipy . spatial . transform import Rotation import matplotlib . pyplot as plt from mpl_toolkits . mplot3d . art3d import Line3DCollection from . Particle import Particle from . SpringDamper import SpringDamper class ParticleSystem : def __ init__ ( self , connectivity_matrix : list , initial_conditions : npt . ArrayLike , sim_param : dict , clean_particles : bool = True , init_surface = True ) : \"\"\" Constructor for ParticleSystem object, model made up of n particles Parameters --------- connectivity_matrix : list 2-by-m matrix, where each column contains a nodal index pair that is connectedby a spring element: [ p1: Particle, p2: Particle, k: float, c: float, optional : linktype] initial_conditions : npt.ArrayLike Array of n arrays to instantiate particles. Each subarray must contain the params required for the particle constructor: [initial_pos, initial_vel, mass, fixed: bool, constraint, optional : constraint_type] param sim_param : dict Dictionary of other parameters required for simulation (dt, rtol, ...) clean_particles : bool Sets wether or not to delete particles without connections on init init_surface : bool Sets wether or not to initialise the surface finding. If disabled will perform it auto matically on surface calculation. But it gives the opertunity to initialise it manually with some extra parameters. \"\"\" if clean_particles : self . clean_up ( connectivity_matrix , initial_conditions ) self . __ connectivity_matrix = connectivity_matrix self . __ initial_conditions = initial_conditions self . __ n = len ( initial_conditions ) self . __ params = sim_param self . __ dt = sim_param [ \"dt\" ] self . __ rtol = sim_param [ \"rel_tol\" ] self . __ atol = sim_param [ \"abs_tol\" ] self . __ maxiter = int ( sim_param [ \"max_iter\" ]) # allocate memory self . __ particles = [] self . __ springdampers = [] self . __ f = np . zeros (( self . __ n * 3 , ), dtype='float64' ) self . __ jx = np . zeros (( self . __ n * 3 , self . __ n * 3 ), dtype='float64' ) self . __ jv = np . zeros (( self . __ n * 3 , self . __ n * 3 )) self . __ instantiate_particles ( initial_conditions ) self . __ m_matrix = self . __ construct_m_matrix () self . __ instantiate_springdampers () # Variables required for kinetic damping self . __ w_kin = self . __ calc_kin_energy () self . __ w_kin_min1 = self . __ calc_kin_energy () self . __ vis_damp = True self . __ x_min1 = np . zeros ( self . __ n , ) self . __ x_min2 = np . zeros ( self . __ n , ) # Variables that aid simulations self . COM_offset = np . zeros ( 3 ) # setup some recording self . __ history = { 'dt' : [], 'E_kin' : []} if init_surface : self . initialize_find_surface () return def __ str__ ( self ) : description = \"\" description += \"ParticleSystem object instantiated with attributes\\nConnectivity matrix:\" description += str ( self . __ connectivity_matrix ) description += \"\\n\\nInstantiated particles:\\n\" n = 1 for particle in self . __ particles : description += f \"p{n}: {particle}\\n\" n += 1 return description def __ instantiate_particles ( self , initial_conditions : list ) : for set_of_initial_cond in initial_conditions : x = set_of_initial_cond [ 0 ] v = set_of_initial_cond [ 1 ] m = set_of_initial_cond [ 2 ] f = set_of_initial_cond [ 3 ] if f and len ( set_of_initial_cond ) >= 5 : con = set_of_initial_cond [ 4 ] con_t = set_of_initial_cond [ 5 ] self . __ particles . append ( Particle ( x , v , m , f , con , con_t )) else : self . __ particles . append ( Particle ( x , v , m , f )) return def __ instantiate_springdampers ( self ) : for link in self . __ connectivity_matrix : link = link . copy () #needed to not override the __ connectivity_matrix link [ 0 ] = self . __ particles [ link [ 0 ]] link [ 1 ] = self . __ particles [ link [ 1 ]] SD = SpringDamper ( * link ) self . __ springdampers . append ( SD ) link [ 0 ]. connections . append ( SD ) link [ 1 ]. connections . append ( SD ) return def clean_up ( self , connectivity_matrix , initial_conditions ) : remove_list = set ( range ( len ( initial_conditions ))) for link in connectivity_matrix : try : remove_list . remove ( link [ 0 ]) except : pass try : remove_list . remove ( link [ 1 ]) except : pass remove_list = list ( remove_list ) remove_list . sort () for i in remove_list [ ::- 1 ] : del initial_conditions [ i ] for link in connectivity_matrix : if link [ 0 ] > i : link [ 0 ] -= 1 if link [ 1 ] > i : link [ 1 ] -= 1 def stress_self ( self , factor : float = 0 ) : \"\"\"Set all node lengths to zero to homogenously stress mesh\"\"\" if factor == 0 : for link in self . springdampers : link . l0 = 0 else : for link in self . springdampers : link . l0 *= factor return def __ construct_m_matrix ( self ) : matrix = np . zeros (( self . __ n * 3 , self . __ n * 3 )) for i in range ( self . __ n ) : matrix [ i * 3 : i * 3 + 3 , i * 3 : i * 3 + 3 ] += np . identity ( 3 ) * self . __ particles [ i ]. m return matrix def __ calc_kin_energy ( self ) : v = self . __ pack_v_current () w_kin = np . matmul ( np . matmul ( v , self . __ m_matrix ), v . T ) # Kinetic energy , 0.5 constant can be neglected return w_kin def simulate ( self , f_external : npt . ArrayLike = ()) : \"\"\" Core simulate function to advance sim a timestep Parameters embedded in self.__params ------------------------------------ adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. !!! TODO complete this with the other requisits Parameters ---------- f_external : npt.ArrayLike, optional DESCRIPTION. The default is (). Returns ------- x_next : TYPE DESCRIPTION. v_next : TYPE DESCRIPTION. \"\"\" if not len ( f_external ) : # check if external force is passed as argument , otherwise use 0 vector f_external = np . zeros ( self . __ n * 3 , ) f = self . __ one_d_force_vector () + f_external v_current = self . __ pack_v_current () x_current = self . __ pack_x_current () jx , jv = self . __ system_jacobians () #jx = sps . lil_array ( jx ) #jv = sps . lil_array ( jv ) # constructing A matrix and b vector for solver A = self . __ m_matrix - self . __ dt * jv - self . __ dt ** 2 * jx b = self . __ dt * f + self . __ dt ** 2 * jx . dot ( v_current ) # checking conditioning of A # print ( \"conditioning A:\" , np . linalg . cond ( A )) # A = sps . bsr_array ( A ) # --- START Prototype new constraint approach --- point_mask = [ not p . constraint_type == 'point' for p in self . __ particles ] plane_mask = [] line_mask = [] for p in self . __ particles : if p . constraint_type == 'plane' : for i in range ( 3 ) : line_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : plane_mask . append ( False ) plane_mask . append ( True ) plane_mask . append ( True ) elif constraint [ 1 ] == 1 : plane_mask . append ( True ) plane_mask . append ( False ) plane_mask . append ( True ) elif constraint [ 2 ] == 1 : plane_mask . append ( True ) plane_mask . append ( True ) plane_mask . append ( False ) else : for i in range ( 3 ) : plane_mask . append ( True ) elif p . constraint_type == 'line' : for i in range ( 3 ) : plane_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : line_mask . append ( True ) line_mask . append ( False ) line_mask . append ( False ) elif constraint [ 1 ] == 1 : line_mask . append ( False ) line_mask . append ( True ) line_mask . append ( False ) elif constraint [ 2 ] == 1 : line_mask . append ( False ) line_mask . append ( False ) line_mask . append ( True ) else : for i in range ( 3 ) : line_mask . append ( True ) else : for i in range ( 3 ) : plane_mask . append ( True ) line_mask . append ( True ) mask = np . outer ( point_mask , [ True , True , True ]). flatten () mask *= plane_mask mask *= line_mask dv = np . zeros_like ( b , dtype='float64' ) A = A [ mask , : ][ : , mask ] b = np . array ( b )[ mask ] # BiCGSTAB from scipy library dv_filtered , _ = bicgstab ( A , b , tol = self . __ rtol , atol = self . __ atol , maxiter = self . __ maxiter ) dv [ mask ] = dv_filtered # numerical time integration following implicit Euler scheme v_next = v_current + dv if 'adaptive_timestepping' in self . __ params : v_max = v_next . max () if v_max ! = 0 : dt = min ( self . __ params [ 'adaptive_timestepping' ] / v_max , self . __ dt ) else : dt = self . __ dt self . __ history [ 'dt' ]. append ( dt ) x_next = x_current + dt * v_next logging . debug ( f'Adaptive timestepping triggered {dt=}' ) else : x_next = x_current + self . __ dt * v_next self . __ history [ 'dt' ]. append ( self . __ dt ) # function returns the pos . and vel . for the next timestep , but for fixed particles this val ue doesn't update! self.__update_x_v(x_next, v_next) # Recording data about the timestep: self.__history[' E_kin '].append(self.__calc_kin_energy()) return x_next, v_next def kin_damp_sim(self, f_ext: npt.ArrayLike = (), q_correction: bool = False): # kinetic damping algorithm # kwargs passed to self.simulate if self.__vis_damp: # Condition resetting viscous damping to 0 for link in self.__springdampers: link.c = 0 self.__c = 0 self.__vis_damp = False if len(f_ext): # condition checking if an f_ext is passed as argument self.__save_state() x_next, v_next = self.simulate(f_ext) else: self.__save_state() x_next, v_next = self.simulate() w_kin_new = self.__calc_kin_energy() if w_kin_new > self.__w_kin: # kin damping algorithm, takes effect when decrease in kin energy is detected self.__update_w_kin(w_kin_new) else: v_next = np.zeros(self.__n*3, ) if q_correction: # statement to check if q_correction is desired, standard is turned off q = (self.__w_kin - w_kin_new)/(2*self.__w_kin - self.__w_kin_min1 - w_kin_new) # print(q) # print(self.__w_kin, w_kin_new) # !!! Not sure if linear interpolation between states is the way to determine new x_next !!! if q < 0.5: x_next = self.__x_min2 + (q / 0.5) * (self.__x_min1 - self.__x_min2) elif q == 0.5: x_next = self.__x_min1 elif q < 1: x_next = self.__x_min1 + ((q - 0.5) / 0.5) * (x_next - self.__x_min1) # Can also use this q factor to recalculate the state for certain timestep h self.__update_x_v(x_next, v_next) self.__update_w_kin(0) return x_next, v_next def __pack_v_current(self): return np.array([particle.v for particle in self.__particles]).flatten() def __pack_x_current(self): return np.array([particle.x for particle in self.__particles]).flatten() def __one_d_force_vector(self): #self.__f[self.__f != 0] = 0 self.__f = np.zeros(self.__f.shape, dtype=np.float64) for n in range(len(self.__springdampers)): f_int = self.__springdampers[n].force_value() i, j, *_ = self.__connectivity_matrix[n] self.__f[i*3: i*3 + 3] += f_int self.__f[j*3: j*3 + 3] -= f_int return self.__f # def __system_jacobians(self): # self.__jx[self.__jx != 0] = 0 # self.__jv[self.__jv != 0] = 0 # for n in range(len(self.__springdampers)): # jx, jv = self.__springdampers[n].calculate_jacobian() # i, j, *_ = self.__connectivity_matrix[n] # if self.__particles[i].fixed: # if self.__particles[i].constraint_type == 'point': # jxplus = np.zeros([3,3]) # jvplus = jxplus # else: # jxplus = self.__particles[i].constraint_projection_matrix.dot(jx) # jvplus = self.__particles[i].constraint_projection_matrix.dot(jv) # else: # jxplus = jx # jvplus = jv # if self.__particles[j].fixed: # if self.__particles[j].constraint_type == 'point': # jxmin = np.zeros([3,3]) # jvmin = jxmin # else: # jxmin = self.__particles[j].constraint_projection_matrix.dot(jx) # jvmin = self.__particles[j].constraint_projection_matrix.dot(jv) # else: # jxmin = jx # jvmin = jv # self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jxplus # self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jxplus # self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jxmin # self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jxmin # self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jvplus # self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jvplus # self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jvmin # self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jvmin # return self.__jx, self.__jv def __system_jacobians(self): # !!! this lookup and zeroing out takes way more time than just replacing it # but replace with sparse method instead! self.__jx[self.__jx != 0] = 0 self.__jv[self.__jv != 0] = 0 for n in range(len(self.__springdampers)): jx, jv = self.__springdampers[n].calculate_jacobian() i, j, *_ = self.__connectivity_matrix[n] self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jx self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jx self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jx self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jx self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jv self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jv self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jv self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jv return self.__jx, self.__jv def __update_x_v(self, x_next: npt.ArrayLike, v_next: npt.ArrayLike): for i in range(self.__n): self.__particles[i].update_pos(x_next[i * 3:i * 3 + 3]) self.__particles[i].update_vel(v_next[i * 3:i * 3 + 3]) return def __update_w_kin(self, w_kin_new: float): self.__w_kin_min1 = self.__w_kin self.__w_kin = w_kin_new return def update_pos_unsafe(self, x_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_pos_unsafe(x_new[3*i: 3*i+3]) def update_vel_unsafe(self, v_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_vel_unsafe(v_new[3*i: 3*i+3]) def __save_state(self): self.__x_min2 = self.__x_min1 self.__x_min1 = self.__pack_x_current() return def find_reaction_forces(self): fixlist = [p.fixed for p in self.particles] projections = [p.constraint_projection_matrix for p in np.array(self.particles)[fixlist]] forces = self.__f.reshape((self.__n,3)) forces = -forces[fixlist] for i, projection in enumerate(projections): forces[i] -= projection.dot(forces[i].T).T return forces @property def particles(self): # @property decorators required, as PS info might be required for external calcs return self.__particles @property def springdampers(self): return self.__springdampers # @property # def stiffness_m(self): # self.__system_jacobians() # return self.__jx @property def kinetic_energy(self): return self.__calc_kin_energy() @property def f_int(self): f_int = self.__f.copy() for i in range(len(self.__particles)): # need to exclude fixed particles for force-based convergence if self.__particles[i].fixed: f_int[i*3:(i+1)*3] = 0 return f_int @property def x_v_current(self): return self.__pack_x_current(), self.__pack_v_current() @property def x_v_current_3D(self): x = self.__pack_x_current() v = self.__pack_v_current() x = np.reshape(x, (int(len(x)/3),3)) v = np.reshape(v, (int(len(v)/3),3)) return x, v @property def history(self): return self.__history @property def params(self): return self.__params @property def n(self): return self.__n def plot(self, ax=None, colors = None): \"\"\"\"Plots current system configuration\"\"\" if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') fixlist = [] freelist = [] for particle in self.__particles: if particle.fixed: fixlist.append(particle.x) else: freelist.append(particle.x) fixlist = np.array(fixlist) freelist = np.array(freelist) if len(fixlist)>0: ax.scatter(fixlist[:,0],fixlist[:,1],fixlist[:,2], color = 'red', marker = 'o') if len(freelist)>0: ax.scatter(freelist[:,0],freelist[:,1],freelist[:,2], color = 'blue', marker = 'o', s =5) segments = [] for link in self.__springdampers: segments.append(link.line_segment()) if colors == 'strain': colors = [] strains = np.array([(sd.l-sd.l0)/sd.l0 for sd in self.__springdampers]) s_range = max(abs(strains.max()),abs(strains.min())) for strain_i in strains: if strain_i>0: colors.append((0,0,strain_i/s_range,1)) elif strain_i<0: colors.append((strain_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) elif colors == 'forces': colors = [] forces = np.array([sd.force_value() for sd in self.__springdampers]) forces = np.linalg.norm(forces, axis=1) s_range = max(abs(forces.max()),abs(forces.min())) for force_i in forces: if force_i>0: colors.append((0,0,force_i/s_range,1)) elif force_i<0: colors.append((force_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) else: colors = 'black' lc = Line3DCollection(segments, colors = colors, linewidths = 0.5) ax.add_collection3d(lc) ax.set_xlabel('x') ax.set_ylabel('y') ax.set_zlabel('z') ax.set_aspect('equal') return ax def plot_forces(self, forces, ax = None, length = 5): if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax = self.plot(ax) x,_ = self.x_v_current_3D ax.quiver(x[:,0], x[:,1], x[:,2], forces[:,0], forces[:,1], forces[:,2], length = length, label = ' Forces ') return ax def initialize_find_surface(self, projection_plane: str = 'z'): \"\"\" performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters ---------- projection_plane : str normal direction of plane for the mesh to be projected on for triangulation. Default: z Returns ------- simplices : list nested list of node indices that make up triangles conversion_matrix : npt.ArrayLike ndarray of shape n_nodes x n_triangles \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) # Checking projection plane if projection_plane == 'x': projection_plane = 0 elif projection_plane == 'y': projection_plane = 1 elif projection_plane == 'z': projection_plane = 2 else: raise AttributeError(\"projection_plane improperly defined; Must be x, y or z.\") # Performing triangulation points_projected = points[:,:projection_plane] # Projecting onto x-y plane tri = Delaunay(points_projected) # Finding areas of each triangle v1 = points[tri.simplices[:,0]]-points[tri.simplices[:,1]] v2 = points[tri.simplices[:,0]]-points[tri.simplices[:,2]] # Next we set up the matrix multiplication that will divide the areas # of the triangles over the actual nodes #conversion_matrix = np.zeros((self.__n*3,len(tri.simplices)*3)) v1_length = np.linalg.norm(v1, axis=1) v2_length = np.linalg.norm(v2, axis=1) v3_length = np.linalg.norm(v2-v1, axis=1) angle_1 = np.arccos(np.sum(v1*v2, axis = 1)/(v1_length*v2_length)) # Next bit is a fix for an error due to limited numerical accuracy inp = v2_length/v3_length * np.sin(angle_1) inp[inp>1] = 1 angle_2 = np.arcsin(inp) angle_3 = np.pi - angle_1 - angle_2 angle_iterator = np.column_stack((angle_1, angle_2, angle_3)).flatten()/np.pi # Sparse matrix construction rows = [] cols = [] data = [] for j, indices in enumerate(tri.simplices): for k, i in enumerate(indices): for l in range(3): rows.append(3*i+l) cols.append(3*j+l) data.append(angle_iterator[3*j+k]) conversion_matrix = sps.csr_matrix((data, (rows, cols)), shape=(self.__n*3, len(tri.simplices)*3)) #for j, indices in enumerate(tri.simplices): # for k, i in enumerate(indices): # conversion_matrix[3*i,3*j]+= angle_iterator[3*j+k] # conversion_matrix[3*i+1,3*j+1]+= angle_iterator[3*j+k] # conversion_matrix[3*i+2,3*j+2]+= angle_iterator[3*j+k] self.__simplices = tri.simplices self.__surface_conversion_matrix = conversion_matrix return tri.simplices, conversion_matrix def find_surface(self, projection_plane: str = 'z') -> np.ndarray: \"\"\" finds the surface area vector for each node in the mesh Parameters ---------- projection_plane: passed to self.initialize_find_surface(). Returns ------- areas: npt.ArrayLike 3D area vectors for each node \"\"\" if not hasattr(self, ' _ ParticleSystem__surface_conversion_matrix '): logging.warning('find_surface called without prior initialization . ') simplices, conversion_matrix = self.initialize_find_surface(projection_plane) self.__simplices = simplices self.__surface_conversion_matrix = conversion_matrix else: conversion_matrix = self.__surface_conversion_matrix simplices = self.__simplices # Gathering points of nodes points = self.__pack_x_current() n = len(points) points = points.reshape((int(n/3),3)) # Finding areas of each triangle v1 = points[simplices[:,0]]-points[simplices[:,1]] v2 = points[simplices[:,0]]-points[simplices[:,2]] # Calculate the area of the triangulated simplices area_vectors = np.cross(v1,v2)/2 # Convert these to correct particle area magnitudes # Summing vectors oposing directions cancel, which we need for finding # the direction but diminishes the area magnitude. We need to correct # for this by calculating them seperately and scaling the vector. simplice_area_magnitudes = np.linalg.norm(area_vectors, axis=1) logging.debug(f' { np . sum ( simplice_area_magnitudes ) = } ') simplice_area_magnitudes_1d = np.outer(simplice_area_magnitudes,np.ones(3)).flatten() particle_area_magnitudes_1d = conversion_matrix.dot(simplice_area_magnitudes_1d) logging.debug(f' { np . sum ( particle_area_magnitudes_1d ) = } ') logging.debug(f' { np . sum ( particle_area_magnitudes_1d [ :: 3 ]) = } ') # Now we transorm the simplice areas into nodal areas input_vector = area_vectors.flatten() area_vectors_1d_direction = conversion_matrix.dot(input_vector) area_vectors_redistributed = area_vectors_1d_direction.reshape((int(n/3),3)) # Scaling the vectors direction_magnitudes = np.linalg.norm(area_vectors_redistributed, axis = 1) logging.debug(f' { np . sum ( direction_magnitudes ) = } ') scaling_factor = particle_area_magnitudes_1d[::3] /direction_magnitudes logging.debug(f' { scaling_factor= } ') area_vectors_redistributed *= np.outer(scaling_factor,np.ones(3)) logging.debug(f' After scaling { np . sum ( np . linalg . norm ( area_vectors_redistributed , axis = 1 )) = } ') return area_vectors_redistributed def plot_triangulated_surface(self, ax = None, arrow_length = 1, plot_points = True): \"\"\" plots triangulated surface for user inspection \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) x,y,z = points[:,0], points[:,1], points[:,2] area_vectors = self.find_surface() a_u = area_vectors[:,0] a_v = area_vectors[:,1] a_w = area_vectors[:,2] if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax.plot_trisurf(x, y, z, triangles=self.__simplices, cmap=plt.cm.Spectral) if plot_points: ax.scatter(x,y,z) if arrow_length: ax.quiver(x,y,z,a_u,a_v,a_w, length = arrow_length) return ax def calculate_correct_masses(self, thickness, density): areas = np.linalg.norm(self.find_surface(), axis=1) masses = areas * thickness * density for i, particle in enumerate(self.particles): particle.set_m(masses[i]) # Recalculate mass matrix self.__m_matrix = self.__construct_m_matrix() def calculate_center_of_mass(self): locations, _ = self.x_v_current_3D masses = np.array([p.m for p in self.particles]) total_mass = np.sum(masses) weighing_vector = masses/total_mass for i in range(3): locations[:,i]*=weighing_vector COM = np.sum(locations,axis=0) return COM+self.COM_offset def calculate_mass_moment_of_inertia(self): masses = np.array([p.m for p in self.particles]) COM = self.calculate_center_of_mass() locations, _ = self.x_v_current_3D locations -= COM r2 = np.vstack([locations[:, 1]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 1]**2]) return r2.T*masses[:,np.newaxis] def displace(self, displacement : list, suppress_warnings = False): \"\"\" displaces the associated particle system with the prescribed amount around the center of mass. Parameters ---------- displacement_range : list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. suppress_warnings : bool allows for repeated displacement of PS without warnings. \"\"\" if len(displacement) != 6: raise AttributeError(\"Expected list of 6 arguments representing \" f\"x,y,z,rx,ry,rz, got list of length {len(displacement)} instead\") if hasattr(self, 'current_displacement'): if (type(self.current_displacement) != type(None) and not suppress_warnings and not np.all(self.current_displacement == -np.array(displacement))): # I want to allow this behavior, #but also inform user that by doing it this way they're breaking stuff logging . warning ( f \" Particle system is already displaced : \\ { self . current_displacement= }; displace called multiple times without\\ un - displacing . un - displacing is now broken . \") elif type(self.current_displacement) != type(None): self.current_displacement += np.array(displacement) else: self.current_displacement = np.array(displacement, dtype =float) else: self.current_displacement = np.array(displacement, dtype =float) qx, qy, qz, *_ = displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) new_locations = self.rotate_mesh(locations, displacement[3:]) new_locations = self.translate_mesh(new_locations, displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) def un_displace(self): \"\"\" Reverses current displacement of the ParticleSystem using stored val ue . \"\"\" if not hasattr(self, 'current_displacement'): raise AttributeError(\" Particle System is not currently displaced \") elif type(self.current_displacement) == type(None): raise AttributeError(\" Particle System is not currently displaced \") current_displacement = self.current_displacement reverse_displacement = -np.array(current_displacement) qx, qy, qz, *_ = reverse_displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) # Extra syntax is to apply rotations in reverse order new_locations = self.rotate_mesh(locations, reverse_displacement[3:][::-1], order = 'xyz') new_locations = self.translate_mesh(new_locations, reverse_displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) self.current_displacement = None def translate_mesh(self, mesh, translation): \"\"\" Translates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point translation : list x , y , z axis translations Returns ------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\"\" qx, qy, qz = translation mesh[:,0] += qx mesh[:,1] += qy mesh[:,2] += qz return mesh def rotate_mesh(self, mesh : npt.ArrayLike, rotations : list, order = 'xyz'): \"\"\" Rotates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point rotations : list x , y , z axis rotation angles in degrees Returns ------- rotated_mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\"\" rotation_matrix = Rotation.from_euler(order, rotations, degrees=True) rotated_mesh = np.matmul(rotation_matrix.as_matrix(), mesh.T).T return rotated_mesh def reset_history(self): for key in self.history.keys(): if type(self.history[key]) == list: self.history[key] = [] else: self.history[key] = np.zeros(self.history[key].shape) if __name__ == \" __ main__ \": params = { # model parameters \" n \": 3, # [-] number of particles \" k \": 2e4, # [N/m] spring stiffness \" c \": 0, # [N s/m] damping coefficient \" l0 \": 0, # [m] rest length # simulation settings \" dt \": 0.001, # [s] simulation timestep \" t_steps \": 1000, # [-] number of simulated time steps \" abs_tol \": 1e-50, # [m/s] absolute error tolerance iterative solver \" rel_tol \": 1e-5, # [-] relative error tolerance iterative solver \" max_iter \": int(1e5), # [-] maximum number of iterations # physical parameters \" g \" : 9.81 # [ m / s^ 2 ] gravitational acceleration } c_matrix = [[ 0 , 1 , params [ 'k' ], params [ 'c' ]], [ 1 , 2 , params [ 'k' ], params [ 'c' ]] ] init_cond = [[[ 0 , 0 , 0 ], [ 0 , 0 , 0 ], 1 , True ], [[ 1 , 0 , 0 ], [ 0 , 0 , 0 ], 1 , False ], [[ 1 , 1 , 0 ], [ 0 , 0 , 0 ], 1 , False ] ] ps = ParticleSystem ( c_matrix , init_cond , params ) print ( ps ) ax = ps . plot () ps . plot_triangulated_surface () ps . stress_self ( 0.5 ) for i in range ( 10 ) : ps . simulate () ps . plot ( ax ) Classes ParticleSystem class ParticleSystem ( connectivity_matrix : list , initial_conditions : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], sim_param : dict , clean_particles : bool = True , init_surface = True ) View Source class ParticleSystem : def __ init__ ( self , connectivity_matrix : list , initial_conditions : npt . ArrayLike , sim_param : dict , clean_particles : bool = True , init_surface = True ) : \"\"\" Constructor for ParticleSystem object, model made up of n particles Parameters --------- connectivity_matrix : list 2-by-m matrix, where each column contains a nodal index pair that is connectedby a spring element: [ p1: Particle, p2: Particle, k: float, c: float, optional : linktype] initial_conditions : npt.ArrayLike Array of n arrays to instantiate particles. Each subarray must contain the params required for the particle constructor: [initial_pos, initial_vel, mass, fixed: bool, constraint, optional : constraint_type] param sim_param : dict Dictionary of other parameters required for simulation (dt, rtol, ...) clean_particles : bool Sets wether or not to delete particles without connections on init init_surface : bool Sets wether or not to initialise the surface finding. If disabled will perform it auto matically on surface calculation. But it gives the opertunity to initialise it manually with some extra parameters. \"\"\" if clean_particles : self . clean_up ( connectivity_matrix , initial_conditions ) self . __ connectivity_matrix = connectivity_matrix self . __ initial_conditions = initial_conditions self . __ n = len ( initial_conditions ) self . __ params = sim_param self . __ dt = sim_param [ \"dt\" ] self . __ rtol = sim_param [ \"rel_tol\" ] self . __ atol = sim_param [ \"abs_tol\" ] self . __ maxiter = int ( sim_param [ \"max_iter\" ]) # allocate memory self . __ particles = [] self . __ springdampers = [] self . __ f = np . zeros (( self . __ n * 3 , ), dtype='float64' ) self . __ jx = np . zeros (( self . __ n * 3 , self . __ n * 3 ), dtype='float64' ) self . __ jv = np . zeros (( self . __ n * 3 , self . __ n * 3 )) self . __ instantiate_particles ( initial_conditions ) self . __ m_matrix = self . __ construct_m_matrix () self . __ instantiate_springdampers () # Variables required for kinetic damping self . __ w_kin = self . __ calc_kin_energy () self . __ w_kin_min1 = self . __ calc_kin_energy () self . __ vis_damp = True self . __ x_min1 = np . zeros ( self . __ n , ) self . __ x_min2 = np . zeros ( self . __ n , ) # Variables that aid simulations self . COM_offset = np . zeros ( 3 ) # setup some recording self . __ history = { 'dt' : [], 'E_kin' : []} if init_surface : self . initialize_find_surface () return def __ str__ ( self ) : description = \"\" description += \"ParticleSystem object instantiated with attributes\\nConnectivity matrix:\" description += str ( self . __ connectivity_matrix ) description += \"\\n\\nInstantiated particles:\\n\" n = 1 for particle in self . __ particles : description += f \"p{n}: {particle}\\n\" n += 1 return description def __ instantiate_particles ( self , initial_conditions : list ) : for set_of_initial_cond in initial_conditions : x = set_of_initial_cond [ 0 ] v = set_of_initial_cond [ 1 ] m = set_of_initial_cond [ 2 ] f = set_of_initial_cond [ 3 ] if f and len ( set_of_initial_cond ) >= 5 : con = set_of_initial_cond [ 4 ] con_t = set_of_initial_cond [ 5 ] self . __ particles . append ( Particle ( x , v , m , f , con , con_t )) else : self . __ particles . append ( Particle ( x , v , m , f )) return def __ instantiate_springdampers ( self ) : for link in self . __ connectivity_matrix : link = link . copy () #needed to not override the __ connectivity_matrix link [ 0 ] = self . __ particles [ link [ 0 ]] link [ 1 ] = self . __ particles [ link [ 1 ]] SD = SpringDamper ( * link ) self . __ springdampers . append ( SD ) link [ 0 ]. connections . append ( SD ) link [ 1 ]. connections . append ( SD ) return def clean_up ( self , connectivity_matrix , initial_conditions ) : remove_list = set ( range ( len ( initial_conditions ))) for link in connectivity_matrix : try : remove_list . remove ( link [ 0 ]) except : pass try : remove_list . remove ( link [ 1 ]) except : pass remove_list = list ( remove_list ) remove_list . sort () for i in remove_list [ ::- 1 ] : del initial_conditions [ i ] for link in connectivity_matrix : if link [ 0 ] > i : link [ 0 ] -= 1 if link [ 1 ] > i : link [ 1 ] -= 1 def stress_self ( self , factor : float = 0 ) : \"\"\"Set all node lengths to zero to homogenously stress mesh\"\"\" if factor == 0 : for link in self . springdampers : link . l0 = 0 else : for link in self . springdampers : link . l0 *= factor return def __ construct_m_matrix ( self ) : matrix = np . zeros (( self . __ n * 3 , self . __ n * 3 )) for i in range ( self . __ n ) : matrix [ i * 3 : i * 3 + 3 , i * 3 : i * 3 + 3 ] += np . identity ( 3 ) * self . __ particles [ i ]. m return matrix def __ calc_kin_energy ( self ) : v = self . __ pack_v_current () w_kin = np . matmul ( np . matmul ( v , self . __ m_matrix ), v . T ) # Kinetic energy , 0.5 constant can be neglected return w_kin def simulate ( self , f_external : npt . ArrayLike = ()) : \"\"\" Core simulate function to advance sim a timestep Parameters embedded in self.__params ------------------------------------ adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. !!! TODO complete this with the other requisits Parameters ---------- f_external : npt.ArrayLike, optional DESCRIPTION. The default is (). Returns ------- x_next : TYPE DESCRIPTION. v_next : TYPE DESCRIPTION. \"\"\" if not len ( f_external ) : # check if external force is passed as argument , otherwise use 0 vector f_external = np . zeros ( self . __ n * 3 , ) f = self . __ one_d_force_vector () + f_external v_current = self . __ pack_v_current () x_current = self . __ pack_x_current () jx , jv = self . __ system_jacobians () #jx = sps . lil_array ( jx ) #jv = sps . lil_array ( jv ) # constructing A matrix and b vector for solver A = self . __ m_matrix - self . __ dt * jv - self . __ dt ** 2 * jx b = self . __ dt * f + self . __ dt ** 2 * jx . dot ( v_current ) # checking conditioning of A # print ( \"conditioning A:\" , np . linalg . cond ( A )) # A = sps . bsr_array ( A ) # --- START Prototype new constraint approach --- point_mask = [ not p . constraint_type == 'point' for p in self . __ particles ] plane_mask = [] line_mask = [] for p in self . __ particles : if p . constraint_type == 'plane' : for i in range ( 3 ) : line_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : plane_mask . append ( False ) plane_mask . append ( True ) plane_mask . append ( True ) elif constraint [ 1 ] == 1 : plane_mask . append ( True ) plane_mask . append ( False ) plane_mask . append ( True ) elif constraint [ 2 ] == 1 : plane_mask . append ( True ) plane_mask . append ( True ) plane_mask . append ( False ) else : for i in range ( 3 ) : plane_mask . append ( True ) elif p . constraint_type == 'line' : for i in range ( 3 ) : plane_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : line_mask . append ( True ) line_mask . append ( False ) line_mask . append ( False ) elif constraint [ 1 ] == 1 : line_mask . append ( False ) line_mask . append ( True ) line_mask . append ( False ) elif constraint [ 2 ] == 1 : line_mask . append ( False ) line_mask . append ( False ) line_mask . append ( True ) else : for i in range ( 3 ) : line_mask . append ( True ) else : for i in range ( 3 ) : plane_mask . append ( True ) line_mask . append ( True ) mask = np . outer ( point_mask , [ True , True , True ]). flatten () mask *= plane_mask mask *= line_mask dv = np . zeros_like ( b , dtype='float64' ) A = A [ mask , : ][ : , mask ] b = np . array ( b )[ mask ] # BiCGSTAB from scipy library dv_filtered , _ = bicgstab ( A , b , tol = self . __ rtol , atol = self . __ atol , maxiter = self . __ maxiter ) dv [ mask ] = dv_filtered # numerical time integration following implicit Euler scheme v_next = v_current + dv if 'adaptive_timestepping' in self . __ params : v_max = v_next . max () if v_max ! = 0 : dt = min ( self . __ params [ 'adaptive_timestepping' ] / v_max , self . __ dt ) else : dt = self . __ dt self . __ history [ 'dt' ]. append ( dt ) x_next = x_current + dt * v_next logging . debug ( f'Adaptive timestepping triggered {dt=}' ) else : x_next = x_current + self . __ dt * v_next self . __ history [ 'dt' ]. append ( self . __ dt ) # function returns the pos . and vel . for the next timestep , but for fixed particles this val ue doesn't update! self.__update_x_v(x_next, v_next) # Recording data about the timestep: self.__history[' E_kin '].append(self.__calc_kin_energy()) return x_next, v_next def kin_damp_sim(self, f_ext: npt.ArrayLike = (), q_correction: bool = False): # kinetic damping algorithm # kwargs passed to self.simulate if self.__vis_damp: # Condition resetting viscous damping to 0 for link in self.__springdampers: link.c = 0 self.__c = 0 self.__vis_damp = False if len(f_ext): # condition checking if an f_ext is passed as argument self.__save_state() x_next, v_next = self.simulate(f_ext) else: self.__save_state() x_next, v_next = self.simulate() w_kin_new = self.__calc_kin_energy() if w_kin_new > self.__w_kin: # kin damping algorithm, takes effect when decrease in kin energy is detected self.__update_w_kin(w_kin_new) else: v_next = np.zeros(self.__n*3, ) if q_correction: # statement to check if q_correction is desired, standard is turned off q = (self.__w_kin - w_kin_new)/(2*self.__w_kin - self.__w_kin_min1 - w_kin_new) # print(q) # print(self.__w_kin, w_kin_new) # !!! Not sure if linear interpolation between states is the way to determine new x_next !!! if q < 0.5: x_next = self.__x_min2 + (q / 0.5) * (self.__x_min1 - self.__x_min2) elif q == 0.5: x_next = self.__x_min1 elif q < 1: x_next = self.__x_min1 + ((q - 0.5) / 0.5) * (x_next - self.__x_min1) # Can also use this q factor to recalculate the state for certain timestep h self.__update_x_v(x_next, v_next) self.__update_w_kin(0) return x_next, v_next def __pack_v_current(self): return np.array([particle.v for particle in self.__particles]).flatten() def __pack_x_current(self): return np.array([particle.x for particle in self.__particles]).flatten() def __one_d_force_vector(self): #self.__f[self.__f != 0] = 0 self.__f = np.zeros(self.__f.shape, dtype=np.float64) for n in range(len(self.__springdampers)): f_int = self.__springdampers[n].force_value() i, j, *_ = self.__connectivity_matrix[n] self.__f[i*3: i*3 + 3] += f_int self.__f[j*3: j*3 + 3] -= f_int return self.__f # def __system_jacobians(self): # self.__jx[self.__jx != 0] = 0 # self.__jv[self.__jv != 0] = 0 # for n in range(len(self.__springdampers)): # jx, jv = self.__springdampers[n].calculate_jacobian() # i, j, *_ = self.__connectivity_matrix[n] # if self.__particles[i].fixed: # if self.__particles[i].constraint_type == 'point': # jxplus = np.zeros([3,3]) # jvplus = jxplus # else: # jxplus = self.__particles[i].constraint_projection_matrix.dot(jx) # jvplus = self.__particles[i].constraint_projection_matrix.dot(jv) # else: # jxplus = jx # jvplus = jv # if self.__particles[j].fixed: # if self.__particles[j].constraint_type == 'point': # jxmin = np.zeros([3,3]) # jvmin = jxmin # else: # jxmin = self.__particles[j].constraint_projection_matrix.dot(jx) # jvmin = self.__particles[j].constraint_projection_matrix.dot(jv) # else: # jxmin = jx # jvmin = jv # self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jxplus # self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jxplus # self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jxmin # self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jxmin # self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jvplus # self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jvplus # self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jvmin # self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jvmin # return self.__jx, self.__jv def __system_jacobians(self): # !!! this lookup and zeroing out takes way more time than just replacing it # but replace with sparse method instead! self.__jx[self.__jx != 0] = 0 self.__jv[self.__jv != 0] = 0 for n in range(len(self.__springdampers)): jx, jv = self.__springdampers[n].calculate_jacobian() i, j, *_ = self.__connectivity_matrix[n] self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jx self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jx self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jx self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jx self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jv self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jv self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jv self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jv return self.__jx, self.__jv def __update_x_v(self, x_next: npt.ArrayLike, v_next: npt.ArrayLike): for i in range(self.__n): self.__particles[i].update_pos(x_next[i * 3:i * 3 + 3]) self.__particles[i].update_vel(v_next[i * 3:i * 3 + 3]) return def __update_w_kin(self, w_kin_new: float): self.__w_kin_min1 = self.__w_kin self.__w_kin = w_kin_new return def update_pos_unsafe(self, x_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_pos_unsafe(x_new[3*i: 3*i+3]) def update_vel_unsafe(self, v_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_vel_unsafe(v_new[3*i: 3*i+3]) def __save_state(self): self.__x_min2 = self.__x_min1 self.__x_min1 = self.__pack_x_current() return def find_reaction_forces(self): fixlist = [p.fixed for p in self.particles] projections = [p.constraint_projection_matrix for p in np.array(self.particles)[fixlist]] forces = self.__f.reshape((self.__n,3)) forces = -forces[fixlist] for i, projection in enumerate(projections): forces[i] -= projection.dot(forces[i].T).T return forces @property def particles(self): # @property decorators required, as PS info might be required for external calcs return self.__particles @property def springdampers(self): return self.__springdampers # @property # def stiffness_m(self): # self.__system_jacobians() # return self.__jx @property def kinetic_energy(self): return self.__calc_kin_energy() @property def f_int(self): f_int = self.__f.copy() for i in range(len(self.__particles)): # need to exclude fixed particles for force-based convergence if self.__particles[i].fixed: f_int[i*3:(i+1)*3] = 0 return f_int @property def x_v_current(self): return self.__pack_x_current(), self.__pack_v_current() @property def x_v_current_3D(self): x = self.__pack_x_current() v = self.__pack_v_current() x = np.reshape(x, (int(len(x)/3),3)) v = np.reshape(v, (int(len(v)/3),3)) return x, v @property def history(self): return self.__history @property def params(self): return self.__params @property def n(self): return self.__n def plot(self, ax=None, colors = None): \"\"\"\"Plots current system configuration\"\"\" if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') fixlist = [] freelist = [] for particle in self.__particles: if particle.fixed: fixlist.append(particle.x) else: freelist.append(particle.x) fixlist = np.array(fixlist) freelist = np.array(freelist) if len(fixlist)>0: ax.scatter(fixlist[:,0],fixlist[:,1],fixlist[:,2], color = 'red', marker = 'o') if len(freelist)>0: ax.scatter(freelist[:,0],freelist[:,1],freelist[:,2], color = 'blue', marker = 'o', s =5) segments = [] for link in self.__springdampers: segments.append(link.line_segment()) if colors == 'strain': colors = [] strains = np.array([(sd.l-sd.l0)/sd.l0 for sd in self.__springdampers]) s_range = max(abs(strains.max()),abs(strains.min())) for strain_i in strains: if strain_i>0: colors.append((0,0,strain_i/s_range,1)) elif strain_i<0: colors.append((strain_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) elif colors == 'forces': colors = [] forces = np.array([sd.force_value() for sd in self.__springdampers]) forces = np.linalg.norm(forces, axis=1) s_range = max(abs(forces.max()),abs(forces.min())) for force_i in forces: if force_i>0: colors.append((0,0,force_i/s_range,1)) elif force_i<0: colors.append((force_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) else: colors = 'black' lc = Line3DCollection(segments, colors = colors, linewidths = 0.5) ax.add_collection3d(lc) ax.set_xlabel('x') ax.set_ylabel('y') ax.set_zlabel('z') ax.set_aspect('equal') return ax def plot_forces(self, forces, ax = None, length = 5): if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax = self.plot(ax) x,_ = self.x_v_current_3D ax.quiver(x[:,0], x[:,1], x[:,2], forces[:,0], forces[:,1], forces[:,2], length = length, label = ' Forces ') return ax def initialize_find_surface(self, projection_plane: str = 'z'): \"\"\" performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters ---------- projection_plane : str normal direction of plane for the mesh to be projected on for triangulation. Default: z Returns ------- simplices : list nested list of node indices that make up triangles conversion_matrix : npt.ArrayLike ndarray of shape n_nodes x n_triangles \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) # Checking projection plane if projection_plane == 'x': projection_plane = 0 elif projection_plane == 'y': projection_plane = 1 elif projection_plane == 'z': projection_plane = 2 else: raise AttributeError(\"projection_plane improperly defined; Must be x, y or z.\") # Performing triangulation points_projected = points[:,:projection_plane] # Projecting onto x-y plane tri = Delaunay(points_projected) # Finding areas of each triangle v1 = points[tri.simplices[:,0]]-points[tri.simplices[:,1]] v2 = points[tri.simplices[:,0]]-points[tri.simplices[:,2]] # Next we set up the matrix multiplication that will divide the areas # of the triangles over the actual nodes #conversion_matrix = np.zeros((self.__n*3,len(tri.simplices)*3)) v1_length = np.linalg.norm(v1, axis=1) v2_length = np.linalg.norm(v2, axis=1) v3_length = np.linalg.norm(v2-v1, axis=1) angle_1 = np.arccos(np.sum(v1*v2, axis = 1)/(v1_length*v2_length)) # Next bit is a fix for an error due to limited numerical accuracy inp = v2_length/v3_length * np.sin(angle_1) inp[inp>1] = 1 angle_2 = np.arcsin(inp) angle_3 = np.pi - angle_1 - angle_2 angle_iterator = np.column_stack((angle_1, angle_2, angle_3)).flatten()/np.pi # Sparse matrix construction rows = [] cols = [] data = [] for j, indices in enumerate(tri.simplices): for k, i in enumerate(indices): for l in range(3): rows.append(3*i+l) cols.append(3*j+l) data.append(angle_iterator[3*j+k]) conversion_matrix = sps.csr_matrix((data, (rows, cols)), shape=(self.__n*3, len(tri.simplices)*3)) #for j, indices in enumerate(tri.simplices): # for k, i in enumerate(indices): # conversion_matrix[3*i,3*j]+= angle_iterator[3*j+k] # conversion_matrix[3*i+1,3*j+1]+= angle_iterator[3*j+k] # conversion_matrix[3*i+2,3*j+2]+= angle_iterator[3*j+k] self.__simplices = tri.simplices self.__surface_conversion_matrix = conversion_matrix return tri.simplices, conversion_matrix def find_surface(self, projection_plane: str = 'z') -> np.ndarray: \"\"\" finds the surface area vector for each node in the mesh Parameters ---------- projection_plane: passed to self.initialize_find_surface(). Returns ------- areas: npt.ArrayLike 3D area vectors for each node \"\"\" if not hasattr(self, ' _ ParticleSystem__surface_conversion_matrix '): logging.warning('find_surface called without prior initialization . ') simplices, conversion_matrix = self.initialize_find_surface(projection_plane) self.__simplices = simplices self.__surface_conversion_matrix = conversion_matrix else: conversion_matrix = self.__surface_conversion_matrix simplices = self.__simplices # Gathering points of nodes points = self.__pack_x_current() n = len(points) points = points.reshape((int(n/3),3)) # Finding areas of each triangle v1 = points[simplices[:,0]]-points[simplices[:,1]] v2 = points[simplices[:,0]]-points[simplices[:,2]] # Calculate the area of the triangulated simplices area_vectors = np.cross(v1,v2)/2 # Convert these to correct particle area magnitudes # Summing vectors oposing directions cancel, which we need for finding # the direction but diminishes the area magnitude. We need to correct # for this by calculating them seperately and scaling the vector. simplice_area_magnitudes = np.linalg.norm(area_vectors, axis=1) logging.debug(f' { np . sum ( simplice_area_magnitudes ) = } ') simplice_area_magnitudes_1d = np.outer(simplice_area_magnitudes,np.ones(3)).flatten() particle_area_magnitudes_1d = conversion_matrix.dot(simplice_area_magnitudes_1d) logging.debug(f' { np . sum ( particle_area_magnitudes_1d ) = } ') logging.debug(f' { np . sum ( particle_area_magnitudes_1d [ :: 3 ]) = } ') # Now we transorm the simplice areas into nodal areas input_vector = area_vectors.flatten() area_vectors_1d_direction = conversion_matrix.dot(input_vector) area_vectors_redistributed = area_vectors_1d_direction.reshape((int(n/3),3)) # Scaling the vectors direction_magnitudes = np.linalg.norm(area_vectors_redistributed, axis = 1) logging.debug(f' { np . sum ( direction_magnitudes ) = } ') scaling_factor = particle_area_magnitudes_1d[::3] /direction_magnitudes logging.debug(f' { scaling_factor= } ') area_vectors_redistributed *= np.outer(scaling_factor,np.ones(3)) logging.debug(f' After scaling { np . sum ( np . linalg . norm ( area_vectors_redistributed , axis = 1 )) = } ') return area_vectors_redistributed def plot_triangulated_surface(self, ax = None, arrow_length = 1, plot_points = True): \"\"\" plots triangulated surface for user inspection \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) x,y,z = points[:,0], points[:,1], points[:,2] area_vectors = self.find_surface() a_u = area_vectors[:,0] a_v = area_vectors[:,1] a_w = area_vectors[:,2] if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax.plot_trisurf(x, y, z, triangles=self.__simplices, cmap=plt.cm.Spectral) if plot_points: ax.scatter(x,y,z) if arrow_length: ax.quiver(x,y,z,a_u,a_v,a_w, length = arrow_length) return ax def calculate_correct_masses(self, thickness, density): areas = np.linalg.norm(self.find_surface(), axis=1) masses = areas * thickness * density for i, particle in enumerate(self.particles): particle.set_m(masses[i]) # Recalculate mass matrix self.__m_matrix = self.__construct_m_matrix() def calculate_center_of_mass(self): locations, _ = self.x_v_current_3D masses = np.array([p.m for p in self.particles]) total_mass = np.sum(masses) weighing_vector = masses/total_mass for i in range(3): locations[:,i]*=weighing_vector COM = np.sum(locations,axis=0) return COM+self.COM_offset def calculate_mass_moment_of_inertia(self): masses = np.array([p.m for p in self.particles]) COM = self.calculate_center_of_mass() locations, _ = self.x_v_current_3D locations -= COM r2 = np.vstack([locations[:, 1]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 1]**2]) return r2.T*masses[:,np.newaxis] def displace(self, displacement : list, suppress_warnings = False): \"\"\" displaces the associated particle system with the prescribed amount around the center of mass. Parameters ---------- displacement_range : list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. suppress_warnings : bool allows for repeated displacement of PS without warnings. \"\"\" if len(displacement) != 6: raise AttributeError(\"Expected list of 6 arguments representing \" f\"x,y,z,rx,ry,rz, got list of length {len(displacement)} instead\") if hasattr(self, 'current_displacement'): if (type(self.current_displacement) != type(None) and not suppress_warnings and not np.all(self.current_displacement == -np.array(displacement))): # I want to allow this behavior, #but also inform user that by doing it this way they're breaking stuff logging . warning ( f \" Particle system is already displaced : \\ { self . current_displacement= }; displace called multiple times without\\ un - displacing . un - displacing is now broken . \") elif type(self.current_displacement) != type(None): self.current_displacement += np.array(displacement) else: self.current_displacement = np.array(displacement, dtype =float) else: self.current_displacement = np.array(displacement, dtype =float) qx, qy, qz, *_ = displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) new_locations = self.rotate_mesh(locations, displacement[3:]) new_locations = self.translate_mesh(new_locations, displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) def un_displace(self): \"\"\" Reverses current displacement of the ParticleSystem using stored val ue . \"\"\" if not hasattr(self, 'current_displacement'): raise AttributeError(\" Particle System is not currently displaced \") elif type(self.current_displacement) == type(None): raise AttributeError(\" Particle System is not currently displaced \") current_displacement = self.current_displacement reverse_displacement = -np.array(current_displacement) qx, qy, qz, *_ = reverse_displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) # Extra syntax is to apply rotations in reverse order new_locations = self.rotate_mesh(locations, reverse_displacement[3:][::-1], order = 'xyz') new_locations = self.translate_mesh(new_locations, reverse_displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) self.current_displacement = None def translate_mesh(self, mesh, translation): \"\"\" Translates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point translation : list x , y , z axis translations Returns ------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\"\" qx, qy, qz = translation mesh[:,0] += qx mesh[:,1] += qy mesh[:,2] += qz return mesh def rotate_mesh(self, mesh : npt.ArrayLike, rotations : list, order = 'xyz'): \"\"\" Rotates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point rotations : list x , y , z axis rotation angles in degrees Returns ------- rotated_mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\" \" rotation_matrix = Rotation . from_euler ( order , rotations , degrees = True ) rotated_mesh = np . matmul ( rotation_matrix . as_matrix (), mesh . T ). T return rotated_mesh def reset_history ( self ) : for key in self . history . keys () : if type ( self . history [ key ]) == list : self . history [ key ] = [] else : self . history [ key ] = np . zeros ( self . history [ key ]. shape ) Instance variables f_int history kinetic_energy n params particles springdampers x_v_current x_v_current_3D Methods calculate_center_of_mass def calculate_center_of_mass ( self ) View Source def calculate_center_of_mass ( self ) : locations , _ = self . x_v_current_3D masses = np . array ( [ p . m for p in self . particles ] ) total_mass = np . sum ( masses ) weighing_vector = masses / total_mass for i in range ( 3 ) : locations [:, i ] *= weighing_vector COM = np . sum ( locations , axis = 0 ) return COM + self . COM_offset calculate_correct_masses def calculate_correct_masses ( self , thickness , density ) View Source def calculate_correct_masses ( self , thickness , density ) : areas = np . linalg . norm ( self . find_surface (), axis = 1 ) masses = areas * thickness * density for i , particle in enumerate ( self . particles ) : particle . set_m ( masses [ i ] ) # Recalculate mass matrix self . __m_matrix = self . __construct_m_matrix () calculate_mass_moment_of_inertia def calculate_mass_moment_of_inertia ( self ) View Source def calculate_mass_moment_of_inertia ( self ) : masses = np . array ( [ p . m for p in self . particles ] ) COM = self . calculate_center_of_mass () locations , _ = self . x_v_current_3D locations -= COM r2 = np . vstack ( [ locations [:, 1 ] ** 2 + locations [:, 2 ] ** 2 , locations [:, 0 ] ** 2 + locations [:, 2 ] ** 2 , locations [:, 0 ] ** 2 + locations [:, 1 ] ** 2 ] ) return r2 . T * masses [:, np . newaxis ] clean_up def clean_up ( self , connectivity_matrix , initial_conditions ) View Source def clean_up ( self , connectivity_matrix , initial_conditions ) : remove_list = set ( range ( len ( initial_conditions ))) for link in connectivity_matrix : try : remove_list . remove ( link [ 0 ]) except : pass try : remove_list . remove ( link [ 1 ]) except : pass remove_list = list ( remove_list ) remove_list . sort () for i in remove_list [ ::- 1 ] : del initial_conditions [ i ] for link in connectivity_matrix : if link [ 0 ] > i : link [ 0 ] -= 1 if link [ 1 ] > i : link [ 1 ] -= 1 displace def displace ( self , displacement : list , suppress_warnings = False ) displaces the associated particle system with the prescribed amount around the center of mass. Parameters: Name Type Description Default displacement_range list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. None suppress_warnings bool allows for repeated displacement of PS without warnings. None View Source def displace ( self , displacement : list , suppress_warnings = False ) : \"\"\" displaces the associated particle system with the prescribed amount around the center of mass. Parameters ---------- displacement_range : list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. suppress_warnings : bool allows for repeated displacement of PS without warnings. \"\"\" if len ( displacement ) != 6 : raise AttributeError ( \"Expected list of 6 arguments representing \" f \"x,y,z,rx,ry,rz, got list of length {len(displacement)} instead\" ) if hasattr ( self , 'current_displacement' ) : if ( type ( self . current_displacement ) != type ( None ) and not suppress_warnings and not np . all ( self . current_displacement == - np . array ( displacement ))) : # I want to allow this behavior , #but also inform user that by doing it this way they 're breaking stuff logging.warning(f\"Particle system is already displaced: \\ {self.current_displacement=}; displace called multiple times without\\ un-displacing. un-displacing is now broken.\") elif type(self.current_displacement) != type(None): self.current_displacement += np.array(displacement) else: self.current_displacement = np.array(displacement, dtype =float) else: self.current_displacement = np.array(displacement, dtype =float) qx, qy, qz, *_ = displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) new_locations = self.rotate_mesh(locations, displacement[3:]) new_locations = self.translate_mesh(new_locations, displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # ' Unsafe ' update needed to move fixed particles as well self . particles [ i ] . update_pos_unsafe ( location ) find_reaction_forces def find_reaction_forces ( self ) View Source def find_reaction_forces ( self ) : fixlist = [ p.fixed for p in self.particles ] projections = [ p.constraint_projection_matrix for p in np.array(self.particles)[fixlist ] ] forces = self . __f . reshape (( self . __n , 3 )) forces = - forces [ fixlist ] for i , projection in enumerate ( projections ) : forces [ i ] -= projection . dot ( forces [ i ] . T ). T return forces find_surface def find_surface ( self , projection_plane : str = 'z' ) -> numpy . ndarray finds the surface area vector for each node in the mesh Returns: Type Description npt.ArrayLike 3D area vectors for each node View Source def find_surface ( self , projection_plane : str = 'z' ) -> np . ndarray : \"\"\" finds the surface area vector for each node in the mesh Parameters ---------- projection_plane: passed to self.initialize_find_surface(). Returns ------- areas: npt.ArrayLike 3D area vectors for each node \"\"\" if not hasattr ( self , ' _ParticleSystem__surface_conversion_matrix ' ): logging . warning ( ' find_surface called without prior initialization . ' ) simplices , conversion_matrix = self . initialize_find_surface ( projection_plane ) self . __simplices = simplices self . __surface_conversion_matrix = conversion_matrix else : conversion_matrix = self . __surface_conversion_matrix simplices = self . __simplices # Gathering points of nodes points = self . __pack_x_current () n = len ( points ) points = points . reshape (( int ( n / 3 ), 3 )) # Finding areas of each triangle v1 = points [ simplices [:, 0 ]] - points [ simplices [:, 1 ]] v2 = points [ simplices [:, 0 ]] - points [ simplices [:, 2 ]] # Calculate the area of the triangulated simplices area_vectors = np . cross ( v1 , v2 ) / 2 # Convert these to correct particle area magnitudes # Summing vectors oposing directions cancel , which we need for finding # the direction but diminishes the area magnitude . We need to correct # for this by calculating them seperately and scaling the vector . simplice_area_magnitudes = np . linalg . norm ( area_vectors , axis = 1 ) logging . debug ( f ' { np . sum ( simplice_area_magnitudes )=} ' ) simplice_area_magnitudes_1d = np . outer ( simplice_area_magnitudes , np . ones ( 3 )). flatten () particle_area_magnitudes_1d = conversion_matrix . dot ( simplice_area_magnitudes_1d ) logging . debug ( f ' { np . sum ( particle_area_magnitudes_1d )=} ' ) logging . debug ( f ' { np . sum ( particle_area_magnitudes_1d [ :: 3 ])=} ' ) # Now we transorm the simplice areas into nodal areas input_vector = area_vectors . flatten () area_vectors_1d_direction = conversion_matrix . dot ( input_vector ) area_vectors_redistributed = area_vectors_1d_direction . reshape (( int ( n / 3 ), 3 )) # Scaling the vectors direction_magnitudes = np . linalg . norm ( area_vectors_redistributed , axis = 1 ) logging . debug ( f ' { np . sum ( direction_magnitudes )=} ' ) scaling_factor = particle_area_magnitudes_1d [ :: 3 ] / direction_magnitudes logging . debug ( f ' { scaling_factor =} ' ) area_vectors_redistributed *= np . outer ( scaling_factor , np . ones ( 3 )) logging . debug ( f ' After scaling { np . sum ( np . linalg . norm ( area_vectors_redistributed , axis = 1 ))=} ' ) return area_vectors_redistributed initialize_find_surface def initialize_find_surface ( self , projection_plane : str = 'z' ) performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters: Name Type Description Default projection_plane str normal direction of plane for the mesh to be projected on for triangulation. Default: z z Returns: Type Description list nested list of node indices that make up triangles View Source def initialize_find_surface ( self , projection_plane : str = 'z' ): \"\"\" performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters ---------- projection_plane : str normal direction of plane for the mesh to be projected on for triangulation. Default: z Returns ------- simplices : list nested list of node indices that make up triangles conversion_matrix : npt.ArrayLike ndarray of shape n_nodes x n_triangles \"\"\" # Gathering points of nodes points = self . __pack_x_current () points = points . reshape (( int ( len ( points ) / 3 ), 3 )) # Checking projection plane if projection_plane == 'x' : projection_plane = 0 elif projection_plane == 'y' : projection_plane = 1 elif projection_plane == 'z' : projection_plane = 2 else : raise AttributeError ( \"projection_plane improperly defined; Must be x, y or z.\" ) # Performing triangulation points_projected = points [:,: projection_plane ] # Projecting onto x-y plane tri = Delaunay ( points_projected ) # Finding areas of each triangle v1 = points [ tri . simplices [:, 0 ]] - points [ tri . simplices [:, 1 ]] v2 = points [ tri . simplices [:, 0 ]] - points [ tri . simplices [:, 2 ]] # Next we set up the matrix multiplication that will divide the areas # of the triangles over the actual nodes #conversion_matrix = np.zeros((self.__n*3,len(tri.simplices)*3)) v1_length = np . linalg . norm ( v1 , axis = 1 ) v2_length = np . linalg . norm ( v2 , axis = 1 ) v3_length = np . linalg . norm ( v2 - v1 , axis = 1 ) angle_1 = np . arccos ( np . sum ( v1 * v2 , axis = 1 ) / ( v1_length * v2_length )) # Next bit is a fix for an error due to limited numerical accuracy inp = v2_length / v3_length * np . sin ( angle_1 ) inp [ inp > 1 ] = 1 angle_2 = np . arcsin ( inp ) angle_3 = np . pi - angle_1 - angle_2 angle_iterator = np . column_stack (( angle_1 , angle_2 , angle_3 )) . flatten () / np . pi # Sparse matrix construction rows = [] cols = [] data = [] for j , indices in enumerate ( tri . simplices ): for k , i in enumerate ( indices ): for l in range ( 3 ): rows . append ( 3 * i + l ) cols . append ( 3 * j + l ) data . append ( angle_iterator [ 3 * j + k ]) conversion_matrix = sps . csr_matrix (( data , ( rows , cols )), shape = ( self . __n * 3 , len ( tri . simplices ) * 3 )) #for j, indices in enumerate(tri.simplices): # for k, i in enumerate(indices): # conversion_matrix[3*i,3*j]+= angle_iterator[3*j+k] # conversion_matrix[3*i+1,3*j+1]+= angle_iterator[3*j+k] # conversion_matrix[3*i+2,3*j+2]+= angle_iterator[3*j+k] self . __simplices = tri . simplices self . __surface_conversion_matrix = conversion_matrix return tri . simplices , conversion_matrix kin_damp_sim def kin_damp_sim ( self , f_ext : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] = (), q_correction : bool = False ) View Source def kin_damp_sim ( self , f_ext : npt . ArrayLike = () , q_correction : bool = False ) : # kinetic damping algorithm # kwargs passed to self . simulate if self . __vis_damp : # Condition resetting viscous damping to 0 for link in self . __springdampers : link . c = 0 self . __c = 0 self . __vis_damp = False if len ( f_ext ) : # condition checking if an f_ext is passed as argument self . __save_state () x_next , v_next = self . simulate ( f_ext ) else : self . __save_state () x_next , v_next = self . simulate () w_kin_new = self . __calc_kin_energy () if w_kin_new > self . __w_kin : # kin damping algorithm , takes effect when decrease in kin energy is detected self . __update_w_kin ( w_kin_new ) else : v_next = np . zeros ( self . __n * 3 , ) if q_correction : # statement to check if q_correction is desired , standard is turned off q = ( self . __w_kin - w_kin_new ) / ( 2 * self . __w_kin - self . __w_kin_min1 - w_kin_new ) # print ( q ) # print ( self . __w_kin , w_kin_new ) # !!! Not sure if linear interpolation between states is the way to determine new x_next !!! if q < 0 . 5 : x_next = self . __x_min2 + ( q / 0 . 5 ) * ( self . __x_min1 - self . __x_min2 ) elif q == 0 . 5 : x_next = self . __x_min1 elif q < 1 : x_next = self . __x_min1 + (( q - 0 . 5 ) / 0 . 5 ) * ( x_next - self . __x_min1 ) # Can also use this q factor to recalculate the state for certain timestep h self . __update_x_v ( x_next , v_next ) self . __update_w_kin ( 0 ) return x_next , v_next plot def plot ( self , ax = None , colors = None ) \"Plots current system configuration View Source def plot ( self , ax = None , colors = None ) : \"\"\"\" Plots current system configuration \"\" \" if ax == None: fig = plt.figure() ax = fig.add_subplot(projection='3d') fixlist = [] freelist = [] for particle in self.__particles: if particle.fixed: fixlist.append(particle.x) else: freelist.append(particle.x) fixlist = np.array(fixlist) freelist = np.array(freelist) if len(fixlist)>0: ax.scatter(fixlist[:,0],fixlist[:,1],fixlist[:,2], color = 'red', marker = 'o') if len(freelist)>0: ax.scatter(freelist[:,0],freelist[:,1],freelist[:,2], color = 'blue', marker = 'o', s =5) segments = [] for link in self.__springdampers: segments.append(link.line_segment()) if colors == 'strain': colors = [] strains = np.array([(sd.l-sd.l0)/sd.l0 for sd in self.__springdampers]) s_range = max(abs(strains.max()),abs(strains.min())) for strain_i in strains: if strain_i>0: colors.append((0,0,strain_i/s_range,1)) elif strain_i<0: colors.append((strain_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) elif colors == 'forces': colors = [] forces = np.array([sd.force_value() for sd in self.__springdampers]) forces = np.linalg.norm(forces, axis=1) s_range = max(abs(forces.max()),abs(forces.min())) for force_i in forces: if force_i>0: colors.append((0,0,force_i/s_range,1)) elif force_i<0: colors.append((force_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) else: colors = 'black' lc = Line3DCollection(segments, colors = colors, linewidths = 0.5) ax.add_collection3d(lc) ax.set_xlabel('x') ax.set_ylabel('y') ax.set_zlabel('z') ax.set_aspect('equal') return ax plot_forces def plot_forces ( self , forces , ax = None , length = 5 ) View Source def plot_forces ( self , forces , ax = None , length = 5 ) : if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax = self . plot ( ax ) x , _ = self . x_v_current_3D ax . quiver ( x [:, 0 ], x [:, 1 ], x [:, 2 ], forces [:, 0 ], forces [:, 1 ], forces [:, 2 ], length = length , label = 'Forces' ) return ax plot_triangulated_surface def plot_triangulated_surface ( self , ax = None , arrow_length = 1 , plot_points = True ) plots triangulated surface for user inspection View Source def plot_triangulated_surface ( self , ax = None , arrow_length = 1 , plot_points = True ): \"\"\" plots triangulated surface for user inspection \"\"\" # Gathering points of nodes points = self . __pack_x_current () points = points . reshape (( int ( len ( points ) / 3 ), 3 )) x , y , z = points [:, 0 ], points [:, 1 ], points [:, 2 ] area_vectors = self . find_surface () a_u = area_vectors [:, 0 ] a_v = area_vectors [:, 1 ] a_w = area_vectors [:, 2 ] if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = ' 3 d ' ) ax . plot_trisurf ( x , y , z , triangles = self . __simplices , cmap = plt . cm . Spectral ) if plot_points : ax . scatter ( x , y , z ) if arrow_length : ax . quiver ( x , y , z , a_u , a_v , a_w , length = arrow_length ) return ax reset_history def reset_history ( self ) View Source def reset_history ( self ) : for key in self . history . keys () : if type ( self . history [ key ] ) == list : self . history [ key ] = [] else : self . history [ key ] = np . zeros ( self . history [ key ] . shape ) rotate_mesh def rotate_mesh ( self , mesh : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], rotations : list , order = 'xyz' ) Rotates mesh locations Parameters: Name Type Description Default mesh npt.ArrayLike shape n x 3 array holding x, y, z locations of each point None rotations list x, y, z axis rotation angles in degrees None Returns: Type Description npt.ArrayLike shape n x 3 array holding x, y, z locations of each point View Source def rotate_mesh ( self , mesh : npt . ArrayLike , rotations : list , order = 'xyz' ) : \"\" \" Rotates mesh locations Parameters ---------- mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point rotations : list x, y, z axis rotation angles in degrees Returns ------- rotated_mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point \"\" \" rotation_matrix = Rotation.from_euler(order, rotations, degrees=True) rotated_mesh = np.matmul(rotation_matrix.as_matrix(), mesh.T).T return rotated_mesh simulate def simulate ( self , f_external : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] = () ) Core simulate function to advance sim a timestep Parameters embedded in self.__params adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. Todo Parameters: Name Type Description Default f_external npt.ArrayLike DESCRIPTION. The default is (). is Returns: Type Description TYPE DESCRIPTION. View Source def simulate ( self , f_external : npt . ArrayLike = ()) : \"\"\" Core simulate function to advance sim a timestep Parameters embedded in self.__params ------------------------------------ adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. !!! TODO complete this with the other requisits Parameters ---------- f_external : npt.ArrayLike, optional DESCRIPTION. The default is (). Returns ------- x_next : TYPE DESCRIPTION. v_next : TYPE DESCRIPTION. \"\"\" if not len ( f_external ) : # check if external force is passed as argument , otherwise use 0 vector f_external = np . zeros ( self . __n * 3 , ) f = self . __one_d_force_vector () + f_external v_current = self . __pack_v_current () x_current = self . __pack_x_current () jx , jv = self . __system_jacobians () #jx = sps . lil_array ( jx ) #jv = sps . lil_array ( jv ) # constructing A matrix and b vector for solver A = self . __m_matrix - self . __dt * jv - self . __dt ** 2 * jx b = self . __dt * f + self . __dt ** 2 * jx . dot ( v_current ) # checking conditioning of A # print ( \"conditioning A:\" , np . linalg . cond ( A )) #A = sps . bsr_array ( A ) # --- START Prototype new constraint approach --- point_mask = [ not p.constraint_type == 'point' for p in self.__particles ] plane_mask = [] line_mask = [] for p in self . __particles : if p . constraint_type == 'plane' : for i in range ( 3 ) : line_mask . append ( True ) constraint = p . _Particle__constraint [ 0 ] if constraint [ 0 ]== 1 : plane_mask . append ( False ) plane_mask . append ( True ) plane_mask . append ( True ) elif constraint [ 1 ]== 1 : plane_mask . append ( True ) plane_mask . append ( False ) plane_mask . append ( True ) elif constraint [ 2 ]== 1 : plane_mask . append ( True ) plane_mask . append ( True ) plane_mask . append ( False ) else : for i in range ( 3 ) : plane_mask . append ( True ) elif p . constraint_type == 'line' : for i in range ( 3 ) : plane_mask . append ( True ) constraint = p . _Particle__constraint [ 0 ] if constraint [ 0 ]== 1 : line_mask . append ( True ) line_mask . append ( False ) line_mask . append ( False ) elif constraint [ 1 ]== 1 : line_mask . append ( False ) line_mask . append ( True ) line_mask . append ( False ) elif constraint [ 2 ]== 1 : line_mask . append ( False ) line_mask . append ( False ) line_mask . append ( True ) else : for i in range ( 3 ) : line_mask . append ( True ) else : for i in range ( 3 ) : plane_mask . append ( True ) line_mask . append ( True ) mask = np . outer ( point_mask , [ True,True,True ] ). flatten () mask *= plane_mask mask *= line_mask dv = np . zeros_like ( b , dtype = 'float64' ) A = A [ mask, : ][ :, mask ] b = np . array ( b ) [ mask ] # BiCGSTAB from scipy library dv_filtered , _ = bicgstab ( A , b , tol = self . __rtol , atol = self . __atol , maxiter = self . __maxiter ) dv [ mask ] = dv_filtered # numerical time integration following implicit Euler scheme v_next = v_current + dv if 'adaptive_timestepping' in self . __params : v_max = v_next . max () if v_max != 0 : dt = min ( self . __params [ 'adaptive_timestepping' ]/ v_max , self . __dt ) else : dt = self . __dt self . __history [ 'dt' ] . append ( dt ) x_next = x_current + dt * v_next logging . debug ( f 'Adaptive timestepping triggered {dt=}' ) else : x_next = x_current + self . __dt * v_next self . __history [ 'dt' ] . append ( self . __dt ) # function returns the pos . and vel . for the next timestep , but for fixed particles this value doesn 't update! self.__update_x_v(x_next, v_next) # Recording data about the timestep: self.__history[' E_kin '] . append ( self . __calc_kin_energy ()) return x_next , v_next stress_self def stress_self ( self , factor : float = 0 ) Set all node lengths to zero to homogenously stress mesh View Source def stress_self ( self , factor : float = 0 ) : \"\"\"Set all node lengths to zero to homogenously stress mesh\"\"\" if factor == 0 : for link in self . springdampers : link . l0 = 0 else : for link in self . springdampers : link . l0 *= factor return translate_mesh def translate_mesh ( self , mesh , translation ) Translates mesh locations Parameters: Name Type Description Default mesh npt.ArrayLike shape n x 3 array holding x, y, z locations of each point None translation list x, y, z axis translations None Returns: Type Description npt.ArrayLike shape n x 3 array holding x, y, z locations of each point View Source def translate_mesh ( self , mesh , translation ) : \"\" \" Translates mesh locations Parameters ---------- mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point translation : list x, y, z axis translations Returns ------- mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point \"\" \" qx, qy, qz = translation mesh[:,0] += qx mesh[:,1] += qy mesh[:,2] += qz return mesh un_displace def un_displace ( self ) Reverses current displacement of the ParticleSystem using stored value. View Source def un_displace ( self ) : \"\"\" Reverses current displacement of the ParticleSystem using stored value. \"\"\" if not hasattr ( self , 'current_displacement' ) : raise AttributeError ( \"Particle System is not currently displaced\" ) elif type ( self . current_displacement ) == type ( None ) : raise AttributeError ( \"Particle System is not currently displaced\" ) current_displacement = self . current_displacement reverse_displacement = - np . array ( current_displacement ) qx , qy , qz , * _ = reverse_displacement locations , _ = self . x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM = self . calculate_center_of_mass () self . translate_mesh ( locations , - COM ) # Extra syntax is to apply rotations in reverse order new_locations = self . rotate_mesh ( locations , reverse_displacement [ 3 : ][ ::- 1 ], order = 'xyz' ) new_locations = self . translate_mesh ( new_locations , reverse_displacement [ : 3 ]) # Put back system in original location new_locations = self . translate_mesh ( new_locations , COM ) for i , location in enumerate ( new_locations ) : # 'Unsafe' update needed to move fixed particles as well self . particles [ i ]. update_pos_unsafe ( location ) self . current_displacement = None update_pos_unsafe def update_pos_unsafe ( self , x_new : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_pos_unsafe ( self , x_new : npt . ArrayLike ): for i , particle in enumerate ( self . __particles ): particle . update_pos_unsafe ( x_new [ 3 * i : 3 * i + 3 ]) update_vel_unsafe def update_vel_unsafe ( self , v_new : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_vel_unsafe ( self , v_new : npt . ArrayLike ): for i , particle in enumerate ( self . __particles ): particle . update_vel_unsafe ( v_new [ 3 * i : 3 * i + 3 ])","title":"Particlesystem"},{"location":"reference/src/particleSystem/ParticleSystem/#module-srcparticlesystemparticlesystem","text":"ParticleSystem framework ... View Source \"\"\" ParticleSystem framework ... \"\"\" import logging import numpy as np import numpy . typing as npt from scipy . sparse . linalg import bicgstab import scipy . sparse as sps from scipy . spatial import Delaunay from scipy . spatial . transform import Rotation import matplotlib . pyplot as plt from mpl_toolkits . mplot3d . art3d import Line3DCollection from . Particle import Particle from . SpringDamper import SpringDamper class ParticleSystem : def __ init__ ( self , connectivity_matrix : list , initial_conditions : npt . ArrayLike , sim_param : dict , clean_particles : bool = True , init_surface = True ) : \"\"\" Constructor for ParticleSystem object, model made up of n particles Parameters --------- connectivity_matrix : list 2-by-m matrix, where each column contains a nodal index pair that is connectedby a spring element: [ p1: Particle, p2: Particle, k: float, c: float, optional : linktype] initial_conditions : npt.ArrayLike Array of n arrays to instantiate particles. Each subarray must contain the params required for the particle constructor: [initial_pos, initial_vel, mass, fixed: bool, constraint, optional : constraint_type] param sim_param : dict Dictionary of other parameters required for simulation (dt, rtol, ...) clean_particles : bool Sets wether or not to delete particles without connections on init init_surface : bool Sets wether or not to initialise the surface finding. If disabled will perform it auto matically on surface calculation. But it gives the opertunity to initialise it manually with some extra parameters. \"\"\" if clean_particles : self . clean_up ( connectivity_matrix , initial_conditions ) self . __ connectivity_matrix = connectivity_matrix self . __ initial_conditions = initial_conditions self . __ n = len ( initial_conditions ) self . __ params = sim_param self . __ dt = sim_param [ \"dt\" ] self . __ rtol = sim_param [ \"rel_tol\" ] self . __ atol = sim_param [ \"abs_tol\" ] self . __ maxiter = int ( sim_param [ \"max_iter\" ]) # allocate memory self . __ particles = [] self . __ springdampers = [] self . __ f = np . zeros (( self . __ n * 3 , ), dtype='float64' ) self . __ jx = np . zeros (( self . __ n * 3 , self . __ n * 3 ), dtype='float64' ) self . __ jv = np . zeros (( self . __ n * 3 , self . __ n * 3 )) self . __ instantiate_particles ( initial_conditions ) self . __ m_matrix = self . __ construct_m_matrix () self . __ instantiate_springdampers () # Variables required for kinetic damping self . __ w_kin = self . __ calc_kin_energy () self . __ w_kin_min1 = self . __ calc_kin_energy () self . __ vis_damp = True self . __ x_min1 = np . zeros ( self . __ n , ) self . __ x_min2 = np . zeros ( self . __ n , ) # Variables that aid simulations self . COM_offset = np . zeros ( 3 ) # setup some recording self . __ history = { 'dt' : [], 'E_kin' : []} if init_surface : self . initialize_find_surface () return def __ str__ ( self ) : description = \"\" description += \"ParticleSystem object instantiated with attributes\\nConnectivity matrix:\" description += str ( self . __ connectivity_matrix ) description += \"\\n\\nInstantiated particles:\\n\" n = 1 for particle in self . __ particles : description += f \"p{n}: {particle}\\n\" n += 1 return description def __ instantiate_particles ( self , initial_conditions : list ) : for set_of_initial_cond in initial_conditions : x = set_of_initial_cond [ 0 ] v = set_of_initial_cond [ 1 ] m = set_of_initial_cond [ 2 ] f = set_of_initial_cond [ 3 ] if f and len ( set_of_initial_cond ) >= 5 : con = set_of_initial_cond [ 4 ] con_t = set_of_initial_cond [ 5 ] self . __ particles . append ( Particle ( x , v , m , f , con , con_t )) else : self . __ particles . append ( Particle ( x , v , m , f )) return def __ instantiate_springdampers ( self ) : for link in self . __ connectivity_matrix : link = link . copy () #needed to not override the __ connectivity_matrix link [ 0 ] = self . __ particles [ link [ 0 ]] link [ 1 ] = self . __ particles [ link [ 1 ]] SD = SpringDamper ( * link ) self . __ springdampers . append ( SD ) link [ 0 ]. connections . append ( SD ) link [ 1 ]. connections . append ( SD ) return def clean_up ( self , connectivity_matrix , initial_conditions ) : remove_list = set ( range ( len ( initial_conditions ))) for link in connectivity_matrix : try : remove_list . remove ( link [ 0 ]) except : pass try : remove_list . remove ( link [ 1 ]) except : pass remove_list = list ( remove_list ) remove_list . sort () for i in remove_list [ ::- 1 ] : del initial_conditions [ i ] for link in connectivity_matrix : if link [ 0 ] > i : link [ 0 ] -= 1 if link [ 1 ] > i : link [ 1 ] -= 1 def stress_self ( self , factor : float = 0 ) : \"\"\"Set all node lengths to zero to homogenously stress mesh\"\"\" if factor == 0 : for link in self . springdampers : link . l0 = 0 else : for link in self . springdampers : link . l0 *= factor return def __ construct_m_matrix ( self ) : matrix = np . zeros (( self . __ n * 3 , self . __ n * 3 )) for i in range ( self . __ n ) : matrix [ i * 3 : i * 3 + 3 , i * 3 : i * 3 + 3 ] += np . identity ( 3 ) * self . __ particles [ i ]. m return matrix def __ calc_kin_energy ( self ) : v = self . __ pack_v_current () w_kin = np . matmul ( np . matmul ( v , self . __ m_matrix ), v . T ) # Kinetic energy , 0.5 constant can be neglected return w_kin def simulate ( self , f_external : npt . ArrayLike = ()) : \"\"\" Core simulate function to advance sim a timestep Parameters embedded in self.__params ------------------------------------ adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. !!! TODO complete this with the other requisits Parameters ---------- f_external : npt.ArrayLike, optional DESCRIPTION. The default is (). Returns ------- x_next : TYPE DESCRIPTION. v_next : TYPE DESCRIPTION. \"\"\" if not len ( f_external ) : # check if external force is passed as argument , otherwise use 0 vector f_external = np . zeros ( self . __ n * 3 , ) f = self . __ one_d_force_vector () + f_external v_current = self . __ pack_v_current () x_current = self . __ pack_x_current () jx , jv = self . __ system_jacobians () #jx = sps . lil_array ( jx ) #jv = sps . lil_array ( jv ) # constructing A matrix and b vector for solver A = self . __ m_matrix - self . __ dt * jv - self . __ dt ** 2 * jx b = self . __ dt * f + self . __ dt ** 2 * jx . dot ( v_current ) # checking conditioning of A # print ( \"conditioning A:\" , np . linalg . cond ( A )) # A = sps . bsr_array ( A ) # --- START Prototype new constraint approach --- point_mask = [ not p . constraint_type == 'point' for p in self . __ particles ] plane_mask = [] line_mask = [] for p in self . __ particles : if p . constraint_type == 'plane' : for i in range ( 3 ) : line_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : plane_mask . append ( False ) plane_mask . append ( True ) plane_mask . append ( True ) elif constraint [ 1 ] == 1 : plane_mask . append ( True ) plane_mask . append ( False ) plane_mask . append ( True ) elif constraint [ 2 ] == 1 : plane_mask . append ( True ) plane_mask . append ( True ) plane_mask . append ( False ) else : for i in range ( 3 ) : plane_mask . append ( True ) elif p . constraint_type == 'line' : for i in range ( 3 ) : plane_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : line_mask . append ( True ) line_mask . append ( False ) line_mask . append ( False ) elif constraint [ 1 ] == 1 : line_mask . append ( False ) line_mask . append ( True ) line_mask . append ( False ) elif constraint [ 2 ] == 1 : line_mask . append ( False ) line_mask . append ( False ) line_mask . append ( True ) else : for i in range ( 3 ) : line_mask . append ( True ) else : for i in range ( 3 ) : plane_mask . append ( True ) line_mask . append ( True ) mask = np . outer ( point_mask , [ True , True , True ]). flatten () mask *= plane_mask mask *= line_mask dv = np . zeros_like ( b , dtype='float64' ) A = A [ mask , : ][ : , mask ] b = np . array ( b )[ mask ] # BiCGSTAB from scipy library dv_filtered , _ = bicgstab ( A , b , tol = self . __ rtol , atol = self . __ atol , maxiter = self . __ maxiter ) dv [ mask ] = dv_filtered # numerical time integration following implicit Euler scheme v_next = v_current + dv if 'adaptive_timestepping' in self . __ params : v_max = v_next . max () if v_max ! = 0 : dt = min ( self . __ params [ 'adaptive_timestepping' ] / v_max , self . __ dt ) else : dt = self . __ dt self . __ history [ 'dt' ]. append ( dt ) x_next = x_current + dt * v_next logging . debug ( f'Adaptive timestepping triggered {dt=}' ) else : x_next = x_current + self . __ dt * v_next self . __ history [ 'dt' ]. append ( self . __ dt ) # function returns the pos . and vel . for the next timestep , but for fixed particles this val ue doesn't update! self.__update_x_v(x_next, v_next) # Recording data about the timestep: self.__history[' E_kin '].append(self.__calc_kin_energy()) return x_next, v_next def kin_damp_sim(self, f_ext: npt.ArrayLike = (), q_correction: bool = False): # kinetic damping algorithm # kwargs passed to self.simulate if self.__vis_damp: # Condition resetting viscous damping to 0 for link in self.__springdampers: link.c = 0 self.__c = 0 self.__vis_damp = False if len(f_ext): # condition checking if an f_ext is passed as argument self.__save_state() x_next, v_next = self.simulate(f_ext) else: self.__save_state() x_next, v_next = self.simulate() w_kin_new = self.__calc_kin_energy() if w_kin_new > self.__w_kin: # kin damping algorithm, takes effect when decrease in kin energy is detected self.__update_w_kin(w_kin_new) else: v_next = np.zeros(self.__n*3, ) if q_correction: # statement to check if q_correction is desired, standard is turned off q = (self.__w_kin - w_kin_new)/(2*self.__w_kin - self.__w_kin_min1 - w_kin_new) # print(q) # print(self.__w_kin, w_kin_new) # !!! Not sure if linear interpolation between states is the way to determine new x_next !!! if q < 0.5: x_next = self.__x_min2 + (q / 0.5) * (self.__x_min1 - self.__x_min2) elif q == 0.5: x_next = self.__x_min1 elif q < 1: x_next = self.__x_min1 + ((q - 0.5) / 0.5) * (x_next - self.__x_min1) # Can also use this q factor to recalculate the state for certain timestep h self.__update_x_v(x_next, v_next) self.__update_w_kin(0) return x_next, v_next def __pack_v_current(self): return np.array([particle.v for particle in self.__particles]).flatten() def __pack_x_current(self): return np.array([particle.x for particle in self.__particles]).flatten() def __one_d_force_vector(self): #self.__f[self.__f != 0] = 0 self.__f = np.zeros(self.__f.shape, dtype=np.float64) for n in range(len(self.__springdampers)): f_int = self.__springdampers[n].force_value() i, j, *_ = self.__connectivity_matrix[n] self.__f[i*3: i*3 + 3] += f_int self.__f[j*3: j*3 + 3] -= f_int return self.__f # def __system_jacobians(self): # self.__jx[self.__jx != 0] = 0 # self.__jv[self.__jv != 0] = 0 # for n in range(len(self.__springdampers)): # jx, jv = self.__springdampers[n].calculate_jacobian() # i, j, *_ = self.__connectivity_matrix[n] # if self.__particles[i].fixed: # if self.__particles[i].constraint_type == 'point': # jxplus = np.zeros([3,3]) # jvplus = jxplus # else: # jxplus = self.__particles[i].constraint_projection_matrix.dot(jx) # jvplus = self.__particles[i].constraint_projection_matrix.dot(jv) # else: # jxplus = jx # jvplus = jv # if self.__particles[j].fixed: # if self.__particles[j].constraint_type == 'point': # jxmin = np.zeros([3,3]) # jvmin = jxmin # else: # jxmin = self.__particles[j].constraint_projection_matrix.dot(jx) # jvmin = self.__particles[j].constraint_projection_matrix.dot(jv) # else: # jxmin = jx # jvmin = jv # self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jxplus # self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jxplus # self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jxmin # self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jxmin # self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jvplus # self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jvplus # self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jvmin # self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jvmin # return self.__jx, self.__jv def __system_jacobians(self): # !!! this lookup and zeroing out takes way more time than just replacing it # but replace with sparse method instead! self.__jx[self.__jx != 0] = 0 self.__jv[self.__jv != 0] = 0 for n in range(len(self.__springdampers)): jx, jv = self.__springdampers[n].calculate_jacobian() i, j, *_ = self.__connectivity_matrix[n] self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jx self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jx self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jx self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jx self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jv self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jv self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jv self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jv return self.__jx, self.__jv def __update_x_v(self, x_next: npt.ArrayLike, v_next: npt.ArrayLike): for i in range(self.__n): self.__particles[i].update_pos(x_next[i * 3:i * 3 + 3]) self.__particles[i].update_vel(v_next[i * 3:i * 3 + 3]) return def __update_w_kin(self, w_kin_new: float): self.__w_kin_min1 = self.__w_kin self.__w_kin = w_kin_new return def update_pos_unsafe(self, x_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_pos_unsafe(x_new[3*i: 3*i+3]) def update_vel_unsafe(self, v_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_vel_unsafe(v_new[3*i: 3*i+3]) def __save_state(self): self.__x_min2 = self.__x_min1 self.__x_min1 = self.__pack_x_current() return def find_reaction_forces(self): fixlist = [p.fixed for p in self.particles] projections = [p.constraint_projection_matrix for p in np.array(self.particles)[fixlist]] forces = self.__f.reshape((self.__n,3)) forces = -forces[fixlist] for i, projection in enumerate(projections): forces[i] -= projection.dot(forces[i].T).T return forces @property def particles(self): # @property decorators required, as PS info might be required for external calcs return self.__particles @property def springdampers(self): return self.__springdampers # @property # def stiffness_m(self): # self.__system_jacobians() # return self.__jx @property def kinetic_energy(self): return self.__calc_kin_energy() @property def f_int(self): f_int = self.__f.copy() for i in range(len(self.__particles)): # need to exclude fixed particles for force-based convergence if self.__particles[i].fixed: f_int[i*3:(i+1)*3] = 0 return f_int @property def x_v_current(self): return self.__pack_x_current(), self.__pack_v_current() @property def x_v_current_3D(self): x = self.__pack_x_current() v = self.__pack_v_current() x = np.reshape(x, (int(len(x)/3),3)) v = np.reshape(v, (int(len(v)/3),3)) return x, v @property def history(self): return self.__history @property def params(self): return self.__params @property def n(self): return self.__n def plot(self, ax=None, colors = None): \"\"\"\"Plots current system configuration\"\"\" if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') fixlist = [] freelist = [] for particle in self.__particles: if particle.fixed: fixlist.append(particle.x) else: freelist.append(particle.x) fixlist = np.array(fixlist) freelist = np.array(freelist) if len(fixlist)>0: ax.scatter(fixlist[:,0],fixlist[:,1],fixlist[:,2], color = 'red', marker = 'o') if len(freelist)>0: ax.scatter(freelist[:,0],freelist[:,1],freelist[:,2], color = 'blue', marker = 'o', s =5) segments = [] for link in self.__springdampers: segments.append(link.line_segment()) if colors == 'strain': colors = [] strains = np.array([(sd.l-sd.l0)/sd.l0 for sd in self.__springdampers]) s_range = max(abs(strains.max()),abs(strains.min())) for strain_i in strains: if strain_i>0: colors.append((0,0,strain_i/s_range,1)) elif strain_i<0: colors.append((strain_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) elif colors == 'forces': colors = [] forces = np.array([sd.force_value() for sd in self.__springdampers]) forces = np.linalg.norm(forces, axis=1) s_range = max(abs(forces.max()),abs(forces.min())) for force_i in forces: if force_i>0: colors.append((0,0,force_i/s_range,1)) elif force_i<0: colors.append((force_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) else: colors = 'black' lc = Line3DCollection(segments, colors = colors, linewidths = 0.5) ax.add_collection3d(lc) ax.set_xlabel('x') ax.set_ylabel('y') ax.set_zlabel('z') ax.set_aspect('equal') return ax def plot_forces(self, forces, ax = None, length = 5): if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax = self.plot(ax) x,_ = self.x_v_current_3D ax.quiver(x[:,0], x[:,1], x[:,2], forces[:,0], forces[:,1], forces[:,2], length = length, label = ' Forces ') return ax def initialize_find_surface(self, projection_plane: str = 'z'): \"\"\" performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters ---------- projection_plane : str normal direction of plane for the mesh to be projected on for triangulation. Default: z Returns ------- simplices : list nested list of node indices that make up triangles conversion_matrix : npt.ArrayLike ndarray of shape n_nodes x n_triangles \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) # Checking projection plane if projection_plane == 'x': projection_plane = 0 elif projection_plane == 'y': projection_plane = 1 elif projection_plane == 'z': projection_plane = 2 else: raise AttributeError(\"projection_plane improperly defined; Must be x, y or z.\") # Performing triangulation points_projected = points[:,:projection_plane] # Projecting onto x-y plane tri = Delaunay(points_projected) # Finding areas of each triangle v1 = points[tri.simplices[:,0]]-points[tri.simplices[:,1]] v2 = points[tri.simplices[:,0]]-points[tri.simplices[:,2]] # Next we set up the matrix multiplication that will divide the areas # of the triangles over the actual nodes #conversion_matrix = np.zeros((self.__n*3,len(tri.simplices)*3)) v1_length = np.linalg.norm(v1, axis=1) v2_length = np.linalg.norm(v2, axis=1) v3_length = np.linalg.norm(v2-v1, axis=1) angle_1 = np.arccos(np.sum(v1*v2, axis = 1)/(v1_length*v2_length)) # Next bit is a fix for an error due to limited numerical accuracy inp = v2_length/v3_length * np.sin(angle_1) inp[inp>1] = 1 angle_2 = np.arcsin(inp) angle_3 = np.pi - angle_1 - angle_2 angle_iterator = np.column_stack((angle_1, angle_2, angle_3)).flatten()/np.pi # Sparse matrix construction rows = [] cols = [] data = [] for j, indices in enumerate(tri.simplices): for k, i in enumerate(indices): for l in range(3): rows.append(3*i+l) cols.append(3*j+l) data.append(angle_iterator[3*j+k]) conversion_matrix = sps.csr_matrix((data, (rows, cols)), shape=(self.__n*3, len(tri.simplices)*3)) #for j, indices in enumerate(tri.simplices): # for k, i in enumerate(indices): # conversion_matrix[3*i,3*j]+= angle_iterator[3*j+k] # conversion_matrix[3*i+1,3*j+1]+= angle_iterator[3*j+k] # conversion_matrix[3*i+2,3*j+2]+= angle_iterator[3*j+k] self.__simplices = tri.simplices self.__surface_conversion_matrix = conversion_matrix return tri.simplices, conversion_matrix def find_surface(self, projection_plane: str = 'z') -> np.ndarray: \"\"\" finds the surface area vector for each node in the mesh Parameters ---------- projection_plane: passed to self.initialize_find_surface(). Returns ------- areas: npt.ArrayLike 3D area vectors for each node \"\"\" if not hasattr(self, ' _ ParticleSystem__surface_conversion_matrix '): logging.warning('find_surface called without prior initialization . ') simplices, conversion_matrix = self.initialize_find_surface(projection_plane) self.__simplices = simplices self.__surface_conversion_matrix = conversion_matrix else: conversion_matrix = self.__surface_conversion_matrix simplices = self.__simplices # Gathering points of nodes points = self.__pack_x_current() n = len(points) points = points.reshape((int(n/3),3)) # Finding areas of each triangle v1 = points[simplices[:,0]]-points[simplices[:,1]] v2 = points[simplices[:,0]]-points[simplices[:,2]] # Calculate the area of the triangulated simplices area_vectors = np.cross(v1,v2)/2 # Convert these to correct particle area magnitudes # Summing vectors oposing directions cancel, which we need for finding # the direction but diminishes the area magnitude. We need to correct # for this by calculating them seperately and scaling the vector. simplice_area_magnitudes = np.linalg.norm(area_vectors, axis=1) logging.debug(f' { np . sum ( simplice_area_magnitudes ) = } ') simplice_area_magnitudes_1d = np.outer(simplice_area_magnitudes,np.ones(3)).flatten() particle_area_magnitudes_1d = conversion_matrix.dot(simplice_area_magnitudes_1d) logging.debug(f' { np . sum ( particle_area_magnitudes_1d ) = } ') logging.debug(f' { np . sum ( particle_area_magnitudes_1d [ :: 3 ]) = } ') # Now we transorm the simplice areas into nodal areas input_vector = area_vectors.flatten() area_vectors_1d_direction = conversion_matrix.dot(input_vector) area_vectors_redistributed = area_vectors_1d_direction.reshape((int(n/3),3)) # Scaling the vectors direction_magnitudes = np.linalg.norm(area_vectors_redistributed, axis = 1) logging.debug(f' { np . sum ( direction_magnitudes ) = } ') scaling_factor = particle_area_magnitudes_1d[::3] /direction_magnitudes logging.debug(f' { scaling_factor= } ') area_vectors_redistributed *= np.outer(scaling_factor,np.ones(3)) logging.debug(f' After scaling { np . sum ( np . linalg . norm ( area_vectors_redistributed , axis = 1 )) = } ') return area_vectors_redistributed def plot_triangulated_surface(self, ax = None, arrow_length = 1, plot_points = True): \"\"\" plots triangulated surface for user inspection \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) x,y,z = points[:,0], points[:,1], points[:,2] area_vectors = self.find_surface() a_u = area_vectors[:,0] a_v = area_vectors[:,1] a_w = area_vectors[:,2] if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax.plot_trisurf(x, y, z, triangles=self.__simplices, cmap=plt.cm.Spectral) if plot_points: ax.scatter(x,y,z) if arrow_length: ax.quiver(x,y,z,a_u,a_v,a_w, length = arrow_length) return ax def calculate_correct_masses(self, thickness, density): areas = np.linalg.norm(self.find_surface(), axis=1) masses = areas * thickness * density for i, particle in enumerate(self.particles): particle.set_m(masses[i]) # Recalculate mass matrix self.__m_matrix = self.__construct_m_matrix() def calculate_center_of_mass(self): locations, _ = self.x_v_current_3D masses = np.array([p.m for p in self.particles]) total_mass = np.sum(masses) weighing_vector = masses/total_mass for i in range(3): locations[:,i]*=weighing_vector COM = np.sum(locations,axis=0) return COM+self.COM_offset def calculate_mass_moment_of_inertia(self): masses = np.array([p.m for p in self.particles]) COM = self.calculate_center_of_mass() locations, _ = self.x_v_current_3D locations -= COM r2 = np.vstack([locations[:, 1]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 1]**2]) return r2.T*masses[:,np.newaxis] def displace(self, displacement : list, suppress_warnings = False): \"\"\" displaces the associated particle system with the prescribed amount around the center of mass. Parameters ---------- displacement_range : list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. suppress_warnings : bool allows for repeated displacement of PS without warnings. \"\"\" if len(displacement) != 6: raise AttributeError(\"Expected list of 6 arguments representing \" f\"x,y,z,rx,ry,rz, got list of length {len(displacement)} instead\") if hasattr(self, 'current_displacement'): if (type(self.current_displacement) != type(None) and not suppress_warnings and not np.all(self.current_displacement == -np.array(displacement))): # I want to allow this behavior, #but also inform user that by doing it this way they're breaking stuff logging . warning ( f \" Particle system is already displaced : \\ { self . current_displacement= }; displace called multiple times without\\ un - displacing . un - displacing is now broken . \") elif type(self.current_displacement) != type(None): self.current_displacement += np.array(displacement) else: self.current_displacement = np.array(displacement, dtype =float) else: self.current_displacement = np.array(displacement, dtype =float) qx, qy, qz, *_ = displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) new_locations = self.rotate_mesh(locations, displacement[3:]) new_locations = self.translate_mesh(new_locations, displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) def un_displace(self): \"\"\" Reverses current displacement of the ParticleSystem using stored val ue . \"\"\" if not hasattr(self, 'current_displacement'): raise AttributeError(\" Particle System is not currently displaced \") elif type(self.current_displacement) == type(None): raise AttributeError(\" Particle System is not currently displaced \") current_displacement = self.current_displacement reverse_displacement = -np.array(current_displacement) qx, qy, qz, *_ = reverse_displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) # Extra syntax is to apply rotations in reverse order new_locations = self.rotate_mesh(locations, reverse_displacement[3:][::-1], order = 'xyz') new_locations = self.translate_mesh(new_locations, reverse_displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) self.current_displacement = None def translate_mesh(self, mesh, translation): \"\"\" Translates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point translation : list x , y , z axis translations Returns ------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\"\" qx, qy, qz = translation mesh[:,0] += qx mesh[:,1] += qy mesh[:,2] += qz return mesh def rotate_mesh(self, mesh : npt.ArrayLike, rotations : list, order = 'xyz'): \"\"\" Rotates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point rotations : list x , y , z axis rotation angles in degrees Returns ------- rotated_mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\"\" rotation_matrix = Rotation.from_euler(order, rotations, degrees=True) rotated_mesh = np.matmul(rotation_matrix.as_matrix(), mesh.T).T return rotated_mesh def reset_history(self): for key in self.history.keys(): if type(self.history[key]) == list: self.history[key] = [] else: self.history[key] = np.zeros(self.history[key].shape) if __name__ == \" __ main__ \": params = { # model parameters \" n \": 3, # [-] number of particles \" k \": 2e4, # [N/m] spring stiffness \" c \": 0, # [N s/m] damping coefficient \" l0 \": 0, # [m] rest length # simulation settings \" dt \": 0.001, # [s] simulation timestep \" t_steps \": 1000, # [-] number of simulated time steps \" abs_tol \": 1e-50, # [m/s] absolute error tolerance iterative solver \" rel_tol \": 1e-5, # [-] relative error tolerance iterative solver \" max_iter \": int(1e5), # [-] maximum number of iterations # physical parameters \" g \" : 9.81 # [ m / s^ 2 ] gravitational acceleration } c_matrix = [[ 0 , 1 , params [ 'k' ], params [ 'c' ]], [ 1 , 2 , params [ 'k' ], params [ 'c' ]] ] init_cond = [[[ 0 , 0 , 0 ], [ 0 , 0 , 0 ], 1 , True ], [[ 1 , 0 , 0 ], [ 0 , 0 , 0 ], 1 , False ], [[ 1 , 1 , 0 ], [ 0 , 0 , 0 ], 1 , False ] ] ps = ParticleSystem ( c_matrix , init_cond , params ) print ( ps ) ax = ps . plot () ps . plot_triangulated_surface () ps . stress_self ( 0.5 ) for i in range ( 10 ) : ps . simulate () ps . plot ( ax )","title":"Module src.particleSystem.ParticleSystem"},{"location":"reference/src/particleSystem/ParticleSystem/#classes","text":"","title":"Classes"},{"location":"reference/src/particleSystem/ParticleSystem/#particlesystem","text":"class ParticleSystem ( connectivity_matrix : list , initial_conditions : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], sim_param : dict , clean_particles : bool = True , init_surface = True ) View Source class ParticleSystem : def __ init__ ( self , connectivity_matrix : list , initial_conditions : npt . ArrayLike , sim_param : dict , clean_particles : bool = True , init_surface = True ) : \"\"\" Constructor for ParticleSystem object, model made up of n particles Parameters --------- connectivity_matrix : list 2-by-m matrix, where each column contains a nodal index pair that is connectedby a spring element: [ p1: Particle, p2: Particle, k: float, c: float, optional : linktype] initial_conditions : npt.ArrayLike Array of n arrays to instantiate particles. Each subarray must contain the params required for the particle constructor: [initial_pos, initial_vel, mass, fixed: bool, constraint, optional : constraint_type] param sim_param : dict Dictionary of other parameters required for simulation (dt, rtol, ...) clean_particles : bool Sets wether or not to delete particles without connections on init init_surface : bool Sets wether or not to initialise the surface finding. If disabled will perform it auto matically on surface calculation. But it gives the opertunity to initialise it manually with some extra parameters. \"\"\" if clean_particles : self . clean_up ( connectivity_matrix , initial_conditions ) self . __ connectivity_matrix = connectivity_matrix self . __ initial_conditions = initial_conditions self . __ n = len ( initial_conditions ) self . __ params = sim_param self . __ dt = sim_param [ \"dt\" ] self . __ rtol = sim_param [ \"rel_tol\" ] self . __ atol = sim_param [ \"abs_tol\" ] self . __ maxiter = int ( sim_param [ \"max_iter\" ]) # allocate memory self . __ particles = [] self . __ springdampers = [] self . __ f = np . zeros (( self . __ n * 3 , ), dtype='float64' ) self . __ jx = np . zeros (( self . __ n * 3 , self . __ n * 3 ), dtype='float64' ) self . __ jv = np . zeros (( self . __ n * 3 , self . __ n * 3 )) self . __ instantiate_particles ( initial_conditions ) self . __ m_matrix = self . __ construct_m_matrix () self . __ instantiate_springdampers () # Variables required for kinetic damping self . __ w_kin = self . __ calc_kin_energy () self . __ w_kin_min1 = self . __ calc_kin_energy () self . __ vis_damp = True self . __ x_min1 = np . zeros ( self . __ n , ) self . __ x_min2 = np . zeros ( self . __ n , ) # Variables that aid simulations self . COM_offset = np . zeros ( 3 ) # setup some recording self . __ history = { 'dt' : [], 'E_kin' : []} if init_surface : self . initialize_find_surface () return def __ str__ ( self ) : description = \"\" description += \"ParticleSystem object instantiated with attributes\\nConnectivity matrix:\" description += str ( self . __ connectivity_matrix ) description += \"\\n\\nInstantiated particles:\\n\" n = 1 for particle in self . __ particles : description += f \"p{n}: {particle}\\n\" n += 1 return description def __ instantiate_particles ( self , initial_conditions : list ) : for set_of_initial_cond in initial_conditions : x = set_of_initial_cond [ 0 ] v = set_of_initial_cond [ 1 ] m = set_of_initial_cond [ 2 ] f = set_of_initial_cond [ 3 ] if f and len ( set_of_initial_cond ) >= 5 : con = set_of_initial_cond [ 4 ] con_t = set_of_initial_cond [ 5 ] self . __ particles . append ( Particle ( x , v , m , f , con , con_t )) else : self . __ particles . append ( Particle ( x , v , m , f )) return def __ instantiate_springdampers ( self ) : for link in self . __ connectivity_matrix : link = link . copy () #needed to not override the __ connectivity_matrix link [ 0 ] = self . __ particles [ link [ 0 ]] link [ 1 ] = self . __ particles [ link [ 1 ]] SD = SpringDamper ( * link ) self . __ springdampers . append ( SD ) link [ 0 ]. connections . append ( SD ) link [ 1 ]. connections . append ( SD ) return def clean_up ( self , connectivity_matrix , initial_conditions ) : remove_list = set ( range ( len ( initial_conditions ))) for link in connectivity_matrix : try : remove_list . remove ( link [ 0 ]) except : pass try : remove_list . remove ( link [ 1 ]) except : pass remove_list = list ( remove_list ) remove_list . sort () for i in remove_list [ ::- 1 ] : del initial_conditions [ i ] for link in connectivity_matrix : if link [ 0 ] > i : link [ 0 ] -= 1 if link [ 1 ] > i : link [ 1 ] -= 1 def stress_self ( self , factor : float = 0 ) : \"\"\"Set all node lengths to zero to homogenously stress mesh\"\"\" if factor == 0 : for link in self . springdampers : link . l0 = 0 else : for link in self . springdampers : link . l0 *= factor return def __ construct_m_matrix ( self ) : matrix = np . zeros (( self . __ n * 3 , self . __ n * 3 )) for i in range ( self . __ n ) : matrix [ i * 3 : i * 3 + 3 , i * 3 : i * 3 + 3 ] += np . identity ( 3 ) * self . __ particles [ i ]. m return matrix def __ calc_kin_energy ( self ) : v = self . __ pack_v_current () w_kin = np . matmul ( np . matmul ( v , self . __ m_matrix ), v . T ) # Kinetic energy , 0.5 constant can be neglected return w_kin def simulate ( self , f_external : npt . ArrayLike = ()) : \"\"\" Core simulate function to advance sim a timestep Parameters embedded in self.__params ------------------------------------ adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. !!! TODO complete this with the other requisits Parameters ---------- f_external : npt.ArrayLike, optional DESCRIPTION. The default is (). Returns ------- x_next : TYPE DESCRIPTION. v_next : TYPE DESCRIPTION. \"\"\" if not len ( f_external ) : # check if external force is passed as argument , otherwise use 0 vector f_external = np . zeros ( self . __ n * 3 , ) f = self . __ one_d_force_vector () + f_external v_current = self . __ pack_v_current () x_current = self . __ pack_x_current () jx , jv = self . __ system_jacobians () #jx = sps . lil_array ( jx ) #jv = sps . lil_array ( jv ) # constructing A matrix and b vector for solver A = self . __ m_matrix - self . __ dt * jv - self . __ dt ** 2 * jx b = self . __ dt * f + self . __ dt ** 2 * jx . dot ( v_current ) # checking conditioning of A # print ( \"conditioning A:\" , np . linalg . cond ( A )) # A = sps . bsr_array ( A ) # --- START Prototype new constraint approach --- point_mask = [ not p . constraint_type == 'point' for p in self . __ particles ] plane_mask = [] line_mask = [] for p in self . __ particles : if p . constraint_type == 'plane' : for i in range ( 3 ) : line_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : plane_mask . append ( False ) plane_mask . append ( True ) plane_mask . append ( True ) elif constraint [ 1 ] == 1 : plane_mask . append ( True ) plane_mask . append ( False ) plane_mask . append ( True ) elif constraint [ 2 ] == 1 : plane_mask . append ( True ) plane_mask . append ( True ) plane_mask . append ( False ) else : for i in range ( 3 ) : plane_mask . append ( True ) elif p . constraint_type == 'line' : for i in range ( 3 ) : plane_mask . append ( True ) constraint = p . _ Particle__constraint [ 0 ] if constraint [ 0 ] == 1 : line_mask . append ( True ) line_mask . append ( False ) line_mask . append ( False ) elif constraint [ 1 ] == 1 : line_mask . append ( False ) line_mask . append ( True ) line_mask . append ( False ) elif constraint [ 2 ] == 1 : line_mask . append ( False ) line_mask . append ( False ) line_mask . append ( True ) else : for i in range ( 3 ) : line_mask . append ( True ) else : for i in range ( 3 ) : plane_mask . append ( True ) line_mask . append ( True ) mask = np . outer ( point_mask , [ True , True , True ]). flatten () mask *= plane_mask mask *= line_mask dv = np . zeros_like ( b , dtype='float64' ) A = A [ mask , : ][ : , mask ] b = np . array ( b )[ mask ] # BiCGSTAB from scipy library dv_filtered , _ = bicgstab ( A , b , tol = self . __ rtol , atol = self . __ atol , maxiter = self . __ maxiter ) dv [ mask ] = dv_filtered # numerical time integration following implicit Euler scheme v_next = v_current + dv if 'adaptive_timestepping' in self . __ params : v_max = v_next . max () if v_max ! = 0 : dt = min ( self . __ params [ 'adaptive_timestepping' ] / v_max , self . __ dt ) else : dt = self . __ dt self . __ history [ 'dt' ]. append ( dt ) x_next = x_current + dt * v_next logging . debug ( f'Adaptive timestepping triggered {dt=}' ) else : x_next = x_current + self . __ dt * v_next self . __ history [ 'dt' ]. append ( self . __ dt ) # function returns the pos . and vel . for the next timestep , but for fixed particles this val ue doesn't update! self.__update_x_v(x_next, v_next) # Recording data about the timestep: self.__history[' E_kin '].append(self.__calc_kin_energy()) return x_next, v_next def kin_damp_sim(self, f_ext: npt.ArrayLike = (), q_correction: bool = False): # kinetic damping algorithm # kwargs passed to self.simulate if self.__vis_damp: # Condition resetting viscous damping to 0 for link in self.__springdampers: link.c = 0 self.__c = 0 self.__vis_damp = False if len(f_ext): # condition checking if an f_ext is passed as argument self.__save_state() x_next, v_next = self.simulate(f_ext) else: self.__save_state() x_next, v_next = self.simulate() w_kin_new = self.__calc_kin_energy() if w_kin_new > self.__w_kin: # kin damping algorithm, takes effect when decrease in kin energy is detected self.__update_w_kin(w_kin_new) else: v_next = np.zeros(self.__n*3, ) if q_correction: # statement to check if q_correction is desired, standard is turned off q = (self.__w_kin - w_kin_new)/(2*self.__w_kin - self.__w_kin_min1 - w_kin_new) # print(q) # print(self.__w_kin, w_kin_new) # !!! Not sure if linear interpolation between states is the way to determine new x_next !!! if q < 0.5: x_next = self.__x_min2 + (q / 0.5) * (self.__x_min1 - self.__x_min2) elif q == 0.5: x_next = self.__x_min1 elif q < 1: x_next = self.__x_min1 + ((q - 0.5) / 0.5) * (x_next - self.__x_min1) # Can also use this q factor to recalculate the state for certain timestep h self.__update_x_v(x_next, v_next) self.__update_w_kin(0) return x_next, v_next def __pack_v_current(self): return np.array([particle.v for particle in self.__particles]).flatten() def __pack_x_current(self): return np.array([particle.x for particle in self.__particles]).flatten() def __one_d_force_vector(self): #self.__f[self.__f != 0] = 0 self.__f = np.zeros(self.__f.shape, dtype=np.float64) for n in range(len(self.__springdampers)): f_int = self.__springdampers[n].force_value() i, j, *_ = self.__connectivity_matrix[n] self.__f[i*3: i*3 + 3] += f_int self.__f[j*3: j*3 + 3] -= f_int return self.__f # def __system_jacobians(self): # self.__jx[self.__jx != 0] = 0 # self.__jv[self.__jv != 0] = 0 # for n in range(len(self.__springdampers)): # jx, jv = self.__springdampers[n].calculate_jacobian() # i, j, *_ = self.__connectivity_matrix[n] # if self.__particles[i].fixed: # if self.__particles[i].constraint_type == 'point': # jxplus = np.zeros([3,3]) # jvplus = jxplus # else: # jxplus = self.__particles[i].constraint_projection_matrix.dot(jx) # jvplus = self.__particles[i].constraint_projection_matrix.dot(jv) # else: # jxplus = jx # jvplus = jv # if self.__particles[j].fixed: # if self.__particles[j].constraint_type == 'point': # jxmin = np.zeros([3,3]) # jvmin = jxmin # else: # jxmin = self.__particles[j].constraint_projection_matrix.dot(jx) # jvmin = self.__particles[j].constraint_projection_matrix.dot(jv) # else: # jxmin = jx # jvmin = jv # self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jxplus # self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jxplus # self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jxmin # self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jxmin # self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jvplus # self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jvplus # self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jvmin # self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jvmin # return self.__jx, self.__jv def __system_jacobians(self): # !!! this lookup and zeroing out takes way more time than just replacing it # but replace with sparse method instead! self.__jx[self.__jx != 0] = 0 self.__jv[self.__jv != 0] = 0 for n in range(len(self.__springdampers)): jx, jv = self.__springdampers[n].calculate_jacobian() i, j, *_ = self.__connectivity_matrix[n] self.__jx[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jx self.__jx[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jx self.__jx[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jx self.__jx[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jx self.__jv[i * 3:i * 3 + 3, i * 3:i * 3 + 3] += jv self.__jv[j * 3:j * 3 + 3, j * 3:j * 3 + 3] += jv self.__jv[i * 3:i * 3 + 3, j * 3:j * 3 + 3] -= jv self.__jv[j * 3:j * 3 + 3, i * 3:i * 3 + 3] -= jv return self.__jx, self.__jv def __update_x_v(self, x_next: npt.ArrayLike, v_next: npt.ArrayLike): for i in range(self.__n): self.__particles[i].update_pos(x_next[i * 3:i * 3 + 3]) self.__particles[i].update_vel(v_next[i * 3:i * 3 + 3]) return def __update_w_kin(self, w_kin_new: float): self.__w_kin_min1 = self.__w_kin self.__w_kin = w_kin_new return def update_pos_unsafe(self, x_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_pos_unsafe(x_new[3*i: 3*i+3]) def update_vel_unsafe(self, v_new: npt.ArrayLike): for i, particle in enumerate(self.__particles): particle.update_vel_unsafe(v_new[3*i: 3*i+3]) def __save_state(self): self.__x_min2 = self.__x_min1 self.__x_min1 = self.__pack_x_current() return def find_reaction_forces(self): fixlist = [p.fixed for p in self.particles] projections = [p.constraint_projection_matrix for p in np.array(self.particles)[fixlist]] forces = self.__f.reshape((self.__n,3)) forces = -forces[fixlist] for i, projection in enumerate(projections): forces[i] -= projection.dot(forces[i].T).T return forces @property def particles(self): # @property decorators required, as PS info might be required for external calcs return self.__particles @property def springdampers(self): return self.__springdampers # @property # def stiffness_m(self): # self.__system_jacobians() # return self.__jx @property def kinetic_energy(self): return self.__calc_kin_energy() @property def f_int(self): f_int = self.__f.copy() for i in range(len(self.__particles)): # need to exclude fixed particles for force-based convergence if self.__particles[i].fixed: f_int[i*3:(i+1)*3] = 0 return f_int @property def x_v_current(self): return self.__pack_x_current(), self.__pack_v_current() @property def x_v_current_3D(self): x = self.__pack_x_current() v = self.__pack_v_current() x = np.reshape(x, (int(len(x)/3),3)) v = np.reshape(v, (int(len(v)/3),3)) return x, v @property def history(self): return self.__history @property def params(self): return self.__params @property def n(self): return self.__n def plot(self, ax=None, colors = None): \"\"\"\"Plots current system configuration\"\"\" if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') fixlist = [] freelist = [] for particle in self.__particles: if particle.fixed: fixlist.append(particle.x) else: freelist.append(particle.x) fixlist = np.array(fixlist) freelist = np.array(freelist) if len(fixlist)>0: ax.scatter(fixlist[:,0],fixlist[:,1],fixlist[:,2], color = 'red', marker = 'o') if len(freelist)>0: ax.scatter(freelist[:,0],freelist[:,1],freelist[:,2], color = 'blue', marker = 'o', s =5) segments = [] for link in self.__springdampers: segments.append(link.line_segment()) if colors == 'strain': colors = [] strains = np.array([(sd.l-sd.l0)/sd.l0 for sd in self.__springdampers]) s_range = max(abs(strains.max()),abs(strains.min())) for strain_i in strains: if strain_i>0: colors.append((0,0,strain_i/s_range,1)) elif strain_i<0: colors.append((strain_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) elif colors == 'forces': colors = [] forces = np.array([sd.force_value() for sd in self.__springdampers]) forces = np.linalg.norm(forces, axis=1) s_range = max(abs(forces.max()),abs(forces.min())) for force_i in forces: if force_i>0: colors.append((0,0,force_i/s_range,1)) elif force_i<0: colors.append((force_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) else: colors = 'black' lc = Line3DCollection(segments, colors = colors, linewidths = 0.5) ax.add_collection3d(lc) ax.set_xlabel('x') ax.set_ylabel('y') ax.set_zlabel('z') ax.set_aspect('equal') return ax def plot_forces(self, forces, ax = None, length = 5): if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax = self.plot(ax) x,_ = self.x_v_current_3D ax.quiver(x[:,0], x[:,1], x[:,2], forces[:,0], forces[:,1], forces[:,2], length = length, label = ' Forces ') return ax def initialize_find_surface(self, projection_plane: str = 'z'): \"\"\" performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters ---------- projection_plane : str normal direction of plane for the mesh to be projected on for triangulation. Default: z Returns ------- simplices : list nested list of node indices that make up triangles conversion_matrix : npt.ArrayLike ndarray of shape n_nodes x n_triangles \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) # Checking projection plane if projection_plane == 'x': projection_plane = 0 elif projection_plane == 'y': projection_plane = 1 elif projection_plane == 'z': projection_plane = 2 else: raise AttributeError(\"projection_plane improperly defined; Must be x, y or z.\") # Performing triangulation points_projected = points[:,:projection_plane] # Projecting onto x-y plane tri = Delaunay(points_projected) # Finding areas of each triangle v1 = points[tri.simplices[:,0]]-points[tri.simplices[:,1]] v2 = points[tri.simplices[:,0]]-points[tri.simplices[:,2]] # Next we set up the matrix multiplication that will divide the areas # of the triangles over the actual nodes #conversion_matrix = np.zeros((self.__n*3,len(tri.simplices)*3)) v1_length = np.linalg.norm(v1, axis=1) v2_length = np.linalg.norm(v2, axis=1) v3_length = np.linalg.norm(v2-v1, axis=1) angle_1 = np.arccos(np.sum(v1*v2, axis = 1)/(v1_length*v2_length)) # Next bit is a fix for an error due to limited numerical accuracy inp = v2_length/v3_length * np.sin(angle_1) inp[inp>1] = 1 angle_2 = np.arcsin(inp) angle_3 = np.pi - angle_1 - angle_2 angle_iterator = np.column_stack((angle_1, angle_2, angle_3)).flatten()/np.pi # Sparse matrix construction rows = [] cols = [] data = [] for j, indices in enumerate(tri.simplices): for k, i in enumerate(indices): for l in range(3): rows.append(3*i+l) cols.append(3*j+l) data.append(angle_iterator[3*j+k]) conversion_matrix = sps.csr_matrix((data, (rows, cols)), shape=(self.__n*3, len(tri.simplices)*3)) #for j, indices in enumerate(tri.simplices): # for k, i in enumerate(indices): # conversion_matrix[3*i,3*j]+= angle_iterator[3*j+k] # conversion_matrix[3*i+1,3*j+1]+= angle_iterator[3*j+k] # conversion_matrix[3*i+2,3*j+2]+= angle_iterator[3*j+k] self.__simplices = tri.simplices self.__surface_conversion_matrix = conversion_matrix return tri.simplices, conversion_matrix def find_surface(self, projection_plane: str = 'z') -> np.ndarray: \"\"\" finds the surface area vector for each node in the mesh Parameters ---------- projection_plane: passed to self.initialize_find_surface(). Returns ------- areas: npt.ArrayLike 3D area vectors for each node \"\"\" if not hasattr(self, ' _ ParticleSystem__surface_conversion_matrix '): logging.warning('find_surface called without prior initialization . ') simplices, conversion_matrix = self.initialize_find_surface(projection_plane) self.__simplices = simplices self.__surface_conversion_matrix = conversion_matrix else: conversion_matrix = self.__surface_conversion_matrix simplices = self.__simplices # Gathering points of nodes points = self.__pack_x_current() n = len(points) points = points.reshape((int(n/3),3)) # Finding areas of each triangle v1 = points[simplices[:,0]]-points[simplices[:,1]] v2 = points[simplices[:,0]]-points[simplices[:,2]] # Calculate the area of the triangulated simplices area_vectors = np.cross(v1,v2)/2 # Convert these to correct particle area magnitudes # Summing vectors oposing directions cancel, which we need for finding # the direction but diminishes the area magnitude. We need to correct # for this by calculating them seperately and scaling the vector. simplice_area_magnitudes = np.linalg.norm(area_vectors, axis=1) logging.debug(f' { np . sum ( simplice_area_magnitudes ) = } ') simplice_area_magnitudes_1d = np.outer(simplice_area_magnitudes,np.ones(3)).flatten() particle_area_magnitudes_1d = conversion_matrix.dot(simplice_area_magnitudes_1d) logging.debug(f' { np . sum ( particle_area_magnitudes_1d ) = } ') logging.debug(f' { np . sum ( particle_area_magnitudes_1d [ :: 3 ]) = } ') # Now we transorm the simplice areas into nodal areas input_vector = area_vectors.flatten() area_vectors_1d_direction = conversion_matrix.dot(input_vector) area_vectors_redistributed = area_vectors_1d_direction.reshape((int(n/3),3)) # Scaling the vectors direction_magnitudes = np.linalg.norm(area_vectors_redistributed, axis = 1) logging.debug(f' { np . sum ( direction_magnitudes ) = } ') scaling_factor = particle_area_magnitudes_1d[::3] /direction_magnitudes logging.debug(f' { scaling_factor= } ') area_vectors_redistributed *= np.outer(scaling_factor,np.ones(3)) logging.debug(f' After scaling { np . sum ( np . linalg . norm ( area_vectors_redistributed , axis = 1 )) = } ') return area_vectors_redistributed def plot_triangulated_surface(self, ax = None, arrow_length = 1, plot_points = True): \"\"\" plots triangulated surface for user inspection \"\"\" # Gathering points of nodes points = self.__pack_x_current() points = points.reshape((int(len(points)/3),3)) x,y,z = points[:,0], points[:,1], points[:,2] area_vectors = self.find_surface() a_u = area_vectors[:,0] a_v = area_vectors[:,1] a_w = area_vectors[:,2] if ax == None: fig = plt.figure() ax = fig.add_subplot(projection=' 3 d') ax.plot_trisurf(x, y, z, triangles=self.__simplices, cmap=plt.cm.Spectral) if plot_points: ax.scatter(x,y,z) if arrow_length: ax.quiver(x,y,z,a_u,a_v,a_w, length = arrow_length) return ax def calculate_correct_masses(self, thickness, density): areas = np.linalg.norm(self.find_surface(), axis=1) masses = areas * thickness * density for i, particle in enumerate(self.particles): particle.set_m(masses[i]) # Recalculate mass matrix self.__m_matrix = self.__construct_m_matrix() def calculate_center_of_mass(self): locations, _ = self.x_v_current_3D masses = np.array([p.m for p in self.particles]) total_mass = np.sum(masses) weighing_vector = masses/total_mass for i in range(3): locations[:,i]*=weighing_vector COM = np.sum(locations,axis=0) return COM+self.COM_offset def calculate_mass_moment_of_inertia(self): masses = np.array([p.m for p in self.particles]) COM = self.calculate_center_of_mass() locations, _ = self.x_v_current_3D locations -= COM r2 = np.vstack([locations[:, 1]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 2]**2, locations[:, 0]**2 + locations[:, 1]**2]) return r2.T*masses[:,np.newaxis] def displace(self, displacement : list, suppress_warnings = False): \"\"\" displaces the associated particle system with the prescribed amount around the center of mass. Parameters ---------- displacement_range : list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. suppress_warnings : bool allows for repeated displacement of PS without warnings. \"\"\" if len(displacement) != 6: raise AttributeError(\"Expected list of 6 arguments representing \" f\"x,y,z,rx,ry,rz, got list of length {len(displacement)} instead\") if hasattr(self, 'current_displacement'): if (type(self.current_displacement) != type(None) and not suppress_warnings and not np.all(self.current_displacement == -np.array(displacement))): # I want to allow this behavior, #but also inform user that by doing it this way they're breaking stuff logging . warning ( f \" Particle system is already displaced : \\ { self . current_displacement= }; displace called multiple times without\\ un - displacing . un - displacing is now broken . \") elif type(self.current_displacement) != type(None): self.current_displacement += np.array(displacement) else: self.current_displacement = np.array(displacement, dtype =float) else: self.current_displacement = np.array(displacement, dtype =float) qx, qy, qz, *_ = displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) new_locations = self.rotate_mesh(locations, displacement[3:]) new_locations = self.translate_mesh(new_locations, displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) def un_displace(self): \"\"\" Reverses current displacement of the ParticleSystem using stored val ue . \"\"\" if not hasattr(self, 'current_displacement'): raise AttributeError(\" Particle System is not currently displaced \") elif type(self.current_displacement) == type(None): raise AttributeError(\" Particle System is not currently displaced \") current_displacement = self.current_displacement reverse_displacement = -np.array(current_displacement) qx, qy, qz, *_ = reverse_displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) # Extra syntax is to apply rotations in reverse order new_locations = self.rotate_mesh(locations, reverse_displacement[3:][::-1], order = 'xyz') new_locations = self.translate_mesh(new_locations, reverse_displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # 'Unsafe' update needed to move fixed particles as well self.particles[i].update_pos_unsafe(location) self.current_displacement = None def translate_mesh(self, mesh, translation): \"\"\" Translates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point translation : list x , y , z axis translations Returns ------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\"\" qx, qy, qz = translation mesh[:,0] += qx mesh[:,1] += qy mesh[:,2] += qz return mesh def rotate_mesh(self, mesh : npt.ArrayLike, rotations : list, order = 'xyz'): \"\"\" Rotates mesh locations Parameters ---------- mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point rotations : list x , y , z axis rotation angles in degrees Returns ------- rotated_mesh : npt . ArrayLike shape n x 3 array holding x , y , z locations of each point \"\" \" rotation_matrix = Rotation . from_euler ( order , rotations , degrees = True ) rotated_mesh = np . matmul ( rotation_matrix . as_matrix (), mesh . T ). T return rotated_mesh def reset_history ( self ) : for key in self . history . keys () : if type ( self . history [ key ]) == list : self . history [ key ] = [] else : self . history [ key ] = np . zeros ( self . history [ key ]. shape )","title":"ParticleSystem"},{"location":"reference/src/particleSystem/ParticleSystem/#instance-variables","text":"f_int history kinetic_energy n params particles springdampers x_v_current x_v_current_3D","title":"Instance variables"},{"location":"reference/src/particleSystem/ParticleSystem/#methods","text":"","title":"Methods"},{"location":"reference/src/particleSystem/ParticleSystem/#calculate_center_of_mass","text":"def calculate_center_of_mass ( self ) View Source def calculate_center_of_mass ( self ) : locations , _ = self . x_v_current_3D masses = np . array ( [ p . m for p in self . particles ] ) total_mass = np . sum ( masses ) weighing_vector = masses / total_mass for i in range ( 3 ) : locations [:, i ] *= weighing_vector COM = np . sum ( locations , axis = 0 ) return COM + self . COM_offset","title":"calculate_center_of_mass"},{"location":"reference/src/particleSystem/ParticleSystem/#calculate_correct_masses","text":"def calculate_correct_masses ( self , thickness , density ) View Source def calculate_correct_masses ( self , thickness , density ) : areas = np . linalg . norm ( self . find_surface (), axis = 1 ) masses = areas * thickness * density for i , particle in enumerate ( self . particles ) : particle . set_m ( masses [ i ] ) # Recalculate mass matrix self . __m_matrix = self . __construct_m_matrix ()","title":"calculate_correct_masses"},{"location":"reference/src/particleSystem/ParticleSystem/#calculate_mass_moment_of_inertia","text":"def calculate_mass_moment_of_inertia ( self ) View Source def calculate_mass_moment_of_inertia ( self ) : masses = np . array ( [ p . m for p in self . particles ] ) COM = self . calculate_center_of_mass () locations , _ = self . x_v_current_3D locations -= COM r2 = np . vstack ( [ locations [:, 1 ] ** 2 + locations [:, 2 ] ** 2 , locations [:, 0 ] ** 2 + locations [:, 2 ] ** 2 , locations [:, 0 ] ** 2 + locations [:, 1 ] ** 2 ] ) return r2 . T * masses [:, np . newaxis ]","title":"calculate_mass_moment_of_inertia"},{"location":"reference/src/particleSystem/ParticleSystem/#clean_up","text":"def clean_up ( self , connectivity_matrix , initial_conditions ) View Source def clean_up ( self , connectivity_matrix , initial_conditions ) : remove_list = set ( range ( len ( initial_conditions ))) for link in connectivity_matrix : try : remove_list . remove ( link [ 0 ]) except : pass try : remove_list . remove ( link [ 1 ]) except : pass remove_list = list ( remove_list ) remove_list . sort () for i in remove_list [ ::- 1 ] : del initial_conditions [ i ] for link in connectivity_matrix : if link [ 0 ] > i : link [ 0 ] -= 1 if link [ 1 ] > i : link [ 1 ] -= 1","title":"clean_up"},{"location":"reference/src/particleSystem/ParticleSystem/#displace","text":"def displace ( self , displacement : list , suppress_warnings = False ) displaces the associated particle system with the prescribed amount around the center of mass. Parameters: Name Type Description Default displacement_range list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. None suppress_warnings bool allows for repeated displacement of PS without warnings. None View Source def displace ( self , displacement : list , suppress_warnings = False ) : \"\"\" displaces the associated particle system with the prescribed amount around the center of mass. Parameters ---------- displacement_range : list list of length 6 representing the displacement magnitudes to perform the displacement. First three values represent lateral displacement in meters. Next three values represent tilt angle around the centre of mass in degrees. suppress_warnings : bool allows for repeated displacement of PS without warnings. \"\"\" if len ( displacement ) != 6 : raise AttributeError ( \"Expected list of 6 arguments representing \" f \"x,y,z,rx,ry,rz, got list of length {len(displacement)} instead\" ) if hasattr ( self , 'current_displacement' ) : if ( type ( self . current_displacement ) != type ( None ) and not suppress_warnings and not np . all ( self . current_displacement == - np . array ( displacement ))) : # I want to allow this behavior , #but also inform user that by doing it this way they 're breaking stuff logging.warning(f\"Particle system is already displaced: \\ {self.current_displacement=}; displace called multiple times without\\ un-displacing. un-displacing is now broken.\") elif type(self.current_displacement) != type(None): self.current_displacement += np.array(displacement) else: self.current_displacement = np.array(displacement, dtype =float) else: self.current_displacement = np.array(displacement, dtype =float) qx, qy, qz, *_ = displacement locations, _ = self.x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM =self.calculate_center_of_mass() self.translate_mesh(locations, -COM) new_locations = self.rotate_mesh(locations, displacement[3:]) new_locations = self.translate_mesh(new_locations, displacement[:3]) # Put back system in original location new_locations = self.translate_mesh(new_locations, COM) for i, location in enumerate(new_locations): # ' Unsafe ' update needed to move fixed particles as well self . particles [ i ] . update_pos_unsafe ( location )","title":"displace"},{"location":"reference/src/particleSystem/ParticleSystem/#find_reaction_forces","text":"def find_reaction_forces ( self ) View Source def find_reaction_forces ( self ) : fixlist = [ p.fixed for p in self.particles ] projections = [ p.constraint_projection_matrix for p in np.array(self.particles)[fixlist ] ] forces = self . __f . reshape (( self . __n , 3 )) forces = - forces [ fixlist ] for i , projection in enumerate ( projections ) : forces [ i ] -= projection . dot ( forces [ i ] . T ). T return forces","title":"find_reaction_forces"},{"location":"reference/src/particleSystem/ParticleSystem/#find_surface","text":"def find_surface ( self , projection_plane : str = 'z' ) -> numpy . ndarray finds the surface area vector for each node in the mesh Returns: Type Description npt.ArrayLike 3D area vectors for each node View Source def find_surface ( self , projection_plane : str = 'z' ) -> np . ndarray : \"\"\" finds the surface area vector for each node in the mesh Parameters ---------- projection_plane: passed to self.initialize_find_surface(). Returns ------- areas: npt.ArrayLike 3D area vectors for each node \"\"\" if not hasattr ( self , ' _ParticleSystem__surface_conversion_matrix ' ): logging . warning ( ' find_surface called without prior initialization . ' ) simplices , conversion_matrix = self . initialize_find_surface ( projection_plane ) self . __simplices = simplices self . __surface_conversion_matrix = conversion_matrix else : conversion_matrix = self . __surface_conversion_matrix simplices = self . __simplices # Gathering points of nodes points = self . __pack_x_current () n = len ( points ) points = points . reshape (( int ( n / 3 ), 3 )) # Finding areas of each triangle v1 = points [ simplices [:, 0 ]] - points [ simplices [:, 1 ]] v2 = points [ simplices [:, 0 ]] - points [ simplices [:, 2 ]] # Calculate the area of the triangulated simplices area_vectors = np . cross ( v1 , v2 ) / 2 # Convert these to correct particle area magnitudes # Summing vectors oposing directions cancel , which we need for finding # the direction but diminishes the area magnitude . We need to correct # for this by calculating them seperately and scaling the vector . simplice_area_magnitudes = np . linalg . norm ( area_vectors , axis = 1 ) logging . debug ( f ' { np . sum ( simplice_area_magnitudes )=} ' ) simplice_area_magnitudes_1d = np . outer ( simplice_area_magnitudes , np . ones ( 3 )). flatten () particle_area_magnitudes_1d = conversion_matrix . dot ( simplice_area_magnitudes_1d ) logging . debug ( f ' { np . sum ( particle_area_magnitudes_1d )=} ' ) logging . debug ( f ' { np . sum ( particle_area_magnitudes_1d [ :: 3 ])=} ' ) # Now we transorm the simplice areas into nodal areas input_vector = area_vectors . flatten () area_vectors_1d_direction = conversion_matrix . dot ( input_vector ) area_vectors_redistributed = area_vectors_1d_direction . reshape (( int ( n / 3 ), 3 )) # Scaling the vectors direction_magnitudes = np . linalg . norm ( area_vectors_redistributed , axis = 1 ) logging . debug ( f ' { np . sum ( direction_magnitudes )=} ' ) scaling_factor = particle_area_magnitudes_1d [ :: 3 ] / direction_magnitudes logging . debug ( f ' { scaling_factor =} ' ) area_vectors_redistributed *= np . outer ( scaling_factor , np . ones ( 3 )) logging . debug ( f ' After scaling { np . sum ( np . linalg . norm ( area_vectors_redistributed , axis = 1 ))=} ' ) return area_vectors_redistributed","title":"find_surface"},{"location":"reference/src/particleSystem/ParticleSystem/#initialize_find_surface","text":"def initialize_find_surface ( self , projection_plane : str = 'z' ) performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters: Name Type Description Default projection_plane str normal direction of plane for the mesh to be projected on for triangulation. Default: z z Returns: Type Description list nested list of node indices that make up triangles View Source def initialize_find_surface ( self , projection_plane : str = 'z' ): \"\"\" performs triangulation and sets up conversion matrix for surface calc Projects the point cloud onto specified plane and performs triangulation. Then uses shape of current triangles to create a conversion matrix for assigning the areas of each triangle onto the nodes. Parameters ---------- projection_plane : str normal direction of plane for the mesh to be projected on for triangulation. Default: z Returns ------- simplices : list nested list of node indices that make up triangles conversion_matrix : npt.ArrayLike ndarray of shape n_nodes x n_triangles \"\"\" # Gathering points of nodes points = self . __pack_x_current () points = points . reshape (( int ( len ( points ) / 3 ), 3 )) # Checking projection plane if projection_plane == 'x' : projection_plane = 0 elif projection_plane == 'y' : projection_plane = 1 elif projection_plane == 'z' : projection_plane = 2 else : raise AttributeError ( \"projection_plane improperly defined; Must be x, y or z.\" ) # Performing triangulation points_projected = points [:,: projection_plane ] # Projecting onto x-y plane tri = Delaunay ( points_projected ) # Finding areas of each triangle v1 = points [ tri . simplices [:, 0 ]] - points [ tri . simplices [:, 1 ]] v2 = points [ tri . simplices [:, 0 ]] - points [ tri . simplices [:, 2 ]] # Next we set up the matrix multiplication that will divide the areas # of the triangles over the actual nodes #conversion_matrix = np.zeros((self.__n*3,len(tri.simplices)*3)) v1_length = np . linalg . norm ( v1 , axis = 1 ) v2_length = np . linalg . norm ( v2 , axis = 1 ) v3_length = np . linalg . norm ( v2 - v1 , axis = 1 ) angle_1 = np . arccos ( np . sum ( v1 * v2 , axis = 1 ) / ( v1_length * v2_length )) # Next bit is a fix for an error due to limited numerical accuracy inp = v2_length / v3_length * np . sin ( angle_1 ) inp [ inp > 1 ] = 1 angle_2 = np . arcsin ( inp ) angle_3 = np . pi - angle_1 - angle_2 angle_iterator = np . column_stack (( angle_1 , angle_2 , angle_3 )) . flatten () / np . pi # Sparse matrix construction rows = [] cols = [] data = [] for j , indices in enumerate ( tri . simplices ): for k , i in enumerate ( indices ): for l in range ( 3 ): rows . append ( 3 * i + l ) cols . append ( 3 * j + l ) data . append ( angle_iterator [ 3 * j + k ]) conversion_matrix = sps . csr_matrix (( data , ( rows , cols )), shape = ( self . __n * 3 , len ( tri . simplices ) * 3 )) #for j, indices in enumerate(tri.simplices): # for k, i in enumerate(indices): # conversion_matrix[3*i,3*j]+= angle_iterator[3*j+k] # conversion_matrix[3*i+1,3*j+1]+= angle_iterator[3*j+k] # conversion_matrix[3*i+2,3*j+2]+= angle_iterator[3*j+k] self . __simplices = tri . simplices self . __surface_conversion_matrix = conversion_matrix return tri . simplices , conversion_matrix","title":"initialize_find_surface"},{"location":"reference/src/particleSystem/ParticleSystem/#kin_damp_sim","text":"def kin_damp_sim ( self , f_ext : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] = (), q_correction : bool = False ) View Source def kin_damp_sim ( self , f_ext : npt . ArrayLike = () , q_correction : bool = False ) : # kinetic damping algorithm # kwargs passed to self . simulate if self . __vis_damp : # Condition resetting viscous damping to 0 for link in self . __springdampers : link . c = 0 self . __c = 0 self . __vis_damp = False if len ( f_ext ) : # condition checking if an f_ext is passed as argument self . __save_state () x_next , v_next = self . simulate ( f_ext ) else : self . __save_state () x_next , v_next = self . simulate () w_kin_new = self . __calc_kin_energy () if w_kin_new > self . __w_kin : # kin damping algorithm , takes effect when decrease in kin energy is detected self . __update_w_kin ( w_kin_new ) else : v_next = np . zeros ( self . __n * 3 , ) if q_correction : # statement to check if q_correction is desired , standard is turned off q = ( self . __w_kin - w_kin_new ) / ( 2 * self . __w_kin - self . __w_kin_min1 - w_kin_new ) # print ( q ) # print ( self . __w_kin , w_kin_new ) # !!! Not sure if linear interpolation between states is the way to determine new x_next !!! if q < 0 . 5 : x_next = self . __x_min2 + ( q / 0 . 5 ) * ( self . __x_min1 - self . __x_min2 ) elif q == 0 . 5 : x_next = self . __x_min1 elif q < 1 : x_next = self . __x_min1 + (( q - 0 . 5 ) / 0 . 5 ) * ( x_next - self . __x_min1 ) # Can also use this q factor to recalculate the state for certain timestep h self . __update_x_v ( x_next , v_next ) self . __update_w_kin ( 0 ) return x_next , v_next","title":"kin_damp_sim"},{"location":"reference/src/particleSystem/ParticleSystem/#plot","text":"def plot ( self , ax = None , colors = None ) \"Plots current system configuration View Source def plot ( self , ax = None , colors = None ) : \"\"\"\" Plots current system configuration \"\" \" if ax == None: fig = plt.figure() ax = fig.add_subplot(projection='3d') fixlist = [] freelist = [] for particle in self.__particles: if particle.fixed: fixlist.append(particle.x) else: freelist.append(particle.x) fixlist = np.array(fixlist) freelist = np.array(freelist) if len(fixlist)>0: ax.scatter(fixlist[:,0],fixlist[:,1],fixlist[:,2], color = 'red', marker = 'o') if len(freelist)>0: ax.scatter(freelist[:,0],freelist[:,1],freelist[:,2], color = 'blue', marker = 'o', s =5) segments = [] for link in self.__springdampers: segments.append(link.line_segment()) if colors == 'strain': colors = [] strains = np.array([(sd.l-sd.l0)/sd.l0 for sd in self.__springdampers]) s_range = max(abs(strains.max()),abs(strains.min())) for strain_i in strains: if strain_i>0: colors.append((0,0,strain_i/s_range,1)) elif strain_i<0: colors.append((strain_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) elif colors == 'forces': colors = [] forces = np.array([sd.force_value() for sd in self.__springdampers]) forces = np.linalg.norm(forces, axis=1) s_range = max(abs(forces.max()),abs(forces.min())) for force_i in forces: if force_i>0: colors.append((0,0,force_i/s_range,1)) elif force_i<0: colors.append((force_i/s_range,0,0,1)) else: colors.append((0,0,0,1)) else: colors = 'black' lc = Line3DCollection(segments, colors = colors, linewidths = 0.5) ax.add_collection3d(lc) ax.set_xlabel('x') ax.set_ylabel('y') ax.set_zlabel('z') ax.set_aspect('equal') return ax","title":"plot"},{"location":"reference/src/particleSystem/ParticleSystem/#plot_forces","text":"def plot_forces ( self , forces , ax = None , length = 5 ) View Source def plot_forces ( self , forces , ax = None , length = 5 ) : if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = '3d' ) ax = self . plot ( ax ) x , _ = self . x_v_current_3D ax . quiver ( x [:, 0 ], x [:, 1 ], x [:, 2 ], forces [:, 0 ], forces [:, 1 ], forces [:, 2 ], length = length , label = 'Forces' ) return ax","title":"plot_forces"},{"location":"reference/src/particleSystem/ParticleSystem/#plot_triangulated_surface","text":"def plot_triangulated_surface ( self , ax = None , arrow_length = 1 , plot_points = True ) plots triangulated surface for user inspection View Source def plot_triangulated_surface ( self , ax = None , arrow_length = 1 , plot_points = True ): \"\"\" plots triangulated surface for user inspection \"\"\" # Gathering points of nodes points = self . __pack_x_current () points = points . reshape (( int ( len ( points ) / 3 ), 3 )) x , y , z = points [:, 0 ], points [:, 1 ], points [:, 2 ] area_vectors = self . find_surface () a_u = area_vectors [:, 0 ] a_v = area_vectors [:, 1 ] a_w = area_vectors [:, 2 ] if ax == None : fig = plt . figure () ax = fig . add_subplot ( projection = ' 3 d ' ) ax . plot_trisurf ( x , y , z , triangles = self . __simplices , cmap = plt . cm . Spectral ) if plot_points : ax . scatter ( x , y , z ) if arrow_length : ax . quiver ( x , y , z , a_u , a_v , a_w , length = arrow_length ) return ax","title":"plot_triangulated_surface"},{"location":"reference/src/particleSystem/ParticleSystem/#reset_history","text":"def reset_history ( self ) View Source def reset_history ( self ) : for key in self . history . keys () : if type ( self . history [ key ] ) == list : self . history [ key ] = [] else : self . history [ key ] = np . zeros ( self . history [ key ] . shape )","title":"reset_history"},{"location":"reference/src/particleSystem/ParticleSystem/#rotate_mesh","text":"def rotate_mesh ( self , mesh : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]], rotations : list , order = 'xyz' ) Rotates mesh locations Parameters: Name Type Description Default mesh npt.ArrayLike shape n x 3 array holding x, y, z locations of each point None rotations list x, y, z axis rotation angles in degrees None Returns: Type Description npt.ArrayLike shape n x 3 array holding x, y, z locations of each point View Source def rotate_mesh ( self , mesh : npt . ArrayLike , rotations : list , order = 'xyz' ) : \"\" \" Rotates mesh locations Parameters ---------- mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point rotations : list x, y, z axis rotation angles in degrees Returns ------- rotated_mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point \"\" \" rotation_matrix = Rotation.from_euler(order, rotations, degrees=True) rotated_mesh = np.matmul(rotation_matrix.as_matrix(), mesh.T).T return rotated_mesh","title":"rotate_mesh"},{"location":"reference/src/particleSystem/ParticleSystem/#simulate","text":"def simulate ( self , f_external : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] = () ) Core simulate function to advance sim a timestep","title":"simulate"},{"location":"reference/src/particleSystem/ParticleSystem/#parameters-embedded-in-self__params","text":"adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. Todo Parameters: Name Type Description Default f_external npt.ArrayLike DESCRIPTION. The default is (). is Returns: Type Description TYPE DESCRIPTION. View Source def simulate ( self , f_external : npt . ArrayLike = ()) : \"\"\" Core simulate function to advance sim a timestep Parameters embedded in self.__params ------------------------------------ adaptive_timestepping : float, optional Enables adaptive timestepping. The default is 0, disabeling it. Adaptive timestepping imposes a limit on the displacement per timestep. To enable it, pass the maximum distance a particle can displace in a timestep. !!! TODO complete this with the other requisits Parameters ---------- f_external : npt.ArrayLike, optional DESCRIPTION. The default is (). Returns ------- x_next : TYPE DESCRIPTION. v_next : TYPE DESCRIPTION. \"\"\" if not len ( f_external ) : # check if external force is passed as argument , otherwise use 0 vector f_external = np . zeros ( self . __n * 3 , ) f = self . __one_d_force_vector () + f_external v_current = self . __pack_v_current () x_current = self . __pack_x_current () jx , jv = self . __system_jacobians () #jx = sps . lil_array ( jx ) #jv = sps . lil_array ( jv ) # constructing A matrix and b vector for solver A = self . __m_matrix - self . __dt * jv - self . __dt ** 2 * jx b = self . __dt * f + self . __dt ** 2 * jx . dot ( v_current ) # checking conditioning of A # print ( \"conditioning A:\" , np . linalg . cond ( A )) #A = sps . bsr_array ( A ) # --- START Prototype new constraint approach --- point_mask = [ not p.constraint_type == 'point' for p in self.__particles ] plane_mask = [] line_mask = [] for p in self . __particles : if p . constraint_type == 'plane' : for i in range ( 3 ) : line_mask . append ( True ) constraint = p . _Particle__constraint [ 0 ] if constraint [ 0 ]== 1 : plane_mask . append ( False ) plane_mask . append ( True ) plane_mask . append ( True ) elif constraint [ 1 ]== 1 : plane_mask . append ( True ) plane_mask . append ( False ) plane_mask . append ( True ) elif constraint [ 2 ]== 1 : plane_mask . append ( True ) plane_mask . append ( True ) plane_mask . append ( False ) else : for i in range ( 3 ) : plane_mask . append ( True ) elif p . constraint_type == 'line' : for i in range ( 3 ) : plane_mask . append ( True ) constraint = p . _Particle__constraint [ 0 ] if constraint [ 0 ]== 1 : line_mask . append ( True ) line_mask . append ( False ) line_mask . append ( False ) elif constraint [ 1 ]== 1 : line_mask . append ( False ) line_mask . append ( True ) line_mask . append ( False ) elif constraint [ 2 ]== 1 : line_mask . append ( False ) line_mask . append ( False ) line_mask . append ( True ) else : for i in range ( 3 ) : line_mask . append ( True ) else : for i in range ( 3 ) : plane_mask . append ( True ) line_mask . append ( True ) mask = np . outer ( point_mask , [ True,True,True ] ). flatten () mask *= plane_mask mask *= line_mask dv = np . zeros_like ( b , dtype = 'float64' ) A = A [ mask, : ][ :, mask ] b = np . array ( b ) [ mask ] # BiCGSTAB from scipy library dv_filtered , _ = bicgstab ( A , b , tol = self . __rtol , atol = self . __atol , maxiter = self . __maxiter ) dv [ mask ] = dv_filtered # numerical time integration following implicit Euler scheme v_next = v_current + dv if 'adaptive_timestepping' in self . __params : v_max = v_next . max () if v_max != 0 : dt = min ( self . __params [ 'adaptive_timestepping' ]/ v_max , self . __dt ) else : dt = self . __dt self . __history [ 'dt' ] . append ( dt ) x_next = x_current + dt * v_next logging . debug ( f 'Adaptive timestepping triggered {dt=}' ) else : x_next = x_current + self . __dt * v_next self . __history [ 'dt' ] . append ( self . __dt ) # function returns the pos . and vel . for the next timestep , but for fixed particles this value doesn 't update! self.__update_x_v(x_next, v_next) # Recording data about the timestep: self.__history[' E_kin '] . append ( self . __calc_kin_energy ()) return x_next , v_next","title":"Parameters embedded in self.__params"},{"location":"reference/src/particleSystem/ParticleSystem/#stress_self","text":"def stress_self ( self , factor : float = 0 ) Set all node lengths to zero to homogenously stress mesh View Source def stress_self ( self , factor : float = 0 ) : \"\"\"Set all node lengths to zero to homogenously stress mesh\"\"\" if factor == 0 : for link in self . springdampers : link . l0 = 0 else : for link in self . springdampers : link . l0 *= factor return","title":"stress_self"},{"location":"reference/src/particleSystem/ParticleSystem/#translate_mesh","text":"def translate_mesh ( self , mesh , translation ) Translates mesh locations Parameters: Name Type Description Default mesh npt.ArrayLike shape n x 3 array holding x, y, z locations of each point None translation list x, y, z axis translations None Returns: Type Description npt.ArrayLike shape n x 3 array holding x, y, z locations of each point View Source def translate_mesh ( self , mesh , translation ) : \"\" \" Translates mesh locations Parameters ---------- mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point translation : list x, y, z axis translations Returns ------- mesh : npt.ArrayLike shape n x 3 array holding x, y, z locations of each point \"\" \" qx, qy, qz = translation mesh[:,0] += qx mesh[:,1] += qy mesh[:,2] += qz return mesh","title":"translate_mesh"},{"location":"reference/src/particleSystem/ParticleSystem/#un_displace","text":"def un_displace ( self ) Reverses current displacement of the ParticleSystem using stored value. View Source def un_displace ( self ) : \"\"\" Reverses current displacement of the ParticleSystem using stored value. \"\"\" if not hasattr ( self , 'current_displacement' ) : raise AttributeError ( \"Particle System is not currently displaced\" ) elif type ( self . current_displacement ) == type ( None ) : raise AttributeError ( \"Particle System is not currently displaced\" ) current_displacement = self . current_displacement reverse_displacement = - np . array ( current_displacement ) qx , qy , qz , * _ = reverse_displacement locations , _ = self . x_v_current_3D # To apply rotations around COM we need to place it at the origin first COM = self . calculate_center_of_mass () self . translate_mesh ( locations , - COM ) # Extra syntax is to apply rotations in reverse order new_locations = self . rotate_mesh ( locations , reverse_displacement [ 3 : ][ ::- 1 ], order = 'xyz' ) new_locations = self . translate_mesh ( new_locations , reverse_displacement [ : 3 ]) # Put back system in original location new_locations = self . translate_mesh ( new_locations , COM ) for i , location in enumerate ( new_locations ) : # 'Unsafe' update needed to move fixed particles as well self . particles [ i ]. update_pos_unsafe ( location ) self . current_displacement = None","title":"un_displace"},{"location":"reference/src/particleSystem/ParticleSystem/#update_pos_unsafe","text":"def update_pos_unsafe ( self , x_new : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_pos_unsafe ( self , x_new : npt . ArrayLike ): for i , particle in enumerate ( self . __particles ): particle . update_pos_unsafe ( x_new [ 3 * i : 3 * i + 3 ])","title":"update_pos_unsafe"},{"location":"reference/src/particleSystem/ParticleSystem/#update_vel_unsafe","text":"def update_vel_unsafe ( self , v_new : Union [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]], numpy . _typing . _nested_sequence . _NestedSequence [ numpy . _typing . _array_like . _SupportsArray [ numpy . dtype [ Any ]]], bool , int , float , complex , str , bytes , numpy . _typing . _nested_sequence . _NestedSequence [ Union [ bool , int , float , complex , str , bytes ]]] ) View Source def update_vel_unsafe ( self , v_new : npt . ArrayLike ): for i , particle in enumerate ( self . __particles ): particle . update_vel_unsafe ( v_new [ 3 * i : 3 * i + 3 ])","title":"update_vel_unsafe"},{"location":"reference/src/particleSystem/SpringDamper/","text":"Module src.particleSystem.SpringDamper Child Class 'SpringDamper', for spring-damper objects to be instantiated in ParticleSystem View Source \"\"\" Child Class 'SpringDamper', for spring-damper objects to be instantiated in ParticleSystem \"\"\" from enum import Enum import numpy as np from .ImplicitForce import ImplicitForce from .Particle import Particle class SpringDamperType ( Enum ): \"\"\" Enumeration representing the various types of SpringDamper objects. Attributes ---------- DEFAULT : str Represents the default SpringDamper type, which has standard characteristics. NONCOMPRESSIVE : str Represents a SpringDamper that cannot be compressed, only stretched. NONTENSILE : str Represents a SpringDamper that cannot be stretched, only compressed. Notes ----- The SpringDamper type affects the initialization and behavior of the SpringDamper objects. Each type might have specific properties or behaviors associated with it in the SpringDamper class. \"\"\" DEFAULT = \"default\" NONCOMPRESSIVE = \"noncompressive\" NONTENSILE = \"nontensile\" class SpringDamper ( ImplicitForce ): \"\"\" #TODO one line summary Attributes: #TODO finish this \"\"\" def __init__ ( self , p1 : Particle , p2 : Particle , k : float , c : float , linktype = SpringDamperType . DEFAULT ): \"\"\"Initializes the spring damper Args: p1, p2: The two Particle instances to be connected k: A float representing the stiffness of the spring in N/m. c: A float representing the damping coefficient in Ns/m linktype: A SpringDamperType enum representing the properties of the link See SpringDamperType for more information \"\"\" super () . __init__ ( p1 , p2 ) self . __k = k self . __c = c self . __l0 = np . linalg . norm ( self . __relative_pos ()) self . __linktype = linktype return def __str__ ( self ): return f \"SpringDamper object, spring stiffness [n/m]: { self . __k } , rest length [m]: { self . l0 } \\n \" \\ f \"Damping coefficient [N s/m]: { self . __c } \\n \" \\ f \"Assigned particles \\n p1: { self . p1 } \\n p2: { self . p2 } \\n \" \\ f \"Link type: { self . __linktype } \" def __relative_pos ( self ): return np . array ([ self . p1 . x - self . p2 . x ]) def __relative_vel ( self ): return np . array ([ self . p1 . v - self . p2 . v ]) def force_value ( self ): if self . __linktype == SpringDamperType . DEFAULT : return self . __calculate_f_spring () + self . __calculate_f_damping () elif self . __linktype == SpringDamperType . NONCOMPRESSIVE : l = np . linalg . norm ( self . __relative_pos ()) if l >= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ]) elif self . __linktype == SpringDamperType . NONTENSILE : l = np . linalg . norm ( self . __relative_pos ()) if l <= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ]) def __calculate_f_spring ( self ): relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : unit_vector = np . array ([ 0 , 0 , 0 ]) f_spring = - self . __k * ( norm_pos - self . l0 ) * unit_vector return np . squeeze ( f_spring ) def __calculate_f_damping ( self ): relative_pos = self . __relative_pos () relative_vel = np . squeeze ( self . __relative_vel ()) norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = np . squeeze ( relative_pos / norm_pos ) else : unit_vector = np . squeeze ( np . array ([ 0 , 0 , 0 ])) f_damping = - self . __c * np . dot ( relative_vel , unit_vector ) * unit_vector return np . squeeze ( f_damping ) def calculate_jacobian ( self ): relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) # Using guard classes to return early in special cases if ( self . __linktype == SpringDamperType . NONCOMPRESSIVE and norm_pos <= self . __l0 ): return np . zeros (( 3 , 3 )), np . zeros (( 3 , 3 )) elif ( self . __linktype == SpringDamperType . NONTENSILE and norm_pos >= self . __l0 ): return np . zeros ( 3 ), np . zeros ( 3 ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : norm_pos = 1 unit_vector = np . array ([ 0 , 0 , 0 ]) i = np . identity ( 3 ) T = np . matmul ( np . transpose ( unit_vector ), unit_vector ) jx = - self . __k * (( self . l0 / norm_pos - 1 ) * ( T - i ) + T ) jv = - self . __c * i return jx , jv def line_segment ( self ): \"\"\"Returns coordinate tuple of particles at either end of segment\"\"\" return ( self . p1 . x , self . p2 . x ) @property def l ( self ): return np . linalg . norm ( self . p1 . x - self . p2 . x ) @property def l0 ( self ): return self . __l0 @l0 . setter def l0 ( self , value ): # Exposed to enable self-stressing of mesh self . __l0 = value @property def c ( self ): return self . __c @c . setter def c ( self , value ): # Exposed to enable resetting when using kinetic damping self . __c = value if __name__ == \"__main__\" : particle1 = Particle ([ 0 , 0 , 0 ], [ 0 , 0 , 0 ], 1 , False ) particle2 = Particle ([ 0 , 0 , 1 ], [ 0 , 0 , 1 ], 1 , False ) stiffness = 1e5 damping = 10 rest_length = 0 linktype = 'noncomp' springdamper = SpringDamper ( particle1 , particle2 , stiffness , damping ) print ( springdamper ) print () print ( springdamper . force_value ()) # print((np.sqrt(3)-1)*1e5/np.sqrt(3)) # value check print () print ( springdamper . calculate_jacobian ()) pass Classes SpringDamper class SpringDamper ( p1 : src . particleSystem . Particle . Particle , p2 : src . particleSystem . Particle . Particle , k : float , c : float , linktype =< SpringDamperType . DEFAULT : 'default' > ) TODO one line summary Attributes: #TODO finish this View Source class SpringDamper ( ImplicitForce ) : \"\"\" #TODO one line summary Attributes: #TODO finish this \"\"\" def __init__ ( self , p1 : Particle , p2 : Particle , k : float , c : float , linktype = SpringDamperType . DEFAULT ) : \"\"\"Initializes the spring damper Args: p1, p2: The two Particle instances to be connected k: A float representing the stiffness of the spring in N/m. c: A float representing the damping coefficient in Ns/m linktype: A SpringDamperType enum representing the properties of the link See SpringDamperType for more information \"\"\" super (). __init__ ( p1 , p2 ) self . __k = k self . __c = c self . __l0 = np . linalg . norm ( self . __relative_pos ()) self . __linktype = linktype return def __str__ ( self ) : return f \"SpringDamper object, spring stiffness [n/m]: {self.__k}, rest length [m]: {self.l0}\\n\" \\ f \"Damping coefficient [N s/m]: {self.__c}\\n\" \\ f \"Assigned particles\\n p1: {self.p1}\\n p2: {self.p2}\\n\" \\ f \"Link type: {self.__linktype}\" def __relative_pos ( self ) : return np . array ( [ self.p1.x - self.p2.x ] ) def __relative_vel ( self ) : return np . array ( [ self.p1.v - self.p2.v ] ) def force_value ( self ) : if self . __linktype == SpringDamperType . DEFAULT : return self . __calculate_f_spring () + self . __calculate_f_damping () elif self . __linktype == SpringDamperType . NONCOMPRESSIVE : l = np . linalg . norm ( self . __relative_pos ()) if l >= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ( [ 0, 0, 0 ] ) elif self . __linktype == SpringDamperType . NONTENSILE : l = np . linalg . norm ( self . __relative_pos ()) if l <= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ( [ 0, 0, 0 ] ) def __calculate_f_spring ( self ) : relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : unit_vector = np . array ( [ 0, 0, 0 ] ) f_spring = - self . __k * ( norm_pos - self . l0 ) * unit_vector return np . squeeze ( f_spring ) def __calculate_f_damping ( self ) : relative_pos = self . __relative_pos () relative_vel = np . squeeze ( self . __relative_vel ()) norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = np . squeeze ( relative_pos / norm_pos ) else : unit_vector = np . squeeze ( np . array ( [ 0, 0, 0 ] )) f_damping = - self . __c * np . dot ( relative_vel , unit_vector ) * unit_vector return np . squeeze ( f_damping ) def calculate_jacobian ( self ) : relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) # Using guard classes to return early in special cases if ( self . __linktype == SpringDamperType . NONCOMPRESSIVE and norm_pos <= self . __l0 ) : return np . zeros (( 3 , 3 )), np . zeros (( 3 , 3 )) elif ( self . __linktype == SpringDamperType . NONTENSILE and norm_pos >= self . __l0 ) : return np . zeros ( 3 ), np . zeros ( 3 ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : norm_pos = 1 unit_vector = np . array ( [ 0, 0, 0 ] ) i = np . identity ( 3 ) T = np . matmul ( np . transpose ( unit_vector ), unit_vector ) jx = - self . __k * (( self . l0 / norm_pos - 1 ) * ( T - i ) + T ) jv = - self . __c * i return jx , jv def line_segment ( self ) : \"\"\"Returns coordinate tuple of particles at either end of segment\"\"\" return ( self . p1 . x , self . p2 . x ) @property def l ( self ) : return np . linalg . norm ( self . p1 . x - self . p2 . x ) @property def l0 ( self ) : return self . __l0 @l0 . setter def l0 ( self , value ) : # Exposed to enable self - stressing of mesh self . __l0 = value @property def c ( self ) : return self . __c @c . setter def c ( self , value ) : # Exposed to enable resetting when using kinetic damping self . __c = value Ancestors (in MRO) src.particleSystem.ImplicitForce.ImplicitForce src.particleSystem.Force.Force src.particleSystem.SystemObject.SystemObject abc.ABC Instance variables c l l0 p1 p2 Methods calculate_jacobian def calculate_jacobian ( self ) View Source def calculate_jacobian ( self ): relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) # Using guard classes to return early in special cases if ( self . __linktype == SpringDamperType . NONCOMPRESSIVE and norm_pos <= self . __l0 ): return np . zeros (( 3 , 3 )), np . zeros (( 3 , 3 )) elif ( self . __linktype == SpringDamperType . NONTENSILE and norm_pos >= self . __l0 ): return np . zeros ( 3 ), np . zeros ( 3 ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : norm_pos = 1 unit_vector = np . array ([ 0 , 0 , 0 ]) i = np . identity ( 3 ) T = np . matmul ( np . transpose ( unit_vector ), unit_vector ) jx = - self . __k * (( self . l0 / norm_pos - 1 ) * ( T - i ) + T ) jv = - self . __c * i return jx , jv force_value def force_value ( self ) View Source def force_value ( self ): if self . __linktype == SpringDamperType . DEFAULT : return self . __calculate_f_spring () + self . __calculate_f_damping () elif self . __linktype == SpringDamperType . NONCOMPRESSIVE : l = np . linalg . norm ( self . __relative_pos ()) if l >= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ]) elif self . __linktype == SpringDamperType . NONTENSILE : l = np . linalg . norm ( self . __relative_pos ()) if l <= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ]) line_segment def line_segment ( self ) Returns coordinate tuple of particles at either end of segment View Source def line_segment ( self ) : \"\"\"Returns coordinate tuple of particles at either end of segment\"\"\" return ( self . p1 . x , self . p2 . x ) SpringDamperType class SpringDamperType ( / , * args , ** kwargs ) Enumeration representing the various types of SpringDamper objects. Attributes Name Type Description Default DEFAULT str Represents the default SpringDamper type, which has standard characteristics. SpringDamper NONCOMPRESSIVE str Represents a SpringDamper that cannot be compressed, only stretched. None NONTENSILE str Represents a SpringDamper that cannot be stretched, only compressed. None View Source class SpringDamperType ( Enum ): \"\"\" Enumeration representing the various types of SpringDamper objects. Attributes ---------- DEFAULT : str Represents the default SpringDamper type, which has standard characteristics. NONCOMPRESSIVE : str Represents a SpringDamper that cannot be compressed, only stretched. NONTENSILE : str Represents a SpringDamper that cannot be stretched, only compressed. Notes ----- The SpringDamper type affects the initialization and behavior of the SpringDamper objects. Each type might have specific properties or behaviors associated with it in the SpringDamper class. \"\"\" DEFAULT = \"default\" NONCOMPRESSIVE = \"noncompressive\" NONTENSILE = \"nontensile\" Ancestors (in MRO) enum.Enum Class variables DEFAULT NONCOMPRESSIVE NONTENSILE name value","title":"Springdamper"},{"location":"reference/src/particleSystem/SpringDamper/#module-srcparticlesystemspringdamper","text":"Child Class 'SpringDamper', for spring-damper objects to be instantiated in ParticleSystem View Source \"\"\" Child Class 'SpringDamper', for spring-damper objects to be instantiated in ParticleSystem \"\"\" from enum import Enum import numpy as np from .ImplicitForce import ImplicitForce from .Particle import Particle class SpringDamperType ( Enum ): \"\"\" Enumeration representing the various types of SpringDamper objects. Attributes ---------- DEFAULT : str Represents the default SpringDamper type, which has standard characteristics. NONCOMPRESSIVE : str Represents a SpringDamper that cannot be compressed, only stretched. NONTENSILE : str Represents a SpringDamper that cannot be stretched, only compressed. Notes ----- The SpringDamper type affects the initialization and behavior of the SpringDamper objects. Each type might have specific properties or behaviors associated with it in the SpringDamper class. \"\"\" DEFAULT = \"default\" NONCOMPRESSIVE = \"noncompressive\" NONTENSILE = \"nontensile\" class SpringDamper ( ImplicitForce ): \"\"\" #TODO one line summary Attributes: #TODO finish this \"\"\" def __init__ ( self , p1 : Particle , p2 : Particle , k : float , c : float , linktype = SpringDamperType . DEFAULT ): \"\"\"Initializes the spring damper Args: p1, p2: The two Particle instances to be connected k: A float representing the stiffness of the spring in N/m. c: A float representing the damping coefficient in Ns/m linktype: A SpringDamperType enum representing the properties of the link See SpringDamperType for more information \"\"\" super () . __init__ ( p1 , p2 ) self . __k = k self . __c = c self . __l0 = np . linalg . norm ( self . __relative_pos ()) self . __linktype = linktype return def __str__ ( self ): return f \"SpringDamper object, spring stiffness [n/m]: { self . __k } , rest length [m]: { self . l0 } \\n \" \\ f \"Damping coefficient [N s/m]: { self . __c } \\n \" \\ f \"Assigned particles \\n p1: { self . p1 } \\n p2: { self . p2 } \\n \" \\ f \"Link type: { self . __linktype } \" def __relative_pos ( self ): return np . array ([ self . p1 . x - self . p2 . x ]) def __relative_vel ( self ): return np . array ([ self . p1 . v - self . p2 . v ]) def force_value ( self ): if self . __linktype == SpringDamperType . DEFAULT : return self . __calculate_f_spring () + self . __calculate_f_damping () elif self . __linktype == SpringDamperType . NONCOMPRESSIVE : l = np . linalg . norm ( self . __relative_pos ()) if l >= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ]) elif self . __linktype == SpringDamperType . NONTENSILE : l = np . linalg . norm ( self . __relative_pos ()) if l <= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ]) def __calculate_f_spring ( self ): relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : unit_vector = np . array ([ 0 , 0 , 0 ]) f_spring = - self . __k * ( norm_pos - self . l0 ) * unit_vector return np . squeeze ( f_spring ) def __calculate_f_damping ( self ): relative_pos = self . __relative_pos () relative_vel = np . squeeze ( self . __relative_vel ()) norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = np . squeeze ( relative_pos / norm_pos ) else : unit_vector = np . squeeze ( np . array ([ 0 , 0 , 0 ])) f_damping = - self . __c * np . dot ( relative_vel , unit_vector ) * unit_vector return np . squeeze ( f_damping ) def calculate_jacobian ( self ): relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) # Using guard classes to return early in special cases if ( self . __linktype == SpringDamperType . NONCOMPRESSIVE and norm_pos <= self . __l0 ): return np . zeros (( 3 , 3 )), np . zeros (( 3 , 3 )) elif ( self . __linktype == SpringDamperType . NONTENSILE and norm_pos >= self . __l0 ): return np . zeros ( 3 ), np . zeros ( 3 ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : norm_pos = 1 unit_vector = np . array ([ 0 , 0 , 0 ]) i = np . identity ( 3 ) T = np . matmul ( np . transpose ( unit_vector ), unit_vector ) jx = - self . __k * (( self . l0 / norm_pos - 1 ) * ( T - i ) + T ) jv = - self . __c * i return jx , jv def line_segment ( self ): \"\"\"Returns coordinate tuple of particles at either end of segment\"\"\" return ( self . p1 . x , self . p2 . x ) @property def l ( self ): return np . linalg . norm ( self . p1 . x - self . p2 . x ) @property def l0 ( self ): return self . __l0 @l0 . setter def l0 ( self , value ): # Exposed to enable self-stressing of mesh self . __l0 = value @property def c ( self ): return self . __c @c . setter def c ( self , value ): # Exposed to enable resetting when using kinetic damping self . __c = value if __name__ == \"__main__\" : particle1 = Particle ([ 0 , 0 , 0 ], [ 0 , 0 , 0 ], 1 , False ) particle2 = Particle ([ 0 , 0 , 1 ], [ 0 , 0 , 1 ], 1 , False ) stiffness = 1e5 damping = 10 rest_length = 0 linktype = 'noncomp' springdamper = SpringDamper ( particle1 , particle2 , stiffness , damping ) print ( springdamper ) print () print ( springdamper . force_value ()) # print((np.sqrt(3)-1)*1e5/np.sqrt(3)) # value check print () print ( springdamper . calculate_jacobian ()) pass","title":"Module src.particleSystem.SpringDamper"},{"location":"reference/src/particleSystem/SpringDamper/#classes","text":"","title":"Classes"},{"location":"reference/src/particleSystem/SpringDamper/#springdamper","text":"class SpringDamper ( p1 : src . particleSystem . Particle . Particle , p2 : src . particleSystem . Particle . Particle , k : float , c : float , linktype =< SpringDamperType . DEFAULT : 'default' > )","title":"SpringDamper"},{"location":"reference/src/particleSystem/SpringDamper/#todo-one-line-summary","text":"Attributes: #TODO finish this View Source class SpringDamper ( ImplicitForce ) : \"\"\" #TODO one line summary Attributes: #TODO finish this \"\"\" def __init__ ( self , p1 : Particle , p2 : Particle , k : float , c : float , linktype = SpringDamperType . DEFAULT ) : \"\"\"Initializes the spring damper Args: p1, p2: The two Particle instances to be connected k: A float representing the stiffness of the spring in N/m. c: A float representing the damping coefficient in Ns/m linktype: A SpringDamperType enum representing the properties of the link See SpringDamperType for more information \"\"\" super (). __init__ ( p1 , p2 ) self . __k = k self . __c = c self . __l0 = np . linalg . norm ( self . __relative_pos ()) self . __linktype = linktype return def __str__ ( self ) : return f \"SpringDamper object, spring stiffness [n/m]: {self.__k}, rest length [m]: {self.l0}\\n\" \\ f \"Damping coefficient [N s/m]: {self.__c}\\n\" \\ f \"Assigned particles\\n p1: {self.p1}\\n p2: {self.p2}\\n\" \\ f \"Link type: {self.__linktype}\" def __relative_pos ( self ) : return np . array ( [ self.p1.x - self.p2.x ] ) def __relative_vel ( self ) : return np . array ( [ self.p1.v - self.p2.v ] ) def force_value ( self ) : if self . __linktype == SpringDamperType . DEFAULT : return self . __calculate_f_spring () + self . __calculate_f_damping () elif self . __linktype == SpringDamperType . NONCOMPRESSIVE : l = np . linalg . norm ( self . __relative_pos ()) if l >= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ( [ 0, 0, 0 ] ) elif self . __linktype == SpringDamperType . NONTENSILE : l = np . linalg . norm ( self . __relative_pos ()) if l <= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ( [ 0, 0, 0 ] ) def __calculate_f_spring ( self ) : relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : unit_vector = np . array ( [ 0, 0, 0 ] ) f_spring = - self . __k * ( norm_pos - self . l0 ) * unit_vector return np . squeeze ( f_spring ) def __calculate_f_damping ( self ) : relative_pos = self . __relative_pos () relative_vel = np . squeeze ( self . __relative_vel ()) norm_pos = np . linalg . norm ( relative_pos ) if norm_pos != 0 : unit_vector = np . squeeze ( relative_pos / norm_pos ) else : unit_vector = np . squeeze ( np . array ( [ 0, 0, 0 ] )) f_damping = - self . __c * np . dot ( relative_vel , unit_vector ) * unit_vector return np . squeeze ( f_damping ) def calculate_jacobian ( self ) : relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) # Using guard classes to return early in special cases if ( self . __linktype == SpringDamperType . NONCOMPRESSIVE and norm_pos <= self . __l0 ) : return np . zeros (( 3 , 3 )), np . zeros (( 3 , 3 )) elif ( self . __linktype == SpringDamperType . NONTENSILE and norm_pos >= self . __l0 ) : return np . zeros ( 3 ), np . zeros ( 3 ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : norm_pos = 1 unit_vector = np . array ( [ 0, 0, 0 ] ) i = np . identity ( 3 ) T = np . matmul ( np . transpose ( unit_vector ), unit_vector ) jx = - self . __k * (( self . l0 / norm_pos - 1 ) * ( T - i ) + T ) jv = - self . __c * i return jx , jv def line_segment ( self ) : \"\"\"Returns coordinate tuple of particles at either end of segment\"\"\" return ( self . p1 . x , self . p2 . x ) @property def l ( self ) : return np . linalg . norm ( self . p1 . x - self . p2 . x ) @property def l0 ( self ) : return self . __l0 @l0 . setter def l0 ( self , value ) : # Exposed to enable self - stressing of mesh self . __l0 = value @property def c ( self ) : return self . __c @c . setter def c ( self , value ) : # Exposed to enable resetting when using kinetic damping self . __c = value","title":"TODO one line summary"},{"location":"reference/src/particleSystem/SpringDamper/#ancestors-in-mro","text":"src.particleSystem.ImplicitForce.ImplicitForce src.particleSystem.Force.Force src.particleSystem.SystemObject.SystemObject abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/src/particleSystem/SpringDamper/#instance-variables","text":"c l l0 p1 p2","title":"Instance variables"},{"location":"reference/src/particleSystem/SpringDamper/#methods","text":"","title":"Methods"},{"location":"reference/src/particleSystem/SpringDamper/#calculate_jacobian","text":"def calculate_jacobian ( self ) View Source def calculate_jacobian ( self ): relative_pos = self . __relative_pos () norm_pos = np . linalg . norm ( relative_pos ) # Using guard classes to return early in special cases if ( self . __linktype == SpringDamperType . NONCOMPRESSIVE and norm_pos <= self . __l0 ): return np . zeros (( 3 , 3 )), np . zeros (( 3 , 3 )) elif ( self . __linktype == SpringDamperType . NONTENSILE and norm_pos >= self . __l0 ): return np . zeros ( 3 ), np . zeros ( 3 ) if norm_pos != 0 : unit_vector = relative_pos / norm_pos else : norm_pos = 1 unit_vector = np . array ([ 0 , 0 , 0 ]) i = np . identity ( 3 ) T = np . matmul ( np . transpose ( unit_vector ), unit_vector ) jx = - self . __k * (( self . l0 / norm_pos - 1 ) * ( T - i ) + T ) jv = - self . __c * i return jx , jv","title":"calculate_jacobian"},{"location":"reference/src/particleSystem/SpringDamper/#force_value","text":"def force_value ( self ) View Source def force_value ( self ): if self . __linktype == SpringDamperType . DEFAULT : return self . __calculate_f_spring () + self . __calculate_f_damping () elif self . __linktype == SpringDamperType . NONCOMPRESSIVE : l = np . linalg . norm ( self . __relative_pos ()) if l >= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ]) elif self . __linktype == SpringDamperType . NONTENSILE : l = np . linalg . norm ( self . __relative_pos ()) if l <= self . l0 : return self . __calculate_f_spring () + self . __calculate_f_damping () else : return np . array ([ 0 , 0 , 0 ])","title":"force_value"},{"location":"reference/src/particleSystem/SpringDamper/#line_segment","text":"def line_segment ( self ) Returns coordinate tuple of particles at either end of segment View Source def line_segment ( self ) : \"\"\"Returns coordinate tuple of particles at either end of segment\"\"\" return ( self . p1 . x , self . p2 . x )","title":"line_segment"},{"location":"reference/src/particleSystem/SpringDamper/#springdampertype","text":"class SpringDamperType ( / , * args , ** kwargs ) Enumeration representing the various types of SpringDamper objects.","title":"SpringDamperType"},{"location":"reference/src/particleSystem/SpringDamper/#attributes","text":"Name Type Description Default DEFAULT str Represents the default SpringDamper type, which has standard characteristics. SpringDamper NONCOMPRESSIVE str Represents a SpringDamper that cannot be compressed, only stretched. None NONTENSILE str Represents a SpringDamper that cannot be stretched, only compressed. None View Source class SpringDamperType ( Enum ): \"\"\" Enumeration representing the various types of SpringDamper objects. Attributes ---------- DEFAULT : str Represents the default SpringDamper type, which has standard characteristics. NONCOMPRESSIVE : str Represents a SpringDamper that cannot be compressed, only stretched. NONTENSILE : str Represents a SpringDamper that cannot be stretched, only compressed. Notes ----- The SpringDamper type affects the initialization and behavior of the SpringDamper objects. Each type might have specific properties or behaviors associated with it in the SpringDamper class. \"\"\" DEFAULT = \"default\" NONCOMPRESSIVE = \"noncompressive\" NONTENSILE = \"nontensile\"","title":"Attributes"},{"location":"reference/src/particleSystem/SpringDamper/#ancestors-in-mro_1","text":"enum.Enum","title":"Ancestors (in MRO)"},{"location":"reference/src/particleSystem/SpringDamper/#class-variables","text":"DEFAULT NONCOMPRESSIVE NONTENSILE name value","title":"Class variables"}]}